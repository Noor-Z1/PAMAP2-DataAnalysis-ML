{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Noor-Z1/PAMAP2-DataAnalysis-ML/blob/main/Subject-Specific-Classifiers/Subject1-8_RandomForest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo77tDJTMZ4f"
      },
      "source": [
        "# **CNG 514 - Term Project**\n",
        "\n",
        "### Notebook # 4\n",
        "\n",
        "### Author: Noor Ul Zain\n",
        "\n",
        "\n",
        "In this notebook, we apply our own selected feature extraction technique(refer to notebook # 2) to 8 subjects and then do 10 fold cross validation with Grid Search on a random forest model and train subject specific classifiers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxicRzUdJKXJ",
        "outputId": "30ccc3ed-82d1-494a-f92d-72100e6aad3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mounting drive for loading the dataset files\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRU8hhdcK6X7"
      },
      "outputs": [],
      "source": [
        "# import the necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "import matplotlib as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABuMszWIdTcq",
        "outputId": "9d928bff-f167-4bc4-b741-2c2a6d1827b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1653, 128)\n",
            "(1653,)\n"
          ]
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "from scipy.signal import ellip, filtfilt, welch\n",
        "import numpy as np\n",
        "from scipy.stats import skew, kurtosis, entropy\n",
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "\n",
        "class PreProcessor:\n",
        "    def __init__(self):\n",
        "        self.dataFrame = pd.DataFrame()\n",
        "\n",
        "    def initializeDataFrame(self, filepath):\n",
        "\n",
        "        colNames = [\"timestamp\", \"activityID\", \"heartrate\"]\n",
        "\n",
        "        IMUhand = ['handTemperature',\n",
        "                   'handAcc16_1', 'handAcc16_2', 'handAcc16_3',\n",
        "                   'handAcc6_1', 'handAcc6_2', 'handAcc6_3',\n",
        "                   'handGyro1', 'handGyro2', 'handGyro3',\n",
        "                   'handMagne1', 'handMagne2', 'handMagne3',\n",
        "                   'handOrientation1', 'handOrientation2', 'handOrientation3', 'handOrientation4']\n",
        "\n",
        "        IMUchest = ['chestTemperature',\n",
        "                    'chestAcc16_1', 'chestAcc16_2', 'chestAcc16_3',\n",
        "                    'chestAcc6_1', 'chestAcc6_2', 'chestAcc6_3',\n",
        "                    'chestGyro1', 'chestGyro2', 'chestGyro3',\n",
        "                    'chestMagne1', 'chestMagne2', 'chestMagne3',\n",
        "                    'chestOrientation1', 'chestOrientation2', 'chestOrientation3', 'chestOrientation4']\n",
        "\n",
        "        IMUankle = ['ankleTemperature',\n",
        "                    'ankleAcc16_1', 'ankleAcc16_2', 'ankleAcc16_3',\n",
        "                    'ankleAcc6_1', 'ankleAcc6_2', 'ankleAcc6_3',\n",
        "                    'ankleGyro1', 'ankleGyro2', 'ankleGyro3',\n",
        "                    'ankleMagne1', 'ankleMagne2', 'ankleMagne3',\n",
        "                    'ankleOrientation1', 'ankleOrientation2', 'ankleOrientation3', 'ankleOrientation4']\n",
        "\n",
        "        columns = colNames + IMUhand + IMUchest + IMUankle  # All columns in one list\n",
        "\n",
        "        procData = pd.read_table(filepath, header=None, sep='\\s+')\n",
        "        procData.columns = columns\n",
        "        procData['subject_id'] = int(filepath[-5])\n",
        "        self.dataFrame = self.dataFrame._append(procData, ignore_index=True)\n",
        "        self.dataFrame.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    def dataCleaning(self):\n",
        "        self.dataFrame = self.dataFrame.drop(\n",
        "            ['handOrientation1', 'handOrientation2', 'handOrientation3', 'handOrientation4',\n",
        "             'chestOrientation1', 'chestOrientation2', 'chestOrientation3', 'chestOrientation4',\n",
        "             'ankleOrientation1', 'ankleOrientation2', 'ankleOrientation3', 'ankleOrientation4',\n",
        "             'handAcc6_1', 'handAcc6_2', 'handAcc6_3', 'chestAcc6_1', 'chestAcc6_2',\n",
        "             'chestAcc6_3', 'ankleAcc6_1', 'ankleAcc6_2', 'ankleAcc6_3'], axis=1)\n",
        "\n",
        "        self.dataFrame = self.dataFrame.drop(self.dataFrame[self.dataFrame.activityID == 0].index)\n",
        "        self.dataFrame = self.dataFrame.apply(pd.to_numeric, errors='ignore')\n",
        "        self.dataFrame = self.dataFrame.interpolate()\n",
        "\n",
        "    def applyPreProcessing(self):\n",
        "        self.dataFrame.reset_index(drop=True, inplace=True)\n",
        "        self.dataFrame.loc[:3, \"heartrate\"] = 100\n",
        "\n",
        "        checkForNan = self.dataFrame.isnull().values.any()\n",
        "        if checkForNan:\n",
        "            print(\"DataFrame still contains some NAN values\")\n",
        "\n",
        "    def getSubjectDf(self, subject_id):\n",
        "        return self.dataFrame[self.dataFrame['subject_id'] == subject_id]\n",
        "\n",
        "\n",
        "class FeatureExtraction1:\n",
        "    def __init__(self, subjectDf, subjectID):\n",
        "        self.dataFrame = subjectDf\n",
        "        self.subjectID = subjectID\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_time_domain_features(data, isheartrate=False):\n",
        "        mean = np.mean(data)\n",
        "        std_dev = np.std(data)\n",
        "\n",
        "        if not isheartrate:\n",
        "            skewness = skew(data, nan_policy='omit')\n",
        "            kurt = kurtosis(data, nan_policy='omit')\n",
        "            return mean, std_dev, skewness, kurt\n",
        "        else:\n",
        "            return mean, std_dev\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_frequency_domain_features(data, fs):\n",
        "        f, Pxx = welch(data, fs=fs, nperseg=len(data))\n",
        "        entropy_power = entropy(Pxx)\n",
        "        peak_power_freq = f[np.argmax(Pxx)]\n",
        "        return entropy_power, peak_power_freq\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_signal_magnitude_area(data):\n",
        "        return np.sum(np.abs(data))\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_pairwise_correlations(data):\n",
        "        correlations = pairwise_distances(data, metric='correlation')\n",
        "        return correlations\n",
        "\n",
        "    def sliding_window_feature_extraction(self, window_size=150, overlap=0, fs=100):\n",
        "\n",
        "        angular_velocity_columns = ['handGyro1', 'handGyro2', 'handGyro3',\n",
        "                                    'chestGyro1', 'chestGyro2', 'chestGyro3',\n",
        "                                    'ankleGyro1', 'ankleGyro2', 'ankleGyro3']\n",
        "        acceleration_columns = ['handAcc16_1', 'handAcc16_2', 'handAcc16_3',\n",
        "                                'chestAcc16_1', 'chestAcc16_2', 'chestAcc16_3',\n",
        "                                'ankleAcc16_1', 'ankleAcc16_2', 'ankleAcc16_3']\n",
        "\n",
        "        heart_rate_col = ['heartrate']\n",
        "        combined_columns = angular_velocity_columns + acceleration_columns\n",
        "\n",
        "        all_features = []\n",
        "        all_labels = []\n",
        "\n",
        "        stride = int(window_size * (1 - overlap))\n",
        "\n",
        "        for start in range(0, len(self.dataFrame) - window_size + 1, stride):\n",
        "            window_data_time = self.dataFrame.loc[start:start + window_size - 1, combined_columns + heart_rate_col]\n",
        "            labels = self.dataFrame.loc[start:start + window_size - 1, 'activityID']\n",
        "\n",
        "            # Ensure the window contains only one activity\n",
        "            if labels.nunique() == 1:\n",
        "                label = labels.iloc[0]\n",
        "\n",
        "                # Extract time-domain features\n",
        "                time_domain_features = []\n",
        "                for column in combined_columns:\n",
        "                    time_domain_features.extend(self.compute_time_domain_features(window_data_time[column]))\n",
        "                for column in heart_rate_col:\n",
        "                    time_domain_features.extend(self.compute_time_domain_features(window_data_time[column], True))\n",
        "\n",
        "                # Extract frequency-domain features\n",
        "                freq_domain_features = []\n",
        "                for column in combined_columns:\n",
        "                    freq_domain_features.extend(self.compute_frequency_domain_features(window_data_time[column], fs))\n",
        "\n",
        "                # Signal magnitude area\n",
        "                sma = [self.compute_signal_magnitude_area(window_data_time[column]) for column in combined_columns]\n",
        "\n",
        "                # Combine all features\n",
        "                features = np.concatenate([time_domain_features, freq_domain_features, sma])\n",
        "                all_features.append(features)\n",
        "                all_labels.append(label)\n",
        "\n",
        "        return np.array(all_features), np.array(all_labels)\n",
        "\n",
        "    def applyFeatureExtraction(self, window_size, overlap, fs):\n",
        "        features, labels = self.sliding_window_feature_extraction(window_size=window_size, overlap=overlap, fs=fs)\n",
        "        return features, labels\n",
        "\n",
        "# Usage example\n",
        "file_path = '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject101.dat'\n",
        "processor = PreProcessor()\n",
        "processor.initializeDataFrame(file_path)\n",
        "processor.dataCleaning()\n",
        "processor.applyPreProcessing()\n",
        "\n",
        "subject_id = 1\n",
        "subject_df = processor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "\n",
        "window_size = 150\n",
        "overlap = 0\n",
        "\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size, overlap, fs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAa1iKkxn-Wy",
        "outputId": "a765cd07-0193-4b3a-9b66-8bc2e1e47868"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model: RForest for subject 1\n",
            "Fold scores: {'accuracy': 0.9396551724137931, 'f1': 0.9404950503348672, 'precision': 0.9496202073788281, 'recall': 0.9396551724137931}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.86      0.92        14\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       0.82      1.00      0.90         9\n",
            "           4       1.00      0.82      0.90        11\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       0.90      1.00      0.95         9\n",
            "          12       0.88      0.88      0.88         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       1.00      1.00      1.00        11\n",
            "          17       0.77      1.00      0.87        10\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.94       116\n",
            "   macro avg       0.95      0.95      0.94       116\n",
            "weighted avg       0.95      0.94      0.94       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.8793103448275862, 'f1': 0.8821579462315557, 'precision': 0.9136079796640142, 'recall': 0.8793103448275862}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.86      0.92        14\n",
            "           2       1.00      0.64      0.78        11\n",
            "           3       0.56      1.00      0.72         9\n",
            "           4       1.00      0.90      0.95        10\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      0.73      0.84        11\n",
            "           7       0.88      0.78      0.82         9\n",
            "          12       0.80      1.00      0.89         8\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.85      1.00      0.92        11\n",
            "          17       0.83      1.00      0.91        10\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.88       116\n",
            "   macro avg       0.91      0.89      0.89       116\n",
            "weighted avg       0.91      0.88      0.88       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.9396551724137931, 'f1': 0.938984079388877, 'precision': 0.9466776040051903, 'recall': 0.9396551724137931}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      0.82      0.90        11\n",
            "           3       0.77      1.00      0.87        10\n",
            "           4       1.00      1.00      1.00        10\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00         9\n",
            "          12       0.86      0.75      0.80         8\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       0.92      1.00      0.96        11\n",
            "          17       0.82      0.90      0.86        10\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.94       116\n",
            "   macro avg       0.95      0.93      0.93       116\n",
            "weighted avg       0.95      0.94      0.94       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.9396551724137931, 'f1': 0.9397175852133358, 'precision': 0.9436476837338906, 'recall': 0.9396551724137931}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        11\n",
            "           3       1.00      1.00      1.00        10\n",
            "           4       1.00      0.90      0.95        10\n",
            "           5       0.90      0.82      0.86        11\n",
            "           6       0.92      1.00      0.96        11\n",
            "           7       1.00      1.00      1.00         9\n",
            "          12       0.78      0.88      0.82         8\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.83      0.91      0.87        11\n",
            "          17       0.91      1.00      0.95        10\n",
            "          24       1.00      0.80      0.89         5\n",
            "\n",
            "    accuracy                           0.94       116\n",
            "   macro avg       0.94      0.93      0.93       116\n",
            "weighted avg       0.94      0.94      0.94       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.896551724137931, 'f1': 0.8978528936693236, 'precision': 0.9095443349753695, 'recall': 0.896551724137931}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.85      0.92        13\n",
            "           2       1.00      0.91      0.95        11\n",
            "           3       0.90      0.90      0.90        10\n",
            "           4       0.90      0.90      0.90        10\n",
            "           5       1.00      0.80      0.89        10\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      0.89      0.94         9\n",
            "          12       0.86      0.75      0.80         8\n",
            "          13       0.75      0.86      0.80         7\n",
            "          16       0.73      1.00      0.85        11\n",
            "          17       0.83      1.00      0.91        10\n",
            "          24       0.83      0.83      0.83         6\n",
            "\n",
            "    accuracy                           0.90       116\n",
            "   macro avg       0.90      0.89      0.89       116\n",
            "weighted avg       0.91      0.90      0.90       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.9396551724137931, 'f1': 0.936952764219394, 'precision': 0.9457723789620343, 'recall': 0.9396551724137931}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        11\n",
            "           3       1.00      0.90      0.95        10\n",
            "           4       1.00      1.00      1.00        10\n",
            "           5       0.91      1.00      0.95        10\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      0.89      0.94         9\n",
            "          12       0.89      1.00      0.94         8\n",
            "          13       0.75      0.86      0.80         7\n",
            "          16       0.83      0.91      0.87        11\n",
            "          17       0.91      1.00      0.95        10\n",
            "          24       1.00      0.50      0.67         6\n",
            "\n",
            "    accuracy                           0.94       116\n",
            "   macro avg       0.94      0.92      0.92       116\n",
            "weighted avg       0.95      0.94      0.94       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.9482758620689655, 'f1': 0.9494808769704218, 'precision': 0.9581625271280444, 'recall': 0.9482758620689655}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.86      0.92        14\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       0.91      1.00      0.95        10\n",
            "           4       1.00      1.00      1.00        10\n",
            "           5       1.00      0.90      0.95        10\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      0.90      0.95        10\n",
            "          12       0.82      1.00      0.90         9\n",
            "          13       1.00      1.00      1.00         6\n",
            "          16       1.00      0.91      0.95        11\n",
            "          17       0.77      1.00      0.87        10\n",
            "          24       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.95       116\n",
            "   macro avg       0.96      0.96      0.95       116\n",
            "weighted avg       0.96      0.95      0.95       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.9130434782608695, 'f1': 0.912955952613698, 'precision': 0.9192912884217231, 'recall': 0.9130434782608695}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.86      0.92        14\n",
            "           2       0.90      0.90      0.90        10\n",
            "           3       0.77      1.00      0.87        10\n",
            "           4       1.00      0.90      0.95        10\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       0.90      0.90      0.90        10\n",
            "          12       0.75      0.75      0.75         8\n",
            "          13       0.86      1.00      0.92         6\n",
            "          16       0.92      1.00      0.96        11\n",
            "          17       1.00      0.90      0.95        10\n",
            "          24       0.80      0.67      0.73         6\n",
            "\n",
            "    accuracy                           0.91       115\n",
            "   macro avg       0.91      0.91      0.90       115\n",
            "weighted avg       0.92      0.91      0.91       115\n",
            "\n",
            "Fold scores: {'accuracy': 0.9565217391304348, 'f1': 0.956438023010035, 'precision': 0.9600037643515903, 'recall': 0.9565217391304348}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       1.00      1.00      1.00        10\n",
            "           4       1.00      0.90      0.95        10\n",
            "           5       0.91      1.00      0.95        10\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      0.89      0.94         9\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       0.86      1.00      0.92         6\n",
            "          16       0.92      1.00      0.96        11\n",
            "          17       0.92      1.00      0.96        11\n",
            "          24       0.83      0.83      0.83         6\n",
            "\n",
            "    accuracy                           0.96       115\n",
            "   macro avg       0.95      0.95      0.95       115\n",
            "weighted avg       0.96      0.96      0.96       115\n",
            "\n",
            "Fold scores: {'accuracy': 0.9391304347826087, 'f1': 0.9377293581253386, 'precision': 0.9422266139657443, 'recall': 0.9391304347826087}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.93      0.96        14\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       0.82      0.90      0.86        10\n",
            "           4       0.91      1.00      0.95        10\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       1.00      1.00      1.00         9\n",
            "          12       0.83      0.62      0.71         8\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.92      1.00      0.96        11\n",
            "          17       0.83      1.00      0.91        10\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.94       115\n",
            "   macro avg       0.94      0.93      0.94       115\n",
            "weighted avg       0.94      0.94      0.94       115\n",
            "\n",
            "Average validation scores: {'accuracy': 0.9291454272863569, 'f1': 0.9292764529776847, 'precision': 0.9388554382586427, 'recall': 0.9291454272863569}\n",
            "Test set scores: {'accuracy': 0.9475806451612904, 'f1': 0.9479888896112034, 'precision': 0.9515804764940711, 'recall': 0.9475806451612904}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.98      0.99        45\n",
            "           2       0.98      0.96      0.97        50\n",
            "           3       0.83      0.98      0.90        46\n",
            "           4       1.00      0.94      0.97        47\n",
            "           5       0.92      0.94      0.93        36\n",
            "           6       1.00      0.98      0.99        50\n",
            "           7       1.00      0.95      0.98        42\n",
            "          12       0.81      0.91      0.86        23\n",
            "          13       0.96      0.77      0.85        30\n",
            "          16       0.89      0.93      0.91        42\n",
            "          17       0.96      0.98      0.97        55\n",
            "          24       1.00      0.97      0.98        30\n",
            "\n",
            "    accuracy                           0.95       496\n",
            "   macro avg       0.95      0.94      0.94       496\n",
            "weighted avg       0.95      0.95      0.95       496\n",
            "\n",
            "   subject_id    model  val_accuracy    val_f1  val_precision  val_recall  \\\n",
            "0           1  RForest      0.929145  0.929276       0.938855    0.929145   \n",
            "\n",
            "   test_accuracy   test_f1  test_precision  test_recall  \n",
            "0       0.947581  0.947989         0.95158     0.947581  \n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, make_scorer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "class ModelEval:\n",
        "    def __init__(self, cv=5, n_splits=10):\n",
        "        self.models = []\n",
        "        self.metrics = []\n",
        "        self.subjectScores = {}\n",
        "        self.cv = cv\n",
        "        self.n_splits = n_splits\n",
        "\n",
        "    def add_model(self, model, name, param_grid=None):\n",
        "        \"\"\"Add a machine learning model for evaluation.\"\"\"\n",
        "        self.models.append((name, model, param_grid))\n",
        "\n",
        "    def add_metric(self, metric, name):\n",
        "        \"\"\"Add a metric for evaluation.\"\"\"\n",
        "        self.metrics.append((name, make_scorer(metric)))\n",
        "\n",
        "    def evaluate_subject(self, features, labels, subject_id):\n",
        "        \"\"\"Evaluate all models using nested cross-validation for a specific subject and store the results.\"\"\"\n",
        "        subject_results = {}\n",
        "        for name, model, param_grid in self.models:\n",
        "            print(f\"Evaluating model: {name} for subject {subject_id}\")\n",
        "            outer_scores, test_scores = self.nested_cross_validation(features, labels, model, param_grid)\n",
        "            subject_results[name] = {'validation_scores': outer_scores, 'test_scores': test_scores}\n",
        "        self.subjectScores[subject_id] = subject_results\n",
        "\n",
        "    def nested_cross_validation(self, features, labels, model, param_grid, test_size=0.3):\n",
        "        \"\"\"Perform nested cross-validation and return the evaluation scores.\"\"\"\n",
        "        X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=test_size, random_state=42)\n",
        "\n",
        "        outer_cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
        "        if param_grid:\n",
        "            clf = GridSearchCV(estimator=model, param_grid=param_grid, cv=self.cv, scoring='accuracy')\n",
        "        else:\n",
        "            clf = model\n",
        "\n",
        "        outer_scores = []\n",
        "\n",
        "        for train_index, val_index in outer_cv.split(X_train, y_train):\n",
        "            X_train_inner, X_val = X_train[train_index], X_train[val_index]\n",
        "            y_train_inner, y_val = y_train[train_index], y_train[val_index]\n",
        "\n",
        "            imputer = SimpleImputer(strategy='mean')\n",
        "            X_train_inner = imputer.fit_transform(X_train_inner)\n",
        "            X_val = imputer.transform(X_val)\n",
        "\n",
        "            scaler = RobustScaler().fit(X_train_inner)\n",
        "            X_train_inner = scaler.transform(X_train_inner)\n",
        "            X_val = scaler.transform(X_val)\n",
        "\n",
        "            if param_grid:\n",
        "                clf.fit(X_train_inner, y_train_inner)\n",
        "                best_model = clf.best_estimator_\n",
        "            else:\n",
        "                best_model = model\n",
        "                best_model.fit(X_train_inner, y_train_inner)\n",
        "\n",
        "            y_pred = best_model.predict(X_val)\n",
        "\n",
        "            scores = {\n",
        "                'accuracy': accuracy_score(y_val, y_pred),\n",
        "                'f1': f1_score(y_val, y_pred, average='weighted'),\n",
        "                'precision': precision_score(y_val, y_pred, average='weighted'),\n",
        "                'recall': recall_score(y_val, y_pred, average='weighted')\n",
        "            }\n",
        "\n",
        "            outer_scores.append(scores)\n",
        "\n",
        "            print(f\"Fold scores: {scores}\")\n",
        "            print(classification_report(y_val, y_pred, zero_division=0))\n",
        "\n",
        "        average_scores = {\n",
        "            'accuracy': np.mean([score['accuracy'] for score in outer_scores]),\n",
        "            'f1': np.mean([score['f1'] for score in outer_scores]),\n",
        "            'precision': np.mean([score['precision'] for score in outer_scores]),\n",
        "            'recall': np.mean([score['recall'] for score in outer_scores])\n",
        "        }\n",
        "        print(\"Average validation scores:\", average_scores)\n",
        "\n",
        "        # Final evaluation on the test set\n",
        "        imputer = SimpleImputer(strategy='mean')\n",
        "        X_train = imputer.fit_transform(X_train)\n",
        "        X_test = imputer.transform(X_test)\n",
        "\n",
        "        scaler = RobustScaler().fit(X_train)\n",
        "        X_train = scaler.transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "        if param_grid:\n",
        "            clf.fit(X_train, y_train)\n",
        "            best_model = clf.best_estimator_\n",
        "        else:\n",
        "            best_model = model\n",
        "            best_model.fit(X_train, y_train)\n",
        "\n",
        "        y_pred_test = best_model.predict(X_test)\n",
        "\n",
        "        test_scores = {\n",
        "            'accuracy': accuracy_score(y_test, y_pred_test),\n",
        "            'f1': f1_score(y_test, y_pred_test, average='weighted'),\n",
        "            'precision': precision_score(y_test, y_pred_test, average='weighted'),\n",
        "            'recall': recall_score(y_test, y_pred_test, average='weighted')\n",
        "        }\n",
        "\n",
        "        print(\"Test set scores:\", test_scores)\n",
        "        print(classification_report(y_test, y_pred_test, zero_division=0))\n",
        "\n",
        "        return average_scores, test_scores\n",
        "\n",
        "    def evaluate_all_subjects(self, subject_data):\n",
        "        \"\"\"Evaluate all models for all subjects.\"\"\"\n",
        "        for subject_id, (features, labels) in subject_data.items():\n",
        "            self.evaluate_subject(features, labels, subject_id)\n",
        "\n",
        "    def get_results_df(self):\n",
        "        \"\"\"Retrieve the results as a Pandas DataFrame.\"\"\"\n",
        "        results = []\n",
        "        for subject_id, models in self.subjectScores.items():\n",
        "            for model_name, scores in models.items():\n",
        "                result = {\n",
        "                    'subject_id': subject_id,\n",
        "                    'model': model_name,\n",
        "                    'val_accuracy': scores['validation_scores']['accuracy'],\n",
        "                    'val_f1': scores['validation_scores']['f1'],\n",
        "                    'val_precision': scores['validation_scores']['precision'],\n",
        "                    'val_recall': scores['validation_scores']['recall'],\n",
        "                    'test_accuracy': scores['test_scores']['accuracy'],\n",
        "                    'test_f1': scores['test_scores']['f1'],\n",
        "                    'test_precision': scores['test_scores']['precision'],\n",
        "                    'test_recall': scores['test_scores']['recall']\n",
        "                }\n",
        "                results.append(result)\n",
        "        return pd.DataFrame(results)\n",
        "\n",
        "    def report_results(self):\n",
        "        \"\"\"Print the evaluation results.\"\"\"\n",
        "        results_df = self.get_results_df()\n",
        "        print(results_df)\n",
        "        return results_df\n",
        "\n",
        "\n",
        "\n",
        "# Initialize the evaluator\n",
        "evaluator = ModelEval(cv=5, n_splits=10)\n",
        "\n",
        "evaluator.add_model(RandomForestClassifier(), \"RForest\", param_grid= {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10] } )\n",
        "\n",
        "\n",
        "# Add metrics\n",
        "evaluator.add_metric(accuracy_score, \"Accuracy\")\n",
        "evaluator.add_metric(f1_score, \"F1 Score\")\n",
        "evaluator.add_metric(precision_score, \"Precision\")\n",
        "evaluator.add_metric(recall_score, \"Recall\")\n",
        "\n",
        "# Generate features and labels for each subject using PreProcessor and FeatureExtraction\n",
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "file_path =  '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject101.dat'\n",
        "\n",
        "preprocessor.initializeDataFrame(file_path)\n",
        "preprocessor.dataCleaning()\n",
        "preprocessor.applyPreProcessing()\n",
        "\n",
        "subject_id = int(file_path[-5])\n",
        "subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvNGQ__WfWXc",
        "outputId": "a9c584d8-3e27-4d20-eaa6-f446440b80a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame still contains some NAN values\n",
            "Evaluating model: RForest for subject 2\n",
            "Fold scores: {'accuracy': 0.9180327868852459, 'f1': 0.9175064997072865, 'precision': 0.9319577508102098, 'recall': 0.9180327868852459}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       1.00      0.70      0.82        10\n",
            "           3       0.86      1.00      0.92        12\n",
            "           4       0.93      0.88      0.90        16\n",
            "           5       1.00      1.00      1.00         4\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       0.86      0.86      0.86         7\n",
            "          13       1.00      0.88      0.93         8\n",
            "          16       0.91      1.00      0.95        10\n",
            "          17       0.72      1.00      0.84        13\n",
            "          24       1.00      0.67      0.80         6\n",
            "\n",
            "    accuracy                           0.92       122\n",
            "   macro avg       0.94      0.91      0.92       122\n",
            "weighted avg       0.93      0.92      0.92       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9426229508196722, 'f1': 0.9436342719690434, 'precision': 0.9477459016393442, 'recall': 0.9426229508196722}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       0.92      0.92      0.92        12\n",
            "           4       0.93      0.93      0.93        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.88      1.00      0.93         7\n",
            "          13       1.00      1.00      1.00         8\n",
            "          16       0.75      0.90      0.82        10\n",
            "          17       0.92      0.92      0.92        13\n",
            "          24       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.94       122\n",
            "   macro avg       0.95      0.94      0.95       122\n",
            "weighted avg       0.95      0.94      0.94       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9344262295081968, 'f1': 0.9328464360538488, 'precision': 0.9465092284764416, 'recall': 0.9344262295081968}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.82      0.90      0.86        10\n",
            "           3       0.80      1.00      0.89        12\n",
            "           4       1.00      1.00      1.00        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      1.00      1.00        14\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       1.00      0.57      0.73         7\n",
            "          16       0.77      1.00      0.87        10\n",
            "          17       1.00      0.77      0.87        13\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.93       122\n",
            "   macro avg       0.95      0.93      0.93       122\n",
            "weighted avg       0.95      0.93      0.93       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9016393442622951, 'f1': 0.9036887003464781, 'precision': 0.9162594577553594, 'recall': 0.9016393442622951}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.80      0.80      0.80        10\n",
            "           3       0.85      0.92      0.88        12\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      0.92      0.96        12\n",
            "           7       1.00      0.93      0.96        14\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.77      1.00      0.87        10\n",
            "          17       0.69      0.85      0.76        13\n",
            "          24       1.00      0.60      0.75         5\n",
            "\n",
            "    accuracy                           0.90       122\n",
            "   macro avg       0.93      0.89      0.90       122\n",
            "weighted avg       0.92      0.90      0.90       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9344262295081968, 'f1': 0.9341920926884183, 'precision': 0.9389317990752417, 'recall': 0.9344262295081968}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.90      0.90      0.90        10\n",
            "           3       0.85      0.92      0.88        12\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      1.00      1.00        14\n",
            "          12       0.83      0.71      0.77         7\n",
            "          13       0.86      0.86      0.86         7\n",
            "          16       1.00      0.80      0.89        10\n",
            "          17       0.81      1.00      0.90        13\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.93       122\n",
            "   macro avg       0.94      0.93      0.93       122\n",
            "weighted avg       0.94      0.93      0.93       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9344262295081968, 'f1': 0.9348072528550451, 'precision': 0.94011544011544, 'recall': 0.9344262295081968}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.91      1.00      0.95        10\n",
            "           3       0.86      1.00      0.92        12\n",
            "           4       1.00      1.00      1.00        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      0.92      0.96        12\n",
            "           7       1.00      0.93      0.96        14\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       0.86      0.86      0.86         7\n",
            "          16       0.89      0.80      0.84        10\n",
            "          17       0.79      0.92      0.85        12\n",
            "          24       1.00      0.80      0.89         5\n",
            "\n",
            "    accuracy                           0.93       122\n",
            "   macro avg       0.94      0.92      0.93       122\n",
            "weighted avg       0.94      0.93      0.93       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9016393442622951, 'f1': 0.9033707372665906, 'precision': 0.9173041894353369, 'recall': 0.9016393442622951}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       0.67      0.80      0.73        10\n",
            "           3       0.91      0.91      0.91        11\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      0.80      0.89         5\n",
            "           6       1.00      0.83      0.91        12\n",
            "           7       1.00      1.00      1.00        14\n",
            "          12       0.89      1.00      0.94         8\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       0.83      1.00      0.91        10\n",
            "          17       0.73      0.92      0.81        12\n",
            "          24       1.00      0.80      0.89         5\n",
            "\n",
            "    accuracy                           0.90       122\n",
            "   macro avg       0.92      0.88      0.89       122\n",
            "weighted avg       0.92      0.90      0.90       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9508196721311475, 'f1': 0.9504413355793857, 'precision': 0.9617486338797814, 'recall': 0.9508196721311475}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       1.00      1.00      1.00        11\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      0.60      0.75         5\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      1.00      1.00        14\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.83      1.00      0.91        10\n",
            "          17       0.75      1.00      0.86        12\n",
            "          24       1.00      0.80      0.89         5\n",
            "\n",
            "    accuracy                           0.95       122\n",
            "   macro avg       0.97      0.93      0.94       122\n",
            "weighted avg       0.96      0.95      0.95       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9426229508196722, 'f1': 0.9430754552066027, 'precision': 0.9519966372425389, 'recall': 0.9426229508196722}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      0.80      0.89        10\n",
            "           3       0.73      1.00      0.85        11\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       0.92      1.00      0.96        12\n",
            "           7       1.00      0.93      0.96        14\n",
            "          12       1.00      0.75      0.86         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.89      0.89      0.89         9\n",
            "          17       0.92      0.92      0.92        12\n",
            "          24       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.94       122\n",
            "   macro avg       0.96      0.94      0.94       122\n",
            "weighted avg       0.95      0.94      0.94       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9338842975206612, 'f1': 0.9349582576963101, 'precision': 0.9461220597584235, 'recall': 0.9338842975206612}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.83      1.00      0.91        10\n",
            "           3       1.00      0.82      0.90        11\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      1.00      1.00         4\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.75      0.86         8\n",
            "          13       0.86      0.86      0.86         7\n",
            "          16       0.69      1.00      0.82         9\n",
            "          17       0.92      0.85      0.88        13\n",
            "          24       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.93       121\n",
            "   macro avg       0.94      0.93      0.93       121\n",
            "weighted avg       0.95      0.93      0.93       121\n",
            "\n",
            "Average validation scores: {'accuracy': 0.929454003522558, 'f1': 0.929852103936901, 'precision': 0.9398691098188117, 'recall': 0.929454003522558}\n",
            "Test set scores: {'accuracy': 0.9464627151051626, 'f1': 0.9467215273274722, 'precision': 0.9487289287300168, 'recall': 0.9464627151051626}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        36\n",
            "           2       0.93      0.88      0.90        48\n",
            "           3       0.96      0.96      0.96        53\n",
            "           4       1.00      0.98      0.99        61\n",
            "           5       1.00      1.00      1.00        13\n",
            "           6       0.98      1.00      0.99        48\n",
            "           7       0.98      0.92      0.95        60\n",
            "          12       0.97      0.89      0.93        38\n",
            "          13       0.81      0.93      0.87        28\n",
            "          16       0.86      0.95      0.90        39\n",
            "          17       0.91      0.97      0.94        66\n",
            "          24       0.94      0.88      0.91        33\n",
            "\n",
            "    accuracy                           0.95       523\n",
            "   macro avg       0.95      0.95      0.95       523\n",
            "weighted avg       0.95      0.95      0.95       523\n",
            "\n",
            "   subject_id    model  val_accuracy    val_f1  val_precision  val_recall  \\\n",
            "0           8  RForest      0.943111  0.942280       0.949996    0.943111   \n",
            "1           7  RForest      0.949836  0.949276       0.954357    0.949836   \n",
            "2           6  RForest      0.936904  0.937313       0.946165    0.936904   \n",
            "3           5  RForest      0.935033  0.934607       0.941313    0.935033   \n",
            "4           4  RForest      0.943034  0.943482       0.952851    0.943034   \n",
            "5           3  RForest      0.926790  0.926721       0.934324    0.926790   \n",
            "6           2  RForest      0.929454  0.929852       0.939869    0.929454   \n",
            "\n",
            "   test_accuracy   test_f1  test_precision  test_recall  \n",
            "0       0.948177  0.948347        0.951668     0.948177  \n",
            "1       0.952381  0.952562        0.956226     0.952381  \n",
            "2       0.951710  0.951473        0.953886     0.951710  \n",
            "3       0.922366  0.922756        0.926140     0.922366  \n",
            "4       0.956522  0.956858        0.960461     0.956522  \n",
            "5       0.953757  0.953535        0.956714     0.953757  \n",
            "6       0.946463  0.946722        0.948729     0.946463  \n"
          ]
        }
      ],
      "source": [
        "# Generate features and labels for each subject using PreProcessor and FeatureExtraction\n",
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "file_path =  '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject102.dat'\n",
        "\n",
        "preprocessor.initializeDataFrame(file_path)\n",
        "preprocessor.dataCleaning()\n",
        "preprocessor.applyPreProcessing()\n",
        "\n",
        "subject_id = int(file_path[-5])\n",
        "subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results_RF.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XNJR0KXfRQ_",
        "outputId": "19926cae-9144-491c-9294-d8615b8b32ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame still contains some NAN values\n",
            "Evaluating model: RForest for subject 3\n",
            "Fold scores: {'accuracy': 0.9382716049382716, 'f1': 0.9365980937870432, 'precision': 0.9450788751714678, 'recall': 0.9382716049382716}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        14\n",
            "           3       0.90      1.00      0.95         9\n",
            "           4       1.00      1.00      1.00        15\n",
            "          12       1.00      0.75      0.86         4\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       0.89      0.80      0.84        10\n",
            "          17       0.81      1.00      0.90        13\n",
            "\n",
            "    accuracy                           0.94        81\n",
            "   macro avg       0.95      0.91      0.92        81\n",
            "weighted avg       0.95      0.94      0.94        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.9135802469135802, 'f1': 0.9144573010557415, 'precision': 0.9276688453159041, 'recall': 0.9135802469135802}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.80      0.89        10\n",
            "           2       0.93      0.93      0.93        14\n",
            "           3       0.80      0.89      0.84         9\n",
            "           4       1.00      1.00      1.00        15\n",
            "          12       1.00      1.00      1.00         4\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       1.00      0.78      0.88         9\n",
            "          17       0.76      1.00      0.87        13\n",
            "\n",
            "    accuracy                           0.91        81\n",
            "   macro avg       0.94      0.91      0.92        81\n",
            "weighted avg       0.93      0.91      0.91        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.9012345679012346, 'f1': 0.9036283519255656, 'precision': 0.9143871540385703, 'recall': 0.9012345679012346}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.90      0.95        10\n",
            "           2       1.00      1.00      1.00        13\n",
            "           3       0.89      0.80      0.84        10\n",
            "           4       0.93      0.93      0.93        15\n",
            "          12       1.00      0.75      0.86         4\n",
            "          13       0.86      0.86      0.86         7\n",
            "          16       1.00      0.89      0.94         9\n",
            "          17       0.71      0.92      0.80        13\n",
            "\n",
            "    accuracy                           0.90        81\n",
            "   macro avg       0.92      0.88      0.90        81\n",
            "weighted avg       0.91      0.90      0.90        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.8888888888888888, 'f1': 0.8885326484936622, 'precision': 0.89680936347603, 'recall': 0.8888888888888888}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.90      0.95        10\n",
            "           2       1.00      0.92      0.96        13\n",
            "           3       0.82      1.00      0.90         9\n",
            "           4       1.00      0.87      0.93        15\n",
            "          12       0.80      1.00      0.89         4\n",
            "          13       0.71      0.62      0.67         8\n",
            "          16       0.82      1.00      0.90         9\n",
            "          17       0.85      0.85      0.85        13\n",
            "\n",
            "    accuracy                           0.89        81\n",
            "   macro avg       0.87      0.90      0.88        81\n",
            "weighted avg       0.90      0.89      0.89        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.9629629629629629, 'f1': 0.9628130154445945, 'precision': 0.9659611992945325, 'recall': 0.9629629629629629}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        10\n",
            "           2       1.00      1.00      1.00        13\n",
            "           3       1.00      1.00      1.00         9\n",
            "           4       1.00      1.00      1.00        15\n",
            "          12       1.00      0.80      0.89         5\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.90      1.00      0.95         9\n",
            "          17       0.86      0.92      0.89        13\n",
            "\n",
            "    accuracy                           0.96        81\n",
            "   macro avg       0.97      0.95      0.96        81\n",
            "weighted avg       0.97      0.96      0.96        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.9629629629629629, 'f1': 0.9628130154445945, 'precision': 0.9654320987654321, 'recall': 0.9629629629629629}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.90      0.95        10\n",
            "           2       1.00      1.00      1.00        13\n",
            "           3       0.90      1.00      0.95         9\n",
            "           4       1.00      1.00      1.00        15\n",
            "          12       1.00      1.00      1.00         5\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.90      1.00      0.95         9\n",
            "          17       0.92      0.92      0.92        13\n",
            "\n",
            "    accuracy                           0.96        81\n",
            "   macro avg       0.97      0.96      0.96        81\n",
            "weighted avg       0.97      0.96      0.96        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.9625, 'f1': 0.9612270955165692, 'precision': 0.9656043956043956, 'recall': 0.9625}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.80      0.89        10\n",
            "           2       0.93      1.00      0.96        13\n",
            "           3       1.00      1.00      1.00         9\n",
            "           4       1.00      1.00      1.00        15\n",
            "          12       1.00      0.80      0.89         5\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.90      1.00      0.95         9\n",
            "          17       0.92      1.00      0.96        12\n",
            "\n",
            "    accuracy                           0.96        80\n",
            "   macro avg       0.97      0.95      0.96        80\n",
            "weighted avg       0.97      0.96      0.96        80\n",
            "\n",
            "Fold scores: {'accuracy': 0.925, 'f1': 0.9240332296257886, 'precision': 0.936875, 'recall': 0.925}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        10\n",
            "           2       1.00      1.00      1.00        13\n",
            "           3       0.80      0.89      0.84         9\n",
            "           4       1.00      0.93      0.97        15\n",
            "          12       1.00      0.50      0.67         4\n",
            "          13       0.86      0.86      0.86         7\n",
            "          16       0.75      1.00      0.86         9\n",
            "          17       1.00      0.92      0.96        13\n",
            "\n",
            "    accuracy                           0.93        80\n",
            "   macro avg       0.93      0.89      0.89        80\n",
            "weighted avg       0.94      0.93      0.92        80\n",
            "\n",
            "Fold scores: {'accuracy': 0.875, 'f1': 0.8754166666666666, 'precision': 0.8818181818181818, 'recall': 0.875}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        10\n",
            "           2       1.00      1.00      1.00        13\n",
            "           3       0.67      0.67      0.67         9\n",
            "           4       1.00      1.00      1.00        15\n",
            "          12       0.75      0.75      0.75         4\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       0.73      0.89      0.80         9\n",
            "          17       0.77      0.77      0.77        13\n",
            "\n",
            "    accuracy                           0.88        80\n",
            "   macro avg       0.86      0.85      0.85        80\n",
            "weighted avg       0.88      0.88      0.88        80\n",
            "\n",
            "Fold scores: {'accuracy': 0.9375, 'f1': 0.9376906452236067, 'precision': 0.9436079545454545, 'recall': 0.9375}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.89      0.94         9\n",
            "           2       1.00      1.00      1.00        14\n",
            "           3       0.82      1.00      0.90         9\n",
            "           4       1.00      0.93      0.97        15\n",
            "          12       1.00      0.75      0.86         4\n",
            "          13       0.88      1.00      0.93         7\n",
            "          16       0.89      0.89      0.89         9\n",
            "          17       0.92      0.92      0.92        13\n",
            "\n",
            "    accuracy                           0.94        80\n",
            "   macro avg       0.94      0.92      0.93        80\n",
            "weighted avg       0.94      0.94      0.94        80\n",
            "\n",
            "Average validation scores: {'accuracy': 0.9267901234567901, 'f1': 0.9267210063183832, 'precision': 0.9343243068029968, 'recall': 0.9267901234567901}\n",
            "Test set scores: {'accuracy': 0.953757225433526, 'f1': 0.9535345337992138, 'precision': 0.9567141232775042, 'recall': 0.953757225433526}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.90      0.95        48\n",
            "           2       1.00      1.00      1.00        58\n",
            "           3       0.88      1.00      0.94        45\n",
            "           4       0.98      0.98      0.98        43\n",
            "          12       1.00      0.92      0.96        24\n",
            "          13       0.96      0.82      0.88        28\n",
            "          16       0.95      0.95      0.95        43\n",
            "          17       0.90      0.98      0.94        57\n",
            "\n",
            "    accuracy                           0.95       346\n",
            "   macro avg       0.96      0.94      0.95       346\n",
            "weighted avg       0.96      0.95      0.95       346\n",
            "\n",
            "   subject_id    model  val_accuracy    val_f1  val_precision  val_recall  \\\n",
            "0           8  RForest      0.943111  0.942280       0.949996    0.943111   \n",
            "1           7  RForest      0.949836  0.949276       0.954357    0.949836   \n",
            "2           6  RForest      0.936904  0.937313       0.946165    0.936904   \n",
            "3           5  RForest      0.935033  0.934607       0.941313    0.935033   \n",
            "4           4  RForest      0.943034  0.943482       0.952851    0.943034   \n",
            "5           3  RForest      0.926790  0.926721       0.934324    0.926790   \n",
            "\n",
            "   test_accuracy   test_f1  test_precision  test_recall  \n",
            "0       0.948177  0.948347        0.951668     0.948177  \n",
            "1       0.952381  0.952562        0.956226     0.952381  \n",
            "2       0.951710  0.951473        0.953886     0.951710  \n",
            "3       0.922366  0.922756        0.926140     0.922366  \n",
            "4       0.956522  0.956858        0.960461     0.956522  \n",
            "5       0.953757  0.953535        0.956714     0.953757  \n"
          ]
        }
      ],
      "source": [
        "# Generate features and labels for each subject using PreProcessor and FeatureExtraction\n",
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "file_path = '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject103.dat'\n",
        "\n",
        "preprocessor.initializeDataFrame(file_path)\n",
        "preprocessor.dataCleaning()\n",
        "preprocessor.applyPreProcessing()\n",
        "\n",
        "subject_id = int(file_path[-5])\n",
        "subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results_RF.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHuIsESvfUw0",
        "outputId": "a4944c9e-2e77-41e5-be46-0d1590401178"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame still contains some NAN values\n",
            "Evaluating model: RForest for subject 4\n",
            "Fold scores: {'accuracy': 0.9537037037037037, 'f1': 0.953834763673733, 'precision': 0.9590055006721673, 'recall': 0.9537037037037037}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.92      1.00      0.96        12\n",
            "           3       0.83      1.00      0.91        10\n",
            "           4       0.93      1.00      0.96        13\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.91      1.00      0.95        10\n",
            "          17       1.00      0.92      0.96        12\n",
            "\n",
            "    accuracy                           0.95       108\n",
            "   macro avg       0.96      0.95      0.95       108\n",
            "weighted avg       0.96      0.95      0.95       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9532710280373832, 'f1': 0.9540919538152912, 'precision': 0.9607796149852225, 'recall': 0.9532710280373832}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      0.83      0.91        12\n",
            "           3       0.77      1.00      0.87        10\n",
            "           4       1.00      0.92      0.96        13\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       0.89      1.00      0.94         8\n",
            "          13       1.00      1.00      1.00         6\n",
            "          16       1.00      0.90      0.95        10\n",
            "          17       0.92      0.92      0.92        12\n",
            "\n",
            "    accuracy                           0.95       107\n",
            "   macro avg       0.96      0.96      0.95       107\n",
            "weighted avg       0.96      0.95      0.95       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9626168224299065, 'f1': 0.9643361000370345, 'precision': 0.9732977303070761, 'recall': 0.9626168224299065}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       1.00      1.00      1.00        12\n",
            "           3       0.71      1.00      0.83        10\n",
            "           4       1.00      0.92      0.96        13\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       1.00      1.00      1.00        10\n",
            "          17       1.00      1.00      1.00        12\n",
            "\n",
            "    accuracy                           0.96       107\n",
            "   macro avg       0.97      0.96      0.96       107\n",
            "weighted avg       0.97      0.96      0.96       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9252336448598131, 'f1': 0.9256975112115299, 'precision': 0.9337085811384876, 'recall': 0.9252336448598131}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.83      0.83      0.83        12\n",
            "           3       0.82      0.90      0.86        10\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       1.00      0.82      0.90        11\n",
            "           7       1.00      0.85      0.92        13\n",
            "          12       0.88      1.00      0.93         7\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       1.00      1.00      1.00        10\n",
            "          17       0.80      1.00      0.89        12\n",
            "\n",
            "    accuracy                           0.93       107\n",
            "   macro avg       0.93      0.93      0.93       107\n",
            "weighted avg       0.93      0.93      0.93       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9532710280373832, 'f1': 0.95378022011098, 'precision': 0.9567157919961659, 'recall': 0.9532710280373832}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.91      0.95        11\n",
            "           2       1.00      0.92      0.96        12\n",
            "           3       0.83      0.91      0.87        11\n",
            "           4       1.00      0.93      0.96        14\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.88      1.00      0.93         7\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.90      0.90      0.90        10\n",
            "          17       0.92      1.00      0.96        12\n",
            "\n",
            "    accuracy                           0.95       107\n",
            "   macro avg       0.95      0.96      0.95       107\n",
            "weighted avg       0.96      0.95      0.95       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9813084112149533, 'f1': 0.9812300356743138, 'precision': 0.9828061346752935, 'recall': 0.9813084112149533}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.91      0.95        11\n",
            "           2       1.00      1.00      1.00        12\n",
            "           3       0.92      1.00      0.96        11\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       1.00      0.90      0.95        10\n",
            "          17       0.92      1.00      0.96        12\n",
            "\n",
            "    accuracy                           0.98       107\n",
            "   macro avg       0.98      0.98      0.98       107\n",
            "weighted avg       0.98      0.98      0.98       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9252336448598131, 'f1': 0.9254595352726193, 'precision': 0.947900367911363, 'recall': 0.9252336448598131}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.64      0.78        11\n",
            "           2       1.00      0.83      0.91        12\n",
            "           3       0.65      1.00      0.79        11\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       0.85      1.00      0.92        11\n",
            "          17       1.00      1.00      1.00        12\n",
            "\n",
            "    accuracy                           0.93       107\n",
            "   macro avg       0.95      0.92      0.92       107\n",
            "weighted avg       0.95      0.93      0.93       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9065420560747663, 'f1': 0.9054678079250887, 'precision': 0.9165109034267912, 'recall': 0.9065420560747663}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        11\n",
            "           2       0.92      0.92      0.92        12\n",
            "           3       0.83      0.91      0.87        11\n",
            "           4       0.92      0.92      0.92        13\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.62      0.77         8\n",
            "          13       0.83      0.71      0.77         7\n",
            "          16       0.91      0.91      0.91        11\n",
            "          17       0.73      1.00      0.85        11\n",
            "\n",
            "    accuracy                           0.91       107\n",
            "   macro avg       0.91      0.89      0.90       107\n",
            "weighted avg       0.92      0.91      0.91       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9065420560747663, 'f1': 0.9081811922093252, 'precision': 0.9291648123423824, 'recall': 0.9065420560747663}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      0.92      0.96        12\n",
            "           3       0.79      1.00      0.88        11\n",
            "           4       1.00      0.92      0.96        13\n",
            "           6       1.00      0.70      0.82        10\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       0.78      1.00      0.88         7\n",
            "          16       1.00      0.70      0.82        10\n",
            "          17       0.67      0.91      0.77        11\n",
            "\n",
            "    accuracy                           0.91       107\n",
            "   macro avg       0.92      0.91      0.90       107\n",
            "weighted avg       0.93      0.91      0.91       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9626168224299065, 'f1': 0.962741433021807, 'precision': 0.9686248331108144, 'recall': 0.9626168224299065}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      1.00      1.00        12\n",
            "           3       0.79      1.00      0.88        11\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.75      0.86         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.90      0.90      0.90        10\n",
            "          17       1.00      0.91      0.95        11\n",
            "\n",
            "    accuracy                           0.96       107\n",
            "   macro avg       0.97      0.96      0.96       107\n",
            "weighted avg       0.97      0.96      0.96       107\n",
            "\n",
            "Average validation scores: {'accuracy': 0.9430339217722394, 'f1': 0.9434820552951722, 'precision': 0.9528514270565763, 'recall': 0.9430339217722394}\n",
            "Test set scores: {'accuracy': 0.9565217391304348, 'f1': 0.9568583942961154, 'precision': 0.9604613111785358, 'recall': 0.9565217391304348}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        37\n",
            "           2       1.00      0.98      0.99        49\n",
            "           3       0.85      1.00      0.92        58\n",
            "           4       1.00      0.96      0.98        80\n",
            "           6       1.00      0.95      0.98        44\n",
            "           7       1.00      1.00      1.00        56\n",
            "          12       0.86      0.94      0.90        32\n",
            "          13       1.00      0.80      0.89        25\n",
            "          16       0.90      0.90      0.90        31\n",
            "          17       0.96      0.92      0.94        48\n",
            "\n",
            "    accuracy                           0.96       460\n",
            "   macro avg       0.96      0.95      0.95       460\n",
            "weighted avg       0.96      0.96      0.96       460\n",
            "\n",
            "   subject_id    model  val_accuracy    val_f1  val_precision  val_recall  \\\n",
            "0           8  RForest      0.943111  0.942280       0.949996    0.943111   \n",
            "1           7  RForest      0.949836  0.949276       0.954357    0.949836   \n",
            "2           6  RForest      0.936904  0.937313       0.946165    0.936904   \n",
            "3           5  RForest      0.935033  0.934607       0.941313    0.935033   \n",
            "4           4  RForest      0.943034  0.943482       0.952851    0.943034   \n",
            "\n",
            "   test_accuracy   test_f1  test_precision  test_recall  \n",
            "0       0.948177  0.948347        0.951668     0.948177  \n",
            "1       0.952381  0.952562        0.956226     0.952381  \n",
            "2       0.951710  0.951473        0.953886     0.951710  \n",
            "3       0.922366  0.922756        0.926140     0.922366  \n",
            "4       0.956522  0.956858        0.960461     0.956522  \n"
          ]
        }
      ],
      "source": [
        "# Generate features and labels for each subject using PreProcessor and FeatureExtraction\n",
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "file_path = '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject104.dat'\n",
        "\n",
        "preprocessor.initializeDataFrame(file_path)\n",
        "preprocessor.dataCleaning()\n",
        "preprocessor.applyPreProcessing()\n",
        "\n",
        "subject_id = int(file_path[-5])\n",
        "subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results_RF.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-8hwS3ofY8Y",
        "outputId": "9d5489d9-8b89-4bfc-d44f-0562c2d1db77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame still contains some NAN values\n",
            "Evaluating model: RForest for subject 5\n",
            "Fold scores: {'accuracy': 0.905511811023622, 'f1': 0.9068624452333991, 'precision': 0.9156269692687015, 'recall': 0.905511811023622}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.92      1.00      0.96        12\n",
            "           3       0.67      0.80      0.73        10\n",
            "           4       0.94      1.00      0.97        15\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      0.83      0.91        12\n",
            "          12       0.88      1.00      0.93         7\n",
            "          13       1.00      0.83      0.91         6\n",
            "          16       0.91      0.83      0.87        12\n",
            "          17       0.78      0.88      0.82        16\n",
            "          24       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.91       127\n",
            "   macro avg       0.92      0.89      0.90       127\n",
            "weighted avg       0.92      0.91      0.91       127\n",
            "\n",
            "Fold scores: {'accuracy': 0.952755905511811, 'f1': 0.9514445084903721, 'precision': 0.9569920487880191, 'recall': 0.952755905511811}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      0.92      0.96        13\n",
            "           3       0.83      1.00      0.91        10\n",
            "           4       0.94      1.00      0.97        15\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       0.92      1.00      0.96        11\n",
            "           7       1.00      1.00      1.00        11\n",
            "          12       1.00      0.71      0.83         7\n",
            "          13       1.00      1.00      1.00         6\n",
            "          16       0.92      0.92      0.92        12\n",
            "          17       0.94      1.00      0.97        16\n",
            "          24       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.95       127\n",
            "   macro avg       0.96      0.93      0.94       127\n",
            "weighted avg       0.96      0.95      0.95       127\n",
            "\n",
            "Fold scores: {'accuracy': 0.9126984126984127, 'f1': 0.9129587139153786, 'precision': 0.9197278911564626, 'recall': 0.9126984126984127}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       1.00      0.92      0.96        12\n",
            "           3       0.67      0.67      0.67         9\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       0.92      0.92      0.92        12\n",
            "           7       1.00      0.91      0.95        11\n",
            "          12       1.00      0.83      0.91         6\n",
            "          13       0.80      0.67      0.73         6\n",
            "          16       0.86      1.00      0.92        12\n",
            "          17       0.80      1.00      0.89        16\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.91       126\n",
            "   macro avg       0.92      0.90      0.91       126\n",
            "weighted avg       0.92      0.91      0.91       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.9285714285714286, 'f1': 0.9277093584667476, 'precision': 0.9320765343174305, 'recall': 0.9285714285714286}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        13\n",
            "           2       0.86      1.00      0.92        12\n",
            "           3       0.80      0.80      0.80        10\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      1.00      1.00        11\n",
            "          12       1.00      0.83      0.91         6\n",
            "          13       0.86      1.00      0.92         6\n",
            "          16       0.89      0.73      0.80        11\n",
            "          17       0.88      1.00      0.94        15\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.93       126\n",
            "   macro avg       0.93      0.93      0.93       126\n",
            "weighted avg       0.93      0.93      0.93       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.9761904761904762, 'f1': 0.975647241057295, 'precision': 0.9779583842083842, 'recall': 0.9761904761904762}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       0.92      1.00      0.96        12\n",
            "           3       1.00      0.90      0.95        10\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       0.92      1.00      0.96        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       1.00      0.82      0.90        11\n",
            "          17       0.94      1.00      0.97        15\n",
            "          24       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.98       126\n",
            "   macro avg       0.98      0.98      0.98       126\n",
            "weighted avg       0.98      0.98      0.98       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.9523809523809523, 'f1': 0.9522281199170434, 'precision': 0.9575080032012805, 'recall': 0.9523809523809523}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       1.00      0.92      0.96        12\n",
            "           3       0.90      0.90      0.90        10\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.88      1.00      0.93         7\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       0.86      1.00      0.92        12\n",
            "          17       0.88      1.00      0.94        15\n",
            "          24       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.95       126\n",
            "   macro avg       0.96      0.95      0.95       126\n",
            "weighted avg       0.96      0.95      0.95       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.9285714285714286, 'f1': 0.9263158628528575, 'precision': 0.9425964830376595, 'recall': 0.9285714285714286}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       1.00      0.92      0.96        12\n",
            "           3       0.83      1.00      0.91        10\n",
            "           4       0.94      1.00      0.97        16\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.88      1.00      0.93         7\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       1.00      0.58      0.74        12\n",
            "          17       0.75      1.00      0.86        15\n",
            "          24       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.93       126\n",
            "   macro avg       0.95      0.93      0.93       126\n",
            "weighted avg       0.94      0.93      0.93       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.9365079365079365, 'f1': 0.936242204158937, 'precision': 0.941917044595616, 'recall': 0.9365079365079365}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        12\n",
            "           2       0.86      1.00      0.92        12\n",
            "           3       0.83      1.00      0.91        10\n",
            "           4       1.00      0.81      0.90        16\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       0.80      0.80      0.80         5\n",
            "          16       0.92      0.92      0.92        12\n",
            "          17       0.94      1.00      0.97        15\n",
            "          24       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.94       126\n",
            "   macro avg       0.94      0.93      0.93       126\n",
            "weighted avg       0.94      0.94      0.94       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.9523809523809523, 'f1': 0.95248037906423, 'precision': 0.9599740537240538, 'recall': 0.9523809523809523}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       1.00      0.92      0.96        12\n",
            "           3       0.77      1.00      0.87        10\n",
            "           4       1.00      0.94      0.97        16\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.88      1.00      0.93         7\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       0.92      1.00      0.96        12\n",
            "          17       0.94      1.00      0.97        15\n",
            "          24       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.95       126\n",
            "   macro avg       0.96      0.94      0.94       126\n",
            "weighted avg       0.96      0.95      0.95       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.9047619047619048, 'f1': 0.9041860615693514, 'precision': 0.9087532837532837, 'recall': 0.9047619047619048}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.91      0.83      0.87        12\n",
            "           3       0.77      1.00      0.87        10\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       0.92      1.00      0.96        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       0.75      0.60      0.67         5\n",
            "          16       0.82      0.75      0.78        12\n",
            "          17       0.75      0.80      0.77        15\n",
            "          24       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.90       126\n",
            "   macro avg       0.91      0.90      0.90       126\n",
            "weighted avg       0.91      0.90      0.90       126\n",
            "\n",
            "Average validation scores: {'accuracy': 0.9350331208598925, 'f1': 0.9346074894725612, 'precision': 0.9413130696050891, 'recall': 0.9350331208598925}\n",
            "Test set scores: {'accuracy': 0.922365988909427, 'f1': 0.9227562933849418, 'precision': 0.9261399876589139, 'recall': 0.922365988909427}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.95      1.00      0.97        35\n",
            "           2       0.88      0.91      0.90        58\n",
            "           3       0.80      0.79      0.80        47\n",
            "           4       1.00      0.95      0.97        57\n",
            "           5       1.00      0.94      0.97        53\n",
            "           6       0.96      0.98      0.97        51\n",
            "           7       1.00      0.96      0.98        57\n",
            "          12       0.95      0.84      0.89        25\n",
            "          13       0.96      0.83      0.89        29\n",
            "          16       0.86      0.86      0.86        44\n",
            "          17       0.82      0.97      0.89        66\n",
            "          24       1.00      0.95      0.97        19\n",
            "\n",
            "    accuracy                           0.92       541\n",
            "   macro avg       0.93      0.92      0.92       541\n",
            "weighted avg       0.93      0.92      0.92       541\n",
            "\n",
            "   subject_id    model  val_accuracy    val_f1  val_precision  val_recall  \\\n",
            "0           8  RForest      0.943111  0.942280       0.949996    0.943111   \n",
            "1           7  RForest      0.949836  0.949276       0.954357    0.949836   \n",
            "2           6  RForest      0.936904  0.937313       0.946165    0.936904   \n",
            "3           5  RForest      0.935033  0.934607       0.941313    0.935033   \n",
            "\n",
            "   test_accuracy   test_f1  test_precision  test_recall  \n",
            "0       0.948177  0.948347        0.951668     0.948177  \n",
            "1       0.952381  0.952562        0.956226     0.952381  \n",
            "2       0.951710  0.951473        0.953886     0.951710  \n",
            "3       0.922366  0.922756        0.926140     0.922366  \n"
          ]
        }
      ],
      "source": [
        "# Generate features and labels for each subject using PreProcessor and FeatureExtraction\n",
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "file_path = '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject105.dat'\n",
        "\n",
        "preprocessor.initializeDataFrame(file_path)\n",
        "preprocessor.dataCleaning()\n",
        "preprocessor.applyPreProcessing()\n",
        "\n",
        "subject_id = int(file_path[-5])\n",
        "subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results_RF.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJD4oHw1fd8M",
        "outputId": "5638cc25-333f-4648-d496-44869312c5cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame still contains some NAN values\n",
            "Evaluating model: RForest for subject 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.9310344827586207, 'f1': 0.9327641270472486, 'precision': 0.9488146551724138, 'recall': 0.9310344827586207}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.91      0.95        11\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       0.69      1.00      0.81        11\n",
            "           4       1.00      1.00      1.00        12\n",
            "           5       1.00      0.67      0.80         9\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       0.75      0.90      0.82        10\n",
            "          17       1.00      1.00      1.00        17\n",
            "\n",
            "    accuracy                           0.93       116\n",
            "   macro avg       0.95      0.91      0.92       116\n",
            "weighted avg       0.95      0.93      0.93       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.9568965517241379, 'f1': 0.9571335666753088, 'precision': 0.9608116978806635, 'recall': 0.9568965517241379}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.91      0.95        11\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       0.85      1.00      0.92        11\n",
            "           4       1.00      1.00      1.00        12\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       1.00      1.00      1.00         6\n",
            "          13       0.80      0.80      0.80         5\n",
            "          16       0.91      1.00      0.95        10\n",
            "          17       0.94      1.00      0.97        17\n",
            "\n",
            "    accuracy                           0.96       116\n",
            "   macro avg       0.95      0.95      0.95       116\n",
            "weighted avg       0.96      0.96      0.96       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.9482758620689655, 'f1': 0.9484398778054581, 'precision': 0.9558114299493611, 'recall': 0.9482758620689655}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.82      0.90      0.86        10\n",
            "           3       0.91      0.91      0.91        11\n",
            "           4       1.00      1.00      1.00        12\n",
            "           5       1.00      0.90      0.95        10\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      0.67      0.80         6\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       0.77      1.00      0.87        10\n",
            "          17       1.00      1.00      1.00        17\n",
            "\n",
            "    accuracy                           0.95       116\n",
            "   macro avg       0.95      0.94      0.94       116\n",
            "weighted avg       0.96      0.95      0.95       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.9482758620689655, 'f1': 0.9476716025104331, 'precision': 0.9566912972085385, 'recall': 0.9482758620689655}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       1.00      1.00      1.00        11\n",
            "           3       0.79      1.00      0.88        11\n",
            "           4       0.91      0.91      0.91        11\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      0.83      0.91         6\n",
            "          13       1.00      0.60      0.75         5\n",
            "          16       0.83      1.00      0.91        10\n",
            "          17       1.00      1.00      1.00        17\n",
            "\n",
            "    accuracy                           0.95       116\n",
            "   macro avg       0.96      0.92      0.93       116\n",
            "weighted avg       0.96      0.95      0.95       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.9396551724137931, 'f1': 0.9411906600812149, 'precision': 0.9474715393499422, 'recall': 0.9396551724137931}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       1.00      0.91      0.95        11\n",
            "           3       1.00      0.91      0.95        11\n",
            "           4       1.00      1.00      1.00        11\n",
            "           5       0.91      1.00      0.95        10\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      0.83      0.91         6\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       0.75      0.90      0.82        10\n",
            "          17       0.84      0.94      0.89        17\n",
            "\n",
            "    accuracy                           0.94       116\n",
            "   macro avg       0.95      0.94      0.94       116\n",
            "weighted avg       0.95      0.94      0.94       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.9310344827586207, 'f1': 0.9328820614755278, 'precision': 0.9420124894262826, 'recall': 0.9310344827586207}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      0.91      0.95        11\n",
            "           3       0.64      0.82      0.72        11\n",
            "           4       1.00      1.00      1.00        11\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      0.71      0.83         7\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       0.91      1.00      0.95        10\n",
            "          17       0.89      0.94      0.91        17\n",
            "\n",
            "    accuracy                           0.93       116\n",
            "   macro avg       0.95      0.92      0.93       116\n",
            "weighted avg       0.94      0.93      0.93       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.9051724137931034, 'f1': 0.9040621142968557, 'precision': 0.9095202398800599, 'recall': 0.9051724137931034}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       0.73      0.73      0.73        11\n",
            "           4       1.00      1.00      1.00        11\n",
            "           5       1.00      0.90      0.95        10\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       0.80      0.89      0.84         9\n",
            "          17       0.74      0.94      0.83        18\n",
            "          24       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.91       116\n",
            "   macro avg       0.86      0.84      0.84       116\n",
            "weighted avg       0.91      0.91      0.90       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.9391304347826087, 'f1': 0.9398836135536041, 'precision': 0.9493727444578106, 'recall': 0.9391304347826087}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       1.00      0.82      0.90        11\n",
            "           4       1.00      1.00      1.00        11\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       0.91      1.00      0.95        10\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       0.89      0.89      0.89         9\n",
            "          17       0.78      1.00      0.88        18\n",
            "\n",
            "    accuracy                           0.94       115\n",
            "   macro avg       0.96      0.93      0.94       115\n",
            "weighted avg       0.95      0.94      0.94       115\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.9652173913043478, 'f1': 0.9642257818459191, 'precision': 0.9669565217391305, 'recall': 0.9652173913043478}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       0.82      0.82      0.82        11\n",
            "           4       1.00      1.00      1.00        11\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      0.71      0.83         7\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       1.00      1.00      1.00         9\n",
            "          17       0.90      1.00      0.95        18\n",
            "\n",
            "    accuracy                           0.97       115\n",
            "   macro avg       0.97      0.96      0.96       115\n",
            "weighted avg       0.97      0.97      0.96       115\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.9043478260869565, 'f1': 0.9048758282784749, 'precision': 0.9241895499618612, 'recall': 0.9043478260869565}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      0.80      0.89        10\n",
            "           3       0.69      1.00      0.81        11\n",
            "           4       1.00      0.64      0.78        11\n",
            "           5       0.89      0.89      0.89         9\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       0.67      1.00      0.80         4\n",
            "          16       0.90      0.90      0.90        10\n",
            "          17       0.95      1.00      0.97        18\n",
            "\n",
            "    accuracy                           0.90       115\n",
            "   macro avg       0.91      0.90      0.89       115\n",
            "weighted avg       0.92      0.90      0.90       115\n",
            "\n",
            "Average validation scores: {'accuracy': 0.936904047976012, 'f1': 0.9373129233570046, 'precision': 0.9461652165026063, 'recall': 0.936904047976012}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set scores: {'accuracy': 0.9517102615694165, 'f1': 0.9514726733966044, 'precision': 0.9538858017488421, 'recall': 0.9517102615694165}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        37\n",
            "           2       0.98      0.98      0.98        50\n",
            "           3       0.90      0.88      0.89        51\n",
            "           4       0.98      0.98      0.98        57\n",
            "           5       1.00      0.94      0.97        53\n",
            "           6       1.00      1.00      1.00        30\n",
            "           7       1.00      0.96      0.98        55\n",
            "          12       0.85      0.81      0.83        21\n",
            "          13       1.00      0.79      0.88        24\n",
            "          16       0.91      0.95      0.93        42\n",
            "          17       0.89      1.00      0.94        77\n",
            "\n",
            "    accuracy                           0.95       497\n",
            "   macro avg       0.96      0.94      0.94       497\n",
            "weighted avg       0.95      0.95      0.95       497\n",
            "\n",
            "   subject_id    model  val_accuracy    val_f1  val_precision  val_recall  \\\n",
            "0           8  RForest      0.943111  0.942280       0.949996    0.943111   \n",
            "1           7  RForest      0.949836  0.949276       0.954357    0.949836   \n",
            "2           6  RForest      0.936904  0.937313       0.946165    0.936904   \n",
            "\n",
            "   test_accuracy   test_f1  test_precision  test_recall  \n",
            "0       0.948177  0.948347        0.951668     0.948177  \n",
            "1       0.952381  0.952562        0.956226     0.952381  \n",
            "2       0.951710  0.951473        0.953886     0.951710  \n"
          ]
        }
      ],
      "source": [
        "# Generate features and labels for each subject using PreProcessor and FeatureExtraction\n",
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "file_path = '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject106.dat'\n",
        "\n",
        "preprocessor.initializeDataFrame(file_path)\n",
        "preprocessor.dataCleaning()\n",
        "preprocessor.applyPreProcessing()\n",
        "\n",
        "subject_id = int(file_path[-5])\n",
        "subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results_RF.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcyBPE3YfgyE",
        "outputId": "8241237d-c077-4ae8-86cc-23790b65c158"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame still contains some NAN values\n",
            "Evaluating model: RForest for subject 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.9166666666666666, 'f1': 0.912323426519333, 'precision': 0.9132069999717058, 'recall': 0.9166666666666666}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       0.80      0.80      0.80         5\n",
            "           3       0.86      1.00      0.92        12\n",
            "           4       0.94      1.00      0.97        16\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      0.85      0.92        13\n",
            "          12       0.90      1.00      0.95         9\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       0.82      0.90      0.86        10\n",
            "          17       0.85      0.85      0.85        13\n",
            "\n",
            "    accuracy                           0.92       108\n",
            "   macro avg       0.83      0.83      0.83       108\n",
            "weighted avg       0.91      0.92      0.91       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9629629629629629, 'f1': 0.9631054131054131, 'precision': 0.9649979649979651, 'recall': 0.9629629629629629}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      1.00      1.00         5\n",
            "           3       0.92      1.00      0.96        12\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.86      0.75      0.80         8\n",
            "          13       0.71      0.83      0.77         6\n",
            "          16       1.00      1.00      1.00        11\n",
            "          17       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           0.96       108\n",
            "   macro avg       0.95      0.96      0.95       108\n",
            "weighted avg       0.96      0.96      0.96       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9629629629629629, 'f1': 0.9618244321259749, 'precision': 0.9662037037037037, 'recall': 0.9629629629629629}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      0.67      0.80         6\n",
            "           3       0.92      1.00      0.96        11\n",
            "           4       1.00      0.94      0.97        16\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       0.83      0.83      0.83         6\n",
            "          16       1.00      1.00      1.00        11\n",
            "          17       0.87      1.00      0.93        13\n",
            "\n",
            "    accuracy                           0.96       108\n",
            "   macro avg       0.97      0.95      0.95       108\n",
            "weighted avg       0.97      0.96      0.96       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9629629629629629, 'f1': 0.9628790996383588, 'precision': 0.967244946411613, 'recall': 0.9629629629629629}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       1.00      0.83      0.91         6\n",
            "           3       0.85      1.00      0.92        11\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.83      0.91         6\n",
            "          16       0.92      1.00      0.96        11\n",
            "          17       0.93      1.00      0.96        13\n",
            "\n",
            "    accuracy                           0.96       108\n",
            "   macro avg       0.97      0.96      0.96       108\n",
            "weighted avg       0.97      0.96      0.96       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9537037037037037, 'f1': 0.9547334455667789, 'precision': 0.9625050875050875, 'recall': 0.9537037037037037}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       1.00      1.00      1.00         6\n",
            "           3       0.79      1.00      0.88        11\n",
            "           4       1.00      0.88      0.93        16\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.83      0.91         6\n",
            "          16       0.85      1.00      0.92        11\n",
            "          17       1.00      0.92      0.96        13\n",
            "\n",
            "    accuracy                           0.95       108\n",
            "   macro avg       0.97      0.96      0.96       108\n",
            "weighted avg       0.96      0.95      0.95       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9537037037037037, 'f1': 0.9536372853603127, 'precision': 0.9587572920906254, 'recall': 0.9537037037037037}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.85      0.92        13\n",
            "           2       1.00      0.83      0.91         6\n",
            "           3       0.85      1.00      0.92        11\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.83      0.91         6\n",
            "          16       0.83      0.91      0.87        11\n",
            "          17       0.93      1.00      0.96        13\n",
            "\n",
            "    accuracy                           0.95       108\n",
            "   macro avg       0.96      0.95      0.95       108\n",
            "weighted avg       0.96      0.95      0.95       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9629629629629629, 'f1': 0.9637869549530654, 'precision': 0.9678537511870844, 'recall': 0.9629629629629629}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      0.83      0.91         6\n",
            "           3       0.77      0.91      0.83        11\n",
            "           4       1.00      0.94      0.97        16\n",
            "           5       1.00      1.00      1.00         2\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       1.00      1.00      1.00        10\n",
            "          17       0.93      1.00      0.97        14\n",
            "\n",
            "    accuracy                           0.96       108\n",
            "   macro avg       0.97      0.96      0.96       108\n",
            "weighted avg       0.97      0.96      0.96       108\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.9065420560747663, 'f1': 0.904523091045811, 'precision': 0.9158878504672897, 'recall': 0.9065420560747663}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       1.00      0.83      0.91         6\n",
            "           3       0.67      1.00      0.80        12\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       1.00      0.82      0.90        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       0.75      0.60      0.67         5\n",
            "          16       0.90      0.90      0.90        10\n",
            "          17       0.88      1.00      0.93        14\n",
            "\n",
            "    accuracy                           0.91       107\n",
            "   macro avg       0.84      0.81      0.82       107\n",
            "weighted avg       0.92      0.91      0.90       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9345794392523364, 'f1': 0.9342633560746961, 'precision': 0.9429313158285121, 'recall': 0.9345794392523364}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       1.00      1.00      1.00         6\n",
            "           3       0.80      1.00      0.89        12\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.78      0.88      0.82         8\n",
            "          13       1.00      0.60      0.75         5\n",
            "          16       1.00      1.00      1.00        10\n",
            "          17       0.93      1.00      0.96        13\n",
            "\n",
            "    accuracy                           0.93       107\n",
            "   macro avg       0.95      0.92      0.93       107\n",
            "weighted avg       0.94      0.93      0.93       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9813084112149533, 'f1': 0.9816792682019881, 'precision': 0.9839786381842456, 'recall': 0.9813084112149533}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00         6\n",
            "           3       0.86      1.00      0.92        12\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       1.00      1.00      1.00        10\n",
            "          17       1.00      0.92      0.96        13\n",
            "\n",
            "    accuracy                           0.98       107\n",
            "   macro avg       0.99      0.99      0.99       107\n",
            "weighted avg       0.98      0.98      0.98       107\n",
            "\n",
            "Average validation scores: {'accuracy': 0.9498355832467983, 'f1': 0.9492755772591732, 'precision': 0.9543567550347831, 'recall': 0.9498355832467983}\n",
            "Test set scores: {'accuracy': 0.9523809523809523, 'f1': 0.9525619887815046, 'precision': 0.9562255368575837, 'recall': 0.9523809523809523}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.98      0.99        41\n",
            "           2       1.00      0.91      0.95        23\n",
            "           3       0.84      1.00      0.91        56\n",
            "           4       1.00      1.00      1.00        67\n",
            "           5       1.00      0.75      0.86        12\n",
            "           6       1.00      1.00      1.00        40\n",
            "           7       1.00      0.99      0.99        67\n",
            "          12       0.94      0.91      0.93        35\n",
            "          13       0.95      1.00      0.98        20\n",
            "          16       0.85      0.87      0.86        38\n",
            "          17       0.97      0.89      0.93        63\n",
            "\n",
            "    accuracy                           0.95       462\n",
            "   macro avg       0.96      0.94      0.94       462\n",
            "weighted avg       0.96      0.95      0.95       462\n",
            "\n",
            "   subject_id    model  val_accuracy    val_f1  val_precision  val_recall  \\\n",
            "0           8  RForest      0.943111  0.942280       0.949996    0.943111   \n",
            "1           7  RForest      0.949836  0.949276       0.954357    0.949836   \n",
            "\n",
            "   test_accuracy   test_f1  test_precision  test_recall  \n",
            "0       0.948177  0.948347        0.951668     0.948177  \n",
            "1       0.952381  0.952562        0.956226     0.952381  \n"
          ]
        }
      ],
      "source": [
        "# Generate features and labels for each subject using PreProcessor and FeatureExtraction\n",
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "file_path = '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject107.dat'\n",
        "\n",
        "preprocessor.initializeDataFrame(file_path)\n",
        "preprocessor.dataCleaning()\n",
        "preprocessor.applyPreProcessing()\n",
        "\n",
        "subject_id = int(file_path[-5])\n",
        "subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results_RF.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf8eXt2SfkTR",
        "outputId": "aeb89f42-c384-4308-f52f-f21888160d8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model: RForest for subject 8\n",
            "Fold scores: {'accuracy': 0.9590163934426229, 'f1': 0.958693225218873, 'precision': 0.9602738450074516, 'recall': 0.9590163934426229}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       0.91      1.00      0.95        10\n",
            "           3       1.00      1.00      1.00        12\n",
            "           4       0.94      1.00      0.97        15\n",
            "           5       1.00      1.00      1.00         9\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.80      0.89         5\n",
            "          13       0.75      0.75      0.75         4\n",
            "          16       0.91      0.91      0.91        11\n",
            "          17       0.93      0.93      0.93        15\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.96       122\n",
            "   macro avg       0.95      0.94      0.95       122\n",
            "weighted avg       0.96      0.96      0.96       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9344262295081968, 'f1': 0.9330775652701883, 'precision': 0.9422096707535472, 'recall': 0.9344262295081968}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       0.91      0.91      0.91        11\n",
            "           4       0.93      0.93      0.93        15\n",
            "           5       1.00      1.00      1.00         9\n",
            "           6       1.00      0.82      0.90        11\n",
            "           7       0.93      1.00      0.96        13\n",
            "          12       1.00      0.80      0.89         5\n",
            "          13       1.00      1.00      1.00         4\n",
            "          16       0.79      1.00      0.88        11\n",
            "          17       0.88      1.00      0.94        15\n",
            "          24       1.00      0.60      0.75         5\n",
            "\n",
            "    accuracy                           0.93       122\n",
            "   macro avg       0.95      0.92      0.93       122\n",
            "weighted avg       0.94      0.93      0.93       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9426229508196722, 'f1': 0.9413471549781435, 'precision': 0.9450478142076503, 'recall': 0.9426229508196722}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.85      0.92        13\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       0.83      0.91      0.87        11\n",
            "           4       1.00      0.87      0.93        15\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       0.93      1.00      0.97        14\n",
            "          12       0.83      1.00      0.91         5\n",
            "          13       0.75      0.60      0.67         5\n",
            "          16       0.92      1.00      0.96        11\n",
            "          17       0.94      1.00      0.97        15\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.94       122\n",
            "   macro avg       0.93      0.94      0.93       122\n",
            "weighted avg       0.95      0.94      0.94       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9586776859504132, 'f1': 0.9580572873646894, 'precision': 0.9618619348565873, 'recall': 0.9586776859504132}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       0.90      0.82      0.86        11\n",
            "           4       1.00      1.00      1.00        15\n",
            "           5       1.00      0.88      0.93         8\n",
            "           6       1.00      0.82      0.90        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      1.00      1.00         5\n",
            "          13       0.83      1.00      0.91         5\n",
            "          16       0.92      1.00      0.96        11\n",
            "          17       0.88      1.00      0.94        15\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.96       121\n",
            "   macro avg       0.96      0.96      0.96       121\n",
            "weighted avg       0.96      0.96      0.96       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.9504132231404959, 'f1': 0.950365270203527, 'precision': 0.9560964881820496, 'recall': 0.9504132231404959}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.86      1.00      0.92        12\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       0.83      0.91      0.87        11\n",
            "           4       1.00      1.00      1.00        15\n",
            "           5       1.00      0.88      0.93         8\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.80      0.89         5\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       1.00      0.91      0.95        11\n",
            "          17       0.88      1.00      0.94        15\n",
            "          24       1.00      0.75      0.86         4\n",
            "\n",
            "    accuracy                           0.95       121\n",
            "   macro avg       0.96      0.93      0.94       121\n",
            "weighted avg       0.96      0.95      0.95       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.9173553719008265, 'f1': 0.9174723967303753, 'precision': 0.9307162534435262, 'recall': 0.9173553719008265}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       0.75      1.00      0.86        12\n",
            "           4       1.00      0.93      0.96        14\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      0.85      0.92        13\n",
            "          12       0.75      0.60      0.67         5\n",
            "          13       1.00      0.60      0.75         5\n",
            "          16       0.73      0.92      0.81        12\n",
            "          17       0.93      1.00      0.97        14\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.92       121\n",
            "   macro avg       0.93      0.89      0.90       121\n",
            "weighted avg       0.93      0.92      0.92       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.9752066115702479, 'f1': 0.9751590282995242, 'precision': 0.9785971604153422, 'recall': 0.9752066115702479}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.83      1.00      0.91        10\n",
            "           3       0.92      1.00      0.96        12\n",
            "           4       1.00      1.00      1.00        14\n",
            "           5       1.00      0.88      0.93         8\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      0.85      0.92        13\n",
            "          12       1.00      1.00      1.00         5\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       1.00      1.00      1.00        12\n",
            "          17       1.00      1.00      1.00        14\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.98       121\n",
            "   macro avg       0.98      0.98      0.98       121\n",
            "weighted avg       0.98      0.98      0.98       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.9256198347107438, 'f1': 0.9258473481460794, 'precision': 0.9364817001180638, 'recall': 0.9256198347107438}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.79      0.92      0.85        12\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       0.86      1.00      0.92        12\n",
            "           4       1.00      0.93      0.96        14\n",
            "           5       1.00      0.88      0.93         8\n",
            "           6       1.00      0.92      0.96        12\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       1.00      1.00      1.00         5\n",
            "          13       1.00      0.60      0.75         5\n",
            "          16       0.80      1.00      0.89        12\n",
            "          17       0.93      0.93      0.93        14\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.93       121\n",
            "   macro avg       0.95      0.92      0.92       121\n",
            "weighted avg       0.94      0.93      0.93       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.9834710743801653, 'f1': 0.9834605195106763, 'precision': 0.984022038567493, 'recall': 0.9834710743801653}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       0.92      0.92      0.92        12\n",
            "           4       1.00      0.93      0.96        14\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      1.00      1.00         5\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       1.00      1.00      1.00        12\n",
            "          17       0.93      1.00      0.97        14\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.98       121\n",
            "   macro avg       0.99      0.99      0.99       121\n",
            "weighted avg       0.98      0.98      0.98       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.8842975206611571, 'f1': 0.8793181164214416, 'precision': 0.9046487603305784, 'recall': 0.8842975206611571}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        13\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       0.69      0.92      0.79        12\n",
            "           4       0.93      1.00      0.97        14\n",
            "           5       1.00      0.62      0.77         8\n",
            "           6       1.00      0.92      0.96        12\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.75      0.60      0.67         5\n",
            "          13       1.00      0.75      0.86         4\n",
            "          16       0.67      0.91      0.77        11\n",
            "          17       0.94      1.00      0.97        15\n",
            "          24       1.00      0.25      0.40         4\n",
            "\n",
            "    accuracy                           0.88       121\n",
            "   macro avg       0.91      0.82      0.84       121\n",
            "weighted avg       0.90      0.88      0.88       121\n",
            "\n",
            "Average validation scores: {'accuracy': 0.9431106896084541, 'f1': 0.9422797912143517, 'precision': 0.9499955665882289, 'recall': 0.9431106896084541}\n",
            "Test set scores: {'accuracy': 0.9481765834932822, 'f1': 0.9483468724040915, 'precision': 0.951668092521788, 'recall': 0.9481765834932822}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      1.00      0.99        36\n",
            "           2       1.00      0.92      0.96        51\n",
            "           3       0.92      0.94      0.93        51\n",
            "           4       0.97      0.95      0.96        65\n",
            "           5       1.00      0.85      0.92        27\n",
            "           6       1.00      1.00      1.00        52\n",
            "           7       1.00      0.98      0.99        61\n",
            "          12       0.95      0.80      0.87        25\n",
            "          13       0.79      0.94      0.86        16\n",
            "          16       0.87      0.98      0.92        47\n",
            "          17       0.90      0.96      0.93        73\n",
            "          24       1.00      0.88      0.94        17\n",
            "\n",
            "    accuracy                           0.95       521\n",
            "   macro avg       0.95      0.93      0.94       521\n",
            "weighted avg       0.95      0.95      0.95       521\n",
            "\n",
            "   subject_id    model  val_accuracy   val_f1  val_precision  val_recall  \\\n",
            "0           8  RForest      0.943111  0.94228       0.949996    0.943111   \n",
            "\n",
            "   test_accuracy   test_f1  test_precision  test_recall  \n",
            "0       0.948177  0.948347        0.951668     0.948177  \n"
          ]
        }
      ],
      "source": [
        "# Generate features and labels for each subject using PreProcessor and FeatureExtraction\n",
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "file_path = '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject108.dat'\n",
        "\n",
        "preprocessor.initializeDataFrame(file_path)\n",
        "preprocessor.dataCleaning()\n",
        "preprocessor.applyPreProcessing()\n",
        "\n",
        "subject_id = int(file_path[-5])\n",
        "subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results_RF.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN0CuxMM63zyb2fg/rNj3JS",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
