{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Noor-Z1/PAMAP2-DataAnalysis-ML/blob/main/Subject-Specific-Classifiers/Subjects1_8_BasicModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo77tDJTMZ4f"
      },
      "source": [
        "# **CNG 514 - Term Project**\n",
        "\n",
        "### Notebook # 3\n",
        "\n",
        "\n",
        "In this notebook, we apply our own selected feature extraction technique(refer to notebook # 2) to 8 subjects and then do 10 fold cross validation with Grid Search on 4 different ML models and train subject specific classifiers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxicRzUdJKXJ",
        "outputId": "0f490bae-804b-4fe5-8a49-e269e4211d40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mounting drive for loading the dataset files\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRU8hhdcK6X7"
      },
      "outputs": [],
      "source": [
        "# import the necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "import matplotlib as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNrKts7GPtLb"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "from scipy.signal import ellip, filtfilt, welch\n",
        "import numpy as np\n",
        "from scipy.stats import skew, kurtosis, entropy\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "from scipy.signal import ellip, filtfilt, welch\n",
        "import numpy as np\n",
        "from scipy.stats import skew, kurtosis, entropy\n",
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "\n",
        "\n",
        "class PreProcessor:\n",
        "    def __init__(self):\n",
        "        self.dataFrame = pd.DataFrame()\n",
        "\n",
        "    def initializeDataFrame(self, filepath):\n",
        "\n",
        "        colNames = [\"timestamp\", \"activityID\", \"heartrate\"]\n",
        "\n",
        "        IMUhand = ['handTemperature',\n",
        "                   'handAcc16_1', 'handAcc16_2', 'handAcc16_3',\n",
        "                   'handAcc6_1', 'handAcc6_2', 'handAcc6_3',\n",
        "                   'handGyro1', 'handGyro2', 'handGyro3',\n",
        "                   'handMagne1', 'handMagne2', 'handMagne3',\n",
        "                   'handOrientation1', 'handOrientation2', 'handOrientation3', 'handOrientation4']\n",
        "\n",
        "        IMUchest = ['chestTemperature',\n",
        "                    'chestAcc16_1', 'chestAcc16_2', 'chestAcc16_3',\n",
        "                    'chestAcc6_1', 'chestAcc6_2', 'chestAcc6_3',\n",
        "                    'chestGyro1', 'chestGyro2', 'chestGyro3',\n",
        "                    'chestMagne1', 'chestMagne2', 'chestMagne3',\n",
        "                    'chestOrientation1', 'chestOrientation2', 'chestOrientation3', 'chestOrientation4']\n",
        "\n",
        "        IMUankle = ['ankleTemperature',\n",
        "                    'ankleAcc16_1', 'ankleAcc16_2', 'ankleAcc16_3',\n",
        "                    'ankleAcc6_1', 'ankleAcc6_2', 'ankleAcc6_3',\n",
        "                    'ankleGyro1', 'ankleGyro2', 'ankleGyro3',\n",
        "                    'ankleMagne1', 'ankleMagne2', 'ankleMagne3',\n",
        "                    'ankleOrientation1', 'ankleOrientation2', 'ankleOrientation3', 'ankleOrientation4']\n",
        "\n",
        "        columns = colNames + IMUhand + IMUchest + IMUankle  # All columns in one list\n",
        "\n",
        "        procData = pd.read_table(filepath, header=None, sep='\\s+')\n",
        "        procData.columns = columns\n",
        "        procData['subject_id'] = int(filepath[-5])\n",
        "        self.dataFrame = self.dataFrame._append(procData, ignore_index=True)\n",
        "        self.dataFrame.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    def dataCleaning(self):\n",
        "        self.dataFrame = self.dataFrame.drop(\n",
        "            ['handOrientation1', 'handOrientation2', 'handOrientation3', 'handOrientation4',\n",
        "             'chestOrientation1', 'chestOrientation2', 'chestOrientation3', 'chestOrientation4',\n",
        "             'ankleOrientation1', 'ankleOrientation2', 'ankleOrientation3', 'ankleOrientation4',\n",
        "             'handAcc6_1', 'handAcc6_2', 'handAcc6_3', 'chestAcc6_1', 'chestAcc6_2',\n",
        "             'chestAcc6_3', 'ankleAcc6_1', 'ankleAcc6_2', 'ankleAcc6_3'], axis=1)\n",
        "\n",
        "        self.dataFrame = self.dataFrame.drop(self.dataFrame[self.dataFrame.activityID == 0].index)\n",
        "        self.dataFrame = self.dataFrame.apply(pd.to_numeric, errors='ignore')\n",
        "        self.dataFrame = self.dataFrame.interpolate()\n",
        "\n",
        "    def applyPreProcessing(self):\n",
        "        self.dataFrame.reset_index(drop=True, inplace=True)\n",
        "        self.dataFrame.loc[:3, \"heartrate\"] = 100\n",
        "\n",
        "        checkForNan = self.dataFrame.isnull().values.any()\n",
        "        if checkForNan:\n",
        "            print(\"DataFrame still contains some NAN values\")\n",
        "\n",
        "    def getSubjectDf(self, subject_id):\n",
        "        return self.dataFrame[self.dataFrame['subject_id'] == subject_id]\n",
        "\n",
        "\n",
        "class FeatureExtraction1:\n",
        "    def __init__(self, subjectDf, subjectID):\n",
        "        self.dataFrame = subjectDf\n",
        "        self.subjectID = subjectID\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_time_domain_features(data, isheartrate=False):\n",
        "        mean = np.mean(data)\n",
        "        std_dev = np.std(data)\n",
        "\n",
        "        if not isheartrate:\n",
        "            skewness = skew(data, nan_policy='omit')\n",
        "            kurt = kurtosis(data, nan_policy='omit')\n",
        "            return mean, std_dev, skewness, kurt\n",
        "        else:\n",
        "            return mean, std_dev\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_frequency_domain_features(data, fs):\n",
        "        f, Pxx = welch(data, fs=fs, nperseg=len(data))\n",
        "        entropy_power = entropy(Pxx)\n",
        "        peak_power_freq = f[np.argmax(Pxx)]\n",
        "        return entropy_power, peak_power_freq\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_signal_magnitude_area(data):\n",
        "        return np.sum(np.abs(data))\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_pairwise_correlations(data):\n",
        "        correlations = pairwise_distances(data, metric='correlation')\n",
        "        return correlations\n",
        "\n",
        "    def sliding_window_feature_extraction(self, window_size=150, overlap=0, fs=100):\n",
        "\n",
        "        angular_velocity_columns = ['handGyro1', 'handGyro2', 'handGyro3',\n",
        "                                    'chestGyro1', 'chestGyro2', 'chestGyro3',\n",
        "                                    'ankleGyro1', 'ankleGyro2', 'ankleGyro3']\n",
        "        acceleration_columns = ['handAcc16_1', 'handAcc16_2', 'handAcc16_3',\n",
        "                                'chestAcc16_1', 'chestAcc16_2', 'chestAcc16_3',\n",
        "                                'ankleAcc16_1', 'ankleAcc16_2', 'ankleAcc16_3']\n",
        "\n",
        "        heart_rate_col = ['heartrate']\n",
        "        combined_columns = angular_velocity_columns + acceleration_columns\n",
        "\n",
        "        all_features = []\n",
        "        all_labels = []\n",
        "\n",
        "        stride = int(window_size * (1 - overlap))\n",
        "\n",
        "        for start in range(0, len(self.dataFrame) - window_size + 1, stride):\n",
        "            window_data_time = self.dataFrame.loc[start:start + window_size - 1, combined_columns + heart_rate_col]\n",
        "            labels = self.dataFrame.loc[start:start + window_size - 1, 'activityID']\n",
        "\n",
        "            # Ensure the window contains only one activity\n",
        "            if labels.nunique() == 1:\n",
        "                label = labels.iloc[0]\n",
        "\n",
        "                # Extract time-domain features\n",
        "                time_domain_features = []\n",
        "                for column in combined_columns:\n",
        "                    time_domain_features.extend(self.compute_time_domain_features(window_data_time[column]))\n",
        "                for column in heart_rate_col:\n",
        "                    time_domain_features.extend(self.compute_time_domain_features(window_data_time[column], True))\n",
        "\n",
        "                # Extract frequency-domain features\n",
        "                freq_domain_features = []\n",
        "                for column in combined_columns:\n",
        "                    freq_domain_features.extend(self.compute_frequency_domain_features(window_data_time[column], fs))\n",
        "\n",
        "                # Signal magnitude area\n",
        "                sma = [self.compute_signal_magnitude_area(window_data_time[column]) for column in combined_columns]\n",
        "\n",
        "                # Combine all features\n",
        "                features = np.concatenate([time_domain_features, freq_domain_features, sma])\n",
        "                all_features.append(features)\n",
        "                all_labels.append(label)\n",
        "\n",
        "        return np.array(all_features), np.array(all_labels)\n",
        "\n",
        "    def applyFeatureExtraction(self, window_size, overlap, fs):\n",
        "        features, labels = self.sliding_window_feature_extraction(window_size=window_size, overlap=overlap, fs=fs)\n",
        "        return features, labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWPbPo49NLcK"
      },
      "source": [
        "## Model Evaluation Class\n",
        "> **Evaluating Subjects 1 - 8 on different models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWcJOgw2Qtij",
        "outputId": "7cdafb12-a599-4cc7-e62d-aab80375364d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model: k-NN for subject 1\n",
            "Fold scores: {'accuracy': 0.9310344827586207, 'f1': 0.9320216639931782, 'precision': 0.942528735632184, 'recall': 0.9310344827586207}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.86      0.92        14\n",
            "           2       0.83      1.00      0.91        10\n",
            "           3       0.75      1.00      0.86         9\n",
            "           4       1.00      0.82      0.90        11\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00         9\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.92      1.00      0.96        11\n",
            "          17       0.90      0.90      0.90        10\n",
            "          24       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.93       116\n",
            "   macro avg       0.94      0.94      0.93       116\n",
            "weighted avg       0.94      0.93      0.93       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.853448275862069, 'f1': 0.8509251476228804, 'precision': 0.88507326007326, 'recall': 0.853448275862069}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.86      0.92        14\n",
            "           2       1.00      0.45      0.62        11\n",
            "           3       0.64      1.00      0.78         9\n",
            "           4       0.90      0.90      0.90        10\n",
            "           5       0.71      0.91      0.80        11\n",
            "           6       1.00      0.73      0.84        11\n",
            "           7       1.00      0.89      0.94         9\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       0.86      0.86      0.86         7\n",
            "          16       0.91      0.91      0.91        11\n",
            "          17       0.77      1.00      0.87        10\n",
            "          24       0.67      0.80      0.73         5\n",
            "\n",
            "    accuracy                           0.85       116\n",
            "   macro avg       0.87      0.86      0.85       116\n",
            "weighted avg       0.89      0.85      0.85       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.9051724137931034, 'f1': 0.9060474624956317, 'precision': 0.9190613026819923, 'recall': 0.9051724137931034}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      0.73      0.84        11\n",
            "           3       0.67      1.00      0.80        10\n",
            "           4       1.00      1.00      1.00        10\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       0.89      0.89      0.89         9\n",
            "          12       0.78      0.88      0.82         8\n",
            "          13       0.83      0.71      0.77         7\n",
            "          16       0.91      0.91      0.91        11\n",
            "          17       0.89      0.80      0.84        10\n",
            "          24       1.00      0.80      0.89         5\n",
            "\n",
            "    accuracy                           0.91       116\n",
            "   macro avg       0.91      0.89      0.90       116\n",
            "weighted avg       0.92      0.91      0.91       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.9051724137931034, 'f1': 0.9036933016649041, 'precision': 0.9098932676518884, 'recall': 0.9051724137931034}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      1.00      0.96        13\n",
            "           2       0.67      0.55      0.60        11\n",
            "           3       0.71      1.00      0.83        10\n",
            "           4       0.90      0.90      0.90        10\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      0.89      0.94         9\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.91      0.91      0.91        11\n",
            "          17       0.90      0.90      0.90        10\n",
            "          24       1.00      0.80      0.89         5\n",
            "\n",
            "    accuracy                           0.91       116\n",
            "   macro avg       0.92      0.90      0.90       116\n",
            "weighted avg       0.91      0.91      0.90       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.8448275862068966, 'f1': 0.8472707941929214, 'precision': 0.8668056081849185, 'recall': 0.8448275862068966}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.85      0.85      0.85        13\n",
            "           2       1.00      0.64      0.78        11\n",
            "           3       0.67      0.80      0.73        10\n",
            "           4       0.90      0.90      0.90        10\n",
            "           5       1.00      0.80      0.89        10\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      0.89      0.94         9\n",
            "          12       0.86      0.75      0.80         8\n",
            "          13       0.86      0.86      0.86         7\n",
            "          16       0.82      0.82      0.82        11\n",
            "          17       0.77      1.00      0.87        10\n",
            "          24       0.56      0.83      0.67         6\n",
            "\n",
            "    accuracy                           0.84       116\n",
            "   macro avg       0.86      0.84      0.84       116\n",
            "weighted avg       0.87      0.84      0.85       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.9482758620689655, 'f1': 0.9458631008382448, 'precision': 0.9568312434691746, 'recall': 0.9482758620689655}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       0.92      1.00      0.96        11\n",
            "           3       0.90      0.90      0.90        10\n",
            "           4       1.00      1.00      1.00        10\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00         9\n",
            "          12       0.73      1.00      0.84         8\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       1.00      0.91      0.95        11\n",
            "          17       0.91      1.00      0.95        10\n",
            "          24       1.00      0.50      0.67         6\n",
            "\n",
            "    accuracy                           0.95       116\n",
            "   macro avg       0.95      0.93      0.93       116\n",
            "weighted avg       0.96      0.95      0.95       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.9051724137931034, 'f1': 0.9034936328039775, 'precision': 0.9187472010747872, 'recall': 0.9051724137931034}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.86      0.92        14\n",
            "           2       1.00      0.60      0.75        10\n",
            "           3       0.75      0.90      0.82        10\n",
            "           4       0.91      1.00      0.95        10\n",
            "           5       0.90      0.90      0.90        10\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       0.90      0.90      0.90        10\n",
            "          12       0.75      1.00      0.86         9\n",
            "          13       0.86      1.00      0.92         6\n",
            "          16       1.00      0.82      0.90        11\n",
            "          17       0.91      1.00      0.95        10\n",
            "          24       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.91       116\n",
            "   macro avg       0.91      0.91      0.91       116\n",
            "weighted avg       0.92      0.91      0.90       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.8260869565217391, 'f1': 0.826148085456811, 'precision': 0.8465727509205772, 'recall': 0.8260869565217391}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.79      0.88        14\n",
            "           2       0.78      0.70      0.74        10\n",
            "           3       0.70      0.70      0.70        10\n",
            "           4       1.00      0.90      0.95        10\n",
            "           5       0.83      1.00      0.91        10\n",
            "           6       0.91      1.00      0.95        10\n",
            "           7       1.00      0.90      0.95        10\n",
            "          12       0.75      0.75      0.75         8\n",
            "          13       0.67      1.00      0.80         6\n",
            "          16       0.82      0.82      0.82        11\n",
            "          17       0.62      0.80      0.70        10\n",
            "          24       1.00      0.50      0.67         6\n",
            "\n",
            "    accuracy                           0.83       115\n",
            "   macro avg       0.84      0.82      0.82       115\n",
            "weighted avg       0.85      0.83      0.83       115\n",
            "\n",
            "Fold scores: {'accuracy': 0.9652173913043478, 'f1': 0.9646254893692959, 'precision': 0.9675230566534915, 'recall': 0.9652173913043478}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       1.00      0.80      0.89        10\n",
            "           3       0.91      1.00      0.95        10\n",
            "           4       1.00      0.90      0.95        10\n",
            "           5       0.91      1.00      0.95        10\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      1.00      1.00         9\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      1.00      1.00         6\n",
            "          16       1.00      1.00      1.00        11\n",
            "          17       0.92      1.00      0.96        11\n",
            "          24       0.83      0.83      0.83         6\n",
            "\n",
            "    accuracy                           0.97       115\n",
            "   macro avg       0.96      0.96      0.96       115\n",
            "weighted avg       0.97      0.97      0.96       115\n",
            "\n",
            "Fold scores: {'accuracy': 0.8695652173913043, 'f1': 0.8679465745961911, 'precision': 0.8824016563146998, 'recall': 0.8695652173913043}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.79      0.85        14\n",
            "           2       0.70      0.70      0.70        10\n",
            "           3       0.71      1.00      0.83        10\n",
            "           4       0.83      1.00      0.91        10\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      0.80      0.89        10\n",
            "           7       1.00      0.89      0.94         9\n",
            "          12       0.83      0.62      0.71         8\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       0.91      0.91      0.91        11\n",
            "          17       0.83      1.00      0.91        10\n",
            "          24       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.87       115\n",
            "   macro avg       0.88      0.87      0.87       115\n",
            "weighted avg       0.88      0.87      0.87       115\n",
            "\n",
            "Average validation scores: {'accuracy': 0.8953973013493254, 'f1': 0.8948035253034036, 'precision': 0.9095438082656973, 'recall': 0.8953973013493254}\n",
            "Test set scores: {'accuracy': 0.8830645161290323, 'f1': 0.8838719186447515, 'precision': 0.8886932561816211, 'recall': 0.8830645161290323}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.96      0.98      0.97        45\n",
            "           2       0.83      0.80      0.82        50\n",
            "           3       0.79      0.83      0.81        46\n",
            "           4       0.90      0.91      0.91        47\n",
            "           5       0.92      0.94      0.93        36\n",
            "           6       0.98      0.92      0.95        50\n",
            "           7       0.95      0.83      0.89        42\n",
            "          12       0.70      0.91      0.79        23\n",
            "          13       0.88      0.73      0.80        30\n",
            "          16       0.95      0.88      0.91        42\n",
            "          17       0.79      0.89      0.84        55\n",
            "          24       1.00      0.97      0.98        30\n",
            "\n",
            "    accuracy                           0.88       496\n",
            "   macro avg       0.89      0.88      0.88       496\n",
            "weighted avg       0.89      0.88      0.88       496\n",
            "\n",
            "Evaluating model: SVM for subject 1\n",
            "Fold scores: {'accuracy': 0.9396551724137931, 'f1': 0.9399407563950293, 'precision': 0.9488636363636364, 'recall': 0.9396551724137931}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.86      0.92        14\n",
            "           2       0.91      1.00      0.95        10\n",
            "           3       0.82      1.00      0.90         9\n",
            "           4       1.00      0.82      0.90        11\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       0.82      1.00      0.90         9\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.92      1.00      0.96        11\n",
            "          17       1.00      1.00      1.00        10\n",
            "          24       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.94       116\n",
            "   macro avg       0.94      0.95      0.94       116\n",
            "weighted avg       0.95      0.94      0.94       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.853448275862069, 'f1': 0.8548414367947036, 'precision': 0.883519210674383, 'recall': 0.853448275862069}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.86      0.89        14\n",
            "           2       1.00      0.64      0.78        11\n",
            "           3       0.60      1.00      0.75         9\n",
            "           4       0.82      0.90      0.86        10\n",
            "           5       0.91      0.91      0.91        11\n",
            "           6       1.00      0.73      0.84        11\n",
            "           7       1.00      0.78      0.88         9\n",
            "          12       0.80      1.00      0.89         8\n",
            "          13       0.75      0.86      0.80         7\n",
            "          16       1.00      0.82      0.90        11\n",
            "          17       0.83      1.00      0.91        10\n",
            "          24       0.80      0.80      0.80         5\n",
            "\n",
            "    accuracy                           0.85       116\n",
            "   macro avg       0.87      0.86      0.85       116\n",
            "weighted avg       0.88      0.85      0.85       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.896551724137931, 'f1': 0.8949667031563584, 'precision': 0.898879568707155, 'recall': 0.896551724137931}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      1.00      0.96        13\n",
            "           2       0.90      0.82      0.86        11\n",
            "           3       0.90      0.90      0.90        10\n",
            "           4       0.91      1.00      0.95        10\n",
            "           5       0.85      1.00      0.92        11\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       0.89      0.89      0.89         9\n",
            "          12       0.75      0.75      0.75         8\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       0.90      0.82      0.86        11\n",
            "          17       0.90      0.90      0.90        10\n",
            "          24       0.80      0.80      0.80         5\n",
            "\n",
            "    accuracy                           0.90       116\n",
            "   macro avg       0.89      0.88      0.88       116\n",
            "weighted avg       0.90      0.90      0.89       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.9051724137931034, 'f1': 0.9059906871134771, 'precision': 0.9159109568592327, 'recall': 0.9051724137931034}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      1.00      0.96        13\n",
            "           2       0.91      0.91      0.91        11\n",
            "           3       1.00      0.90      0.95        10\n",
            "           4       0.75      0.90      0.82        10\n",
            "           5       0.90      0.82      0.86        11\n",
            "           6       0.92      1.00      0.96        11\n",
            "           7       1.00      0.89      0.94         9\n",
            "          12       0.70      0.88      0.78         8\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       1.00      0.91      0.95        11\n",
            "          17       0.91      1.00      0.95        10\n",
            "          24       1.00      0.80      0.89         5\n",
            "\n",
            "    accuracy                           0.91       116\n",
            "   macro avg       0.92      0.89      0.90       116\n",
            "weighted avg       0.92      0.91      0.91       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.8362068965517241, 'f1': 0.8336279726125437, 'precision': 0.8394230769230769, 'recall': 0.8362068965517241}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.77      0.83        13\n",
            "           2       0.75      0.82      0.78        11\n",
            "           3       0.71      0.50      0.59        10\n",
            "           4       0.82      0.90      0.86        10\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       0.80      0.89      0.84         9\n",
            "          12       0.86      0.75      0.80         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.82      0.82      0.82        11\n",
            "          17       0.69      0.90      0.78        10\n",
            "          24       0.83      0.83      0.83         6\n",
            "\n",
            "    accuracy                           0.84       116\n",
            "   macro avg       0.84      0.84      0.84       116\n",
            "weighted avg       0.84      0.84      0.83       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.9137931034482759, 'f1': 0.9132663931192297, 'precision': 0.9296630094043887, 'recall': 0.9137931034482759}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      0.82      0.90        11\n",
            "           3       0.90      0.90      0.90        10\n",
            "           4       1.00      0.90      0.95        10\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00         9\n",
            "          12       0.67      1.00      0.80         8\n",
            "          13       0.75      0.86      0.80         7\n",
            "          16       0.83      0.91      0.87        11\n",
            "          17       0.91      1.00      0.95        10\n",
            "          24       1.00      0.50      0.67         6\n",
            "\n",
            "    accuracy                           0.91       116\n",
            "   macro avg       0.92      0.90      0.90       116\n",
            "weighted avg       0.93      0.91      0.91       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.8620689655172413, 'f1': 0.8629306290603929, 'precision': 0.8794403393541322, 'recall': 0.8620689655172413}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.79      0.85        14\n",
            "           2       0.78      0.70      0.74        10\n",
            "           3       0.88      0.70      0.78        10\n",
            "           4       0.83      1.00      0.91        10\n",
            "           5       0.80      0.80      0.80        10\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      0.90      0.95        10\n",
            "          12       0.60      1.00      0.75         9\n",
            "          13       0.86      1.00      0.92         6\n",
            "          16       0.89      0.73      0.80        11\n",
            "          17       1.00      1.00      1.00        10\n",
            "          24       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.86       116\n",
            "   macro avg       0.88      0.87      0.87       116\n",
            "weighted avg       0.88      0.86      0.86       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.8608695652173913, 'f1': 0.8614016050609423, 'precision': 0.8721877156659765, 'recall': 0.8608695652173913}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.79      0.79      0.79        14\n",
            "           2       0.67      0.80      0.73        10\n",
            "           3       0.78      0.70      0.74        10\n",
            "           4       1.00      0.90      0.95        10\n",
            "           5       0.83      1.00      0.91        10\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      0.90      0.95        10\n",
            "          12       0.86      0.75      0.80         8\n",
            "          13       0.75      1.00      0.86         6\n",
            "          16       0.83      0.91      0.87        11\n",
            "          17       1.00      0.90      0.95        10\n",
            "          24       1.00      0.67      0.80         6\n",
            "\n",
            "    accuracy                           0.86       115\n",
            "   macro avg       0.88      0.86      0.86       115\n",
            "weighted avg       0.87      0.86      0.86       115\n",
            "\n",
            "Fold scores: {'accuracy': 0.9391304347826087, 'f1': 0.939393175451517, 'precision': 0.9477995150629422, 'recall': 0.9391304347826087}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.82      1.00      0.90        14\n",
            "           2       1.00      0.80      0.89        10\n",
            "           3       1.00      0.80      0.89        10\n",
            "           4       1.00      0.90      0.95        10\n",
            "           5       0.91      1.00      0.95        10\n",
            "           6       0.91      1.00      0.95        10\n",
            "           7       1.00      0.89      0.94         9\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      1.00      1.00         6\n",
            "          16       1.00      1.00      1.00        11\n",
            "          17       1.00      1.00      1.00        11\n",
            "          24       0.71      0.83      0.77         6\n",
            "\n",
            "    accuracy                           0.94       115\n",
            "   macro avg       0.95      0.94      0.94       115\n",
            "weighted avg       0.95      0.94      0.94       115\n",
            "\n",
            "Fold scores: {'accuracy': 0.8695652173913043, 'f1': 0.8671102338732719, 'precision': 0.8792084726867336, 'recall': 0.8695652173913043}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.79      0.85        14\n",
            "           2       0.77      1.00      0.87        10\n",
            "           3       0.80      0.80      0.80        10\n",
            "           4       0.83      1.00      0.91        10\n",
            "           5       0.92      1.00      0.96        11\n",
            "           6       1.00      0.80      0.89        10\n",
            "           7       1.00      0.89      0.94         9\n",
            "          12       0.83      0.62      0.71         8\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       0.83      0.91      0.87        11\n",
            "          17       0.83      1.00      0.91        10\n",
            "          24       0.80      0.80      0.80         5\n",
            "\n",
            "    accuracy                           0.87       115\n",
            "   macro avg       0.88      0.86      0.86       115\n",
            "weighted avg       0.88      0.87      0.87       115\n",
            "\n",
            "Average validation scores: {'accuracy': 0.8876461769115442, 'f1': 0.8873469592637464, 'precision': 0.8994895501701657, 'recall': 0.8876461769115442}\n",
            "Test set scores: {'accuracy': 0.8891129032258065, 'f1': 0.8893252353659157, 'precision': 0.893333129516659, 'recall': 0.8891129032258065}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.98      0.95        45\n",
            "           2       0.91      0.84      0.87        50\n",
            "           3       0.87      0.89      0.88        46\n",
            "           4       0.94      0.94      0.94        47\n",
            "           5       0.94      0.94      0.94        36\n",
            "           6       0.90      0.90      0.90        50\n",
            "           7       0.93      0.88      0.90        42\n",
            "          12       0.69      0.87      0.77        23\n",
            "          13       0.92      0.73      0.81        30\n",
            "          16       0.79      0.88      0.83        42\n",
            "          17       0.92      0.84      0.88        55\n",
            "          24       0.91      0.97      0.94        30\n",
            "\n",
            "    accuracy                           0.89       496\n",
            "   macro avg       0.89      0.89      0.88       496\n",
            "weighted avg       0.89      0.89      0.89       496\n",
            "\n",
            "Evaluating model: Naive Bayes for subject 1\n",
            "Fold scores: {'accuracy': 0.9396551724137931, 'f1': 0.9396072796934865, 'precision': 0.9463467566915843, 'recall': 0.9396551724137931}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.86      0.89        14\n",
            "           2       0.91      1.00      0.95        10\n",
            "           3       0.82      1.00      0.90         9\n",
            "           4       1.00      0.82      0.90        11\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00         9\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.85      1.00      0.92        11\n",
            "          17       0.91      1.00      0.95        10\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.94       116\n",
            "   macro avg       0.95      0.95      0.95       116\n",
            "weighted avg       0.95      0.94      0.94       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.853448275862069, 'f1': 0.8609711031557674, 'precision': 0.903448275862069, 'recall': 0.853448275862069}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.86      0.92        14\n",
            "           2       1.00      0.64      0.78        11\n",
            "           3       0.53      0.89      0.67         9\n",
            "           4       1.00      0.90      0.95        10\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      0.73      0.84        11\n",
            "           7       1.00      0.78      0.88         9\n",
            "          12       0.67      1.00      0.80         8\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.91      0.91      0.91        11\n",
            "          17       0.67      1.00      0.80        10\n",
            "          24       1.00      0.80      0.89         5\n",
            "\n",
            "    accuracy                           0.85       116\n",
            "   macro avg       0.90      0.86      0.86       116\n",
            "weighted avg       0.90      0.85      0.86       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.896551724137931, 'f1': 0.8953099568387279, 'precision': 0.9066605090311985, 'recall': 0.896551724137931}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      1.00      0.96        13\n",
            "           2       0.88      0.64      0.74        11\n",
            "           3       0.75      0.90      0.82        10\n",
            "           4       1.00      1.00      1.00        10\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      0.89      0.94         9\n",
            "          12       1.00      0.75      0.86         8\n",
            "          13       0.83      0.71      0.77         7\n",
            "          16       0.79      1.00      0.88        11\n",
            "          17       0.75      0.90      0.82        10\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.90       116\n",
            "   macro avg       0.91      0.89      0.89       116\n",
            "weighted avg       0.91      0.90      0.90       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.9137931034482759, 'f1': 0.9144853545088413, 'precision': 0.9211243737105806, 'recall': 0.9137931034482759}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       0.91      0.91      0.91        11\n",
            "           3       0.90      0.90      0.90        10\n",
            "           4       1.00      0.90      0.95        10\n",
            "           5       1.00      0.82      0.90        11\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00         9\n",
            "          12       0.78      0.88      0.82         8\n",
            "          13       0.83      0.71      0.77         7\n",
            "          16       0.77      0.91      0.83        11\n",
            "          17       0.83      1.00      0.91        10\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.91       116\n",
            "   macro avg       0.92      0.91      0.91       116\n",
            "weighted avg       0.92      0.91      0.91       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.8620689655172413, 'f1': 0.8648124918448927, 'precision': 0.8779796113847838, 'recall': 0.8620689655172413}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.85      0.92        13\n",
            "           2       0.82      0.82      0.82        11\n",
            "           3       0.78      0.70      0.74        10\n",
            "           4       1.00      0.90      0.95        10\n",
            "           5       1.00      0.80      0.89        10\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      0.89      0.94         9\n",
            "          12       0.60      0.75      0.67         8\n",
            "          13       0.88      1.00      0.93         7\n",
            "          16       0.82      0.82      0.82        11\n",
            "          17       0.71      1.00      0.83        10\n",
            "          24       0.83      0.83      0.83         6\n",
            "\n",
            "    accuracy                           0.86       116\n",
            "   macro avg       0.87      0.86      0.86       116\n",
            "weighted avg       0.88      0.86      0.86       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.9137931034482759, 'f1': 0.9110333603200328, 'precision': 0.9234490126731505, 'recall': 0.9137931034482759}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       0.83      0.91      0.87        11\n",
            "           3       0.78      0.70      0.74        10\n",
            "           4       1.00      1.00      1.00        10\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00         9\n",
            "          12       0.80      1.00      0.89         8\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.92      1.00      0.96        11\n",
            "          17       0.77      1.00      0.87        10\n",
            "          24       1.00      0.50      0.67         6\n",
            "\n",
            "    accuracy                           0.91       116\n",
            "   macro avg       0.92      0.90      0.90       116\n",
            "weighted avg       0.92      0.91      0.91       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.8793103448275862, 'f1': 0.8801886823516875, 'precision': 0.8942876089427814, 'recall': 0.8793103448275862}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.86      0.89        14\n",
            "           2       0.86      0.60      0.71        10\n",
            "           3       0.88      0.70      0.78        10\n",
            "           4       1.00      1.00      1.00        10\n",
            "           5       1.00      0.90      0.95        10\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      0.90      0.95        10\n",
            "          12       0.90      1.00      0.95         9\n",
            "          13       0.86      1.00      0.92         6\n",
            "          16       0.75      0.82      0.78        11\n",
            "          17       0.60      0.90      0.72        10\n",
            "          24       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.88       116\n",
            "   macro avg       0.90      0.89      0.89       116\n",
            "weighted avg       0.89      0.88      0.88       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.9130434782608695, 'f1': 0.914262558211419, 'precision': 0.9274247491638795, 'recall': 0.9130434782608695}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.86      0.89        14\n",
            "           2       0.75      0.90      0.82        10\n",
            "           3       0.69      0.90      0.78        10\n",
            "           4       1.00      0.90      0.95        10\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      0.90      0.95        10\n",
            "          12       1.00      0.75      0.86         8\n",
            "          13       1.00      1.00      1.00         6\n",
            "          16       0.85      1.00      0.92        11\n",
            "          17       1.00      1.00      1.00        10\n",
            "          24       1.00      0.67      0.80         6\n",
            "\n",
            "    accuracy                           0.91       115\n",
            "   macro avg       0.93      0.91      0.91       115\n",
            "weighted avg       0.93      0.91      0.91       115\n",
            "\n",
            "Fold scores: {'accuracy': 0.9478260869565217, 'f1': 0.948292334033583, 'precision': 0.9537107819716515, 'recall': 0.9478260869565217}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       0.90      0.90      0.90        10\n",
            "           3       1.00      0.80      0.89        10\n",
            "           4       1.00      0.90      0.95        10\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      0.89      0.94         9\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      1.00      1.00         6\n",
            "          16       0.92      1.00      0.96        11\n",
            "          17       0.85      1.00      0.92        11\n",
            "          24       0.71      0.83      0.77         6\n",
            "\n",
            "    accuracy                           0.95       115\n",
            "   macro avg       0.95      0.94      0.94       115\n",
            "weighted avg       0.95      0.95      0.95       115\n",
            "\n",
            "Fold scores: {'accuracy': 0.8695652173913043, 'f1': 0.8705864295211564, 'precision': 0.8861984392419174, 'recall': 0.8695652173913043}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.86      0.89        14\n",
            "           2       0.90      0.90      0.90        10\n",
            "           3       0.70      0.70      0.70        10\n",
            "           4       1.00      1.00      1.00        10\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      0.70      0.82        10\n",
            "           7       1.00      0.89      0.94         9\n",
            "          12       0.75      0.75      0.75         8\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       0.73      1.00      0.85        11\n",
            "          17       0.69      0.90      0.78        10\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.87       115\n",
            "   macro avg       0.89      0.87      0.87       115\n",
            "weighted avg       0.89      0.87      0.87       115\n",
            "\n",
            "Average validation scores: {'accuracy': 0.8989055472263867, 'f1': 0.8999549550479594, 'precision': 0.9140630118673597, 'recall': 0.8989055472263867}\n",
            "Test set scores: {'accuracy': 0.9112903225806451, 'f1': 0.9118604534803144, 'precision': 0.9188227795078737, 'recall': 0.9112903225806451}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.96      0.98      0.97        45\n",
            "           2       0.87      0.82      0.85        50\n",
            "           3       0.78      0.87      0.82        46\n",
            "           4       0.98      0.91      0.95        47\n",
            "           5       1.00      0.94      0.97        36\n",
            "           6       1.00      0.94      0.97        50\n",
            "           7       1.00      0.88      0.94        42\n",
            "          12       0.79      0.96      0.86        23\n",
            "          13       1.00      0.73      0.85        30\n",
            "          16       0.83      0.93      0.88        42\n",
            "          17       0.86      0.98      0.92        55\n",
            "          24       0.97      0.97      0.97        30\n",
            "\n",
            "    accuracy                           0.91       496\n",
            "   macro avg       0.92      0.91      0.91       496\n",
            "weighted avg       0.92      0.91      0.91       496\n",
            "\n",
            "   subject_id        model  val_accuracy    val_f1  val_precision  val_recall  \\\n",
            "0           1         k-NN      0.895397  0.894804       0.909544    0.895397   \n",
            "1           1          SVM      0.887646  0.887347       0.899490    0.887646   \n",
            "2           1  Naive Bayes      0.898906  0.899955       0.914063    0.898906   \n",
            "\n",
            "   test_accuracy   test_f1  test_precision  test_recall  \n",
            "0       0.883065  0.883872        0.888693     0.883065  \n",
            "1       0.889113  0.889325        0.893333     0.889113  \n",
            "2       0.911290  0.911860        0.918823     0.911290  \n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, make_scorer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "class ModelEval:\n",
        "    def __init__(self, cv=5, n_splits=10):\n",
        "        self.models = []\n",
        "        self.metrics = []\n",
        "        self.subjectScores = {}\n",
        "        self.cv = cv\n",
        "        self.n_splits = n_splits\n",
        "\n",
        "    def add_model(self, model, name, param_grid=None):\n",
        "        \"\"\"Add a machine learning model for evaluation.\"\"\"\n",
        "        self.models.append((name, model, param_grid))\n",
        "\n",
        "    def add_metric(self, metric, name):\n",
        "        \"\"\"Add a metric for evaluation.\"\"\"\n",
        "        self.metrics.append((name, make_scorer(metric)))\n",
        "\n",
        "    def evaluate_subject(self, features, labels, subject_id):\n",
        "        \"\"\"Evaluate all models using nested cross-validation for a specific subject and store the results.\"\"\"\n",
        "        subject_results = {}\n",
        "        for name, model, param_grid in self.models:\n",
        "            print(f\"Evaluating model: {name} for subject {subject_id}\")\n",
        "            outer_scores, test_scores = self.nested_cross_validation(features, labels, model, param_grid)\n",
        "            subject_results[name] = {'validation_scores': outer_scores, 'test_scores': test_scores}\n",
        "        self.subjectScores[subject_id] = subject_results\n",
        "\n",
        "    def nested_cross_validation(self, features, labels, model, param_grid, test_size=0.3):\n",
        "        \"\"\"Perform nested cross-validation and return the evaluation scores.\"\"\"\n",
        "        X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=test_size, random_state=42, stratify=labels)\n",
        "\n",
        "        outer_cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
        "        if param_grid:\n",
        "            clf = GridSearchCV(estimator=model, param_grid=param_grid, cv=self.cv, scoring='accuracy')\n",
        "        else:\n",
        "            clf = model\n",
        "\n",
        "        outer_scores = []\n",
        "\n",
        "        for train_index, val_index in outer_cv.split(X_train, y_train):\n",
        "            X_train_inner, X_val = X_train[train_index], X_train[val_index]\n",
        "            y_train_inner, y_val = y_train[train_index], y_train[val_index]\n",
        "\n",
        "            imputer = SimpleImputer(strategy='mean')\n",
        "            X_train_inner = imputer.fit_transform(X_train_inner)\n",
        "            X_val = imputer.transform(X_val)\n",
        "\n",
        "            scaler = RobustScaler().fit(X_train_inner)\n",
        "            X_train_inner = scaler.transform(X_train_inner)\n",
        "            X_val = scaler.transform(X_val)\n",
        "\n",
        "            if param_grid:\n",
        "                clf.fit(X_train_inner, y_train_inner)\n",
        "                best_model = clf.best_estimator_\n",
        "            else:\n",
        "                best_model = model\n",
        "                best_model.fit(X_train_inner, y_train_inner)\n",
        "\n",
        "            y_pred = best_model.predict(X_val)\n",
        "\n",
        "            scores = {\n",
        "                'accuracy': accuracy_score(y_val, y_pred),\n",
        "                'f1': f1_score(y_val, y_pred, average='weighted'),\n",
        "                'precision': precision_score(y_val, y_pred, average='weighted'),\n",
        "                'recall': recall_score(y_val, y_pred, average='weighted')\n",
        "            }\n",
        "\n",
        "            outer_scores.append(scores)\n",
        "\n",
        "            print(f\"Fold scores: {scores}\")\n",
        "            print(classification_report(y_val, y_pred, zero_division=0))\n",
        "\n",
        "        average_scores = {\n",
        "            'accuracy': np.mean([score['accuracy'] for score in outer_scores]),\n",
        "            'f1': np.mean([score['f1'] for score in outer_scores]),\n",
        "            'precision': np.mean([score['precision'] for score in outer_scores]),\n",
        "            'recall': np.mean([score['recall'] for score in outer_scores])\n",
        "        }\n",
        "        print(\"Average validation scores:\", average_scores)\n",
        "\n",
        "        # Final evaluation on the test set\n",
        "        imputer = SimpleImputer(strategy='mean')\n",
        "        X_train = imputer.fit_transform(X_train)\n",
        "        X_test = imputer.transform(X_test)\n",
        "\n",
        "        scaler = RobustScaler().fit(X_train)\n",
        "        X_train = scaler.transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "        if param_grid:\n",
        "            clf.fit(X_train, y_train)\n",
        "            best_model = clf.best_estimator_\n",
        "        else:\n",
        "            best_model = model\n",
        "            best_model.fit(X_train, y_train)\n",
        "\n",
        "        y_pred_test = best_model.predict(X_test)\n",
        "\n",
        "        test_scores = {\n",
        "            'accuracy': accuracy_score(y_test, y_pred_test),\n",
        "            'f1': f1_score(y_test, y_pred_test, average='weighted'),\n",
        "            'precision': precision_score(y_test, y_pred_test, average='weighted'),\n",
        "            'recall': recall_score(y_test, y_pred_test, average='weighted')\n",
        "        }\n",
        "\n",
        "        print(\"Test set scores:\", test_scores)\n",
        "        print(classification_report(y_test, y_pred_test, zero_division=0))\n",
        "\n",
        "        return average_scores, test_scores\n",
        "\n",
        "    def evaluate_all_subjects(self, subject_data):\n",
        "        \"\"\"Evaluate all models for all subjects.\"\"\"\n",
        "        for subject_id, (features, labels) in subject_data.items():\n",
        "            self.evaluate_subject(features, labels, subject_id)\n",
        "\n",
        "    def get_results_df(self):\n",
        "        \"\"\"Retrieve the results as a Pandas DataFrame.\"\"\"\n",
        "        results = []\n",
        "        for subject_id, models in self.subjectScores.items():\n",
        "            for model_name, scores in models.items():\n",
        "                result = {\n",
        "                    'subject_id': subject_id,\n",
        "                    'model': model_name,\n",
        "                    'val_accuracy': scores['validation_scores']['accuracy'],\n",
        "                    'val_f1': scores['validation_scores']['f1'],\n",
        "                    'val_precision': scores['validation_scores']['precision'],\n",
        "                    'val_recall': scores['validation_scores']['recall'],\n",
        "                    'test_accuracy': scores['test_scores']['accuracy'],\n",
        "                    'test_f1': scores['test_scores']['f1'],\n",
        "                    'test_precision': scores['test_scores']['precision'],\n",
        "                    'test_recall': scores['test_scores']['recall']\n",
        "                }\n",
        "                results.append(result)\n",
        "        return pd.DataFrame(results)\n",
        "\n",
        "    def report_results(self):\n",
        "        \"\"\"Print the evaluation results.\"\"\"\n",
        "        results_df = self.get_results_df()\n",
        "        print(results_df)\n",
        "        return results_df\n",
        "\n",
        "\n",
        "\n",
        "# Initialize the evaluator\n",
        "evaluator = ModelEval(cv=5, n_splits=10)\n",
        "\n",
        "evaluator.add_model(KNeighborsClassifier(), \"k-NN\", param_grid={\n",
        "    'n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
        "})\n",
        "\n",
        "evaluator.add_model(SVC(), \"SVM\", param_grid={\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'degree': [2, 3, 4],\n",
        "    'gamma': ['scale', 'auto']\n",
        "})\n",
        "\n",
        "evaluator.add_model(GaussianNB(), \"Naive Bayes\", param_grid={\n",
        "    'var_smoothing': np.logspace(-9, -6, 4)\n",
        "})\n",
        "\n",
        "\n",
        "# Add metrics\n",
        "evaluator.add_metric(accuracy_score, \"Accuracy\")\n",
        "evaluator.add_metric(f1_score, \"F1 Score\")\n",
        "evaluator.add_metric(precision_score, \"Precision\")\n",
        "evaluator.add_metric(recall_score, \"Recall\")\n",
        "\n",
        "# Generate features and labels for each subject using PreProcessor and FeatureExtraction\n",
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "file_path =  '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject101.dat'\n",
        "\n",
        "preprocessor.initializeDataFrame(file_path)\n",
        "preprocessor.dataCleaning()\n",
        "preprocessor.applyPreProcessing()\n",
        "\n",
        "subject_id = int(file_path[-5])\n",
        "subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfOYlqpYnept",
        "outputId": "47acfe57-d5b9-4c6e-cacc-87de1838c831"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame still contains some NAN values\n",
            "Evaluating model: k-NN for subject 2\n",
            "Fold scores: {'accuracy': 0.8770491803278688, 'f1': 0.8805809248432199, 'precision': 0.9020491803278688, 'recall': 0.8770491803278688}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       0.88      0.70      0.78        10\n",
            "           3       0.79      0.92      0.85        12\n",
            "           4       0.88      0.88      0.88        16\n",
            "           5       1.00      1.00      1.00         4\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       0.93      1.00      0.96        13\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       1.00      0.88      0.93         8\n",
            "          16       1.00      0.80      0.89        10\n",
            "          17       0.60      0.92      0.73        13\n",
            "          24       1.00      0.67      0.80         6\n",
            "\n",
            "    accuracy                           0.88       122\n",
            "   macro avg       0.92      0.87      0.89       122\n",
            "weighted avg       0.90      0.88      0.88       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.860655737704918, 'f1': 0.858906571570506, 'precision': 0.8727700096432016, 'recall': 0.860655737704918}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.83      0.50      0.62        10\n",
            "           3       0.62      0.83      0.71        12\n",
            "           4       0.82      0.93      0.87        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.88      1.00      0.93         7\n",
            "          13       0.83      0.62      0.71         8\n",
            "          16       0.75      0.90      0.82        10\n",
            "          17       0.85      0.85      0.85        13\n",
            "          24       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.86       122\n",
            "   macro avg       0.88      0.86      0.86       122\n",
            "weighted avg       0.87      0.86      0.86       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.860655737704918, 'f1': 0.8554747581676889, 'precision': 0.8785872639248394, 'recall': 0.860655737704918}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        12\n",
            "           2       0.83      0.50      0.62        10\n",
            "           3       0.58      0.92      0.71        12\n",
            "           4       0.94      1.00      0.97        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       0.93      1.00      0.97        14\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       1.00      0.43      0.60         7\n",
            "          16       0.78      0.70      0.74        10\n",
            "          17       0.77      0.77      0.77        13\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.86       122\n",
            "   macro avg       0.90      0.85      0.86       122\n",
            "weighted avg       0.88      0.86      0.86       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.860655737704918, 'f1': 0.8641627282350168, 'precision': 0.9052348142868456, 'recall': 0.860655737704918}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       1.00      0.50      0.67        10\n",
            "           3       0.52      1.00      0.69        12\n",
            "           4       0.93      0.93      0.93        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      0.92      0.96        12\n",
            "           7       1.00      0.93      0.96        14\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       0.78      0.70      0.74        10\n",
            "          17       0.80      0.92      0.86        13\n",
            "          24       1.00      0.60      0.75         5\n",
            "\n",
            "    accuracy                           0.86       122\n",
            "   macro avg       0.92      0.84      0.86       122\n",
            "weighted avg       0.91      0.86      0.86       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8524590163934426, 'f1': 0.856365068502282, 'precision': 0.8904163696840105, 'recall': 0.8524590163934426}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.83      0.50      0.62        10\n",
            "           3       0.48      0.92      0.63        12\n",
            "           4       0.88      0.93      0.90        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      1.00      1.00        14\n",
            "          12       0.80      0.57      0.67         7\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       1.00      0.70      0.82        10\n",
            "          17       0.83      0.77      0.80        13\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.85       122\n",
            "   macro avg       0.90      0.84      0.86       122\n",
            "weighted avg       0.89      0.85      0.86       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8852459016393442, 'f1': 0.8887047924907973, 'precision': 0.9055425448868071, 'recall': 0.8852459016393442}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.86      0.60      0.71        10\n",
            "           3       0.61      0.92      0.73        12\n",
            "           4       1.00      1.00      1.00        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      0.92      0.96        12\n",
            "           7       1.00      0.93      0.96        14\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.80      0.80      0.80        10\n",
            "          17       0.71      0.83      0.77        12\n",
            "          24       1.00      0.80      0.89         5\n",
            "\n",
            "    accuracy                           0.89       122\n",
            "   macro avg       0.92      0.88      0.89       122\n",
            "weighted avg       0.91      0.89      0.89       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8770491803278688, 'f1': 0.8800866315121482, 'precision': 0.901954939949154, 'recall': 0.8770491803278688}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.75      0.86        12\n",
            "           2       1.00      0.80      0.89        10\n",
            "           3       0.59      0.91      0.71        11\n",
            "           4       0.94      1.00      0.97        16\n",
            "           5       1.00      0.80      0.89         5\n",
            "           6       0.91      0.83      0.87        12\n",
            "           7       1.00      1.00      1.00        14\n",
            "          12       0.88      0.88      0.88         8\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       0.80      0.80      0.80        10\n",
            "          17       0.80      1.00      0.89        12\n",
            "          24       1.00      0.80      0.89         5\n",
            "\n",
            "    accuracy                           0.88       122\n",
            "   macro avg       0.91      0.86      0.87       122\n",
            "weighted avg       0.90      0.88      0.88       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8688524590163934, 'f1': 0.8713465244155565, 'precision': 0.8979613282891971, 'recall': 0.8688524590163934}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       1.00      0.70      0.82        10\n",
            "           3       0.85      1.00      0.92        11\n",
            "           4       0.94      0.94      0.94        16\n",
            "           5       1.00      0.60      0.75         5\n",
            "           6       0.92      1.00      0.96        12\n",
            "           7       0.93      1.00      0.97        14\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.75      0.60      0.67        10\n",
            "          17       0.55      0.92      0.69        12\n",
            "          24       1.00      0.80      0.89         5\n",
            "\n",
            "    accuracy                           0.87       122\n",
            "   macro avg       0.91      0.84      0.86       122\n",
            "weighted avg       0.90      0.87      0.87       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9180327868852459, 'f1': 0.9178276065316442, 'precision': 0.9312429942552893, 'recall': 0.9180327868852459}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.88      0.70      0.78        10\n",
            "           3       0.69      1.00      0.81        11\n",
            "           4       0.89      1.00      0.94        16\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       0.92      1.00      0.96        12\n",
            "           7       1.00      0.79      0.88        14\n",
            "          12       1.00      0.75      0.86         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.89      0.89      0.89         9\n",
            "          17       1.00      0.92      0.96        12\n",
            "          24       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.92       122\n",
            "   macro avg       0.94      0.92      0.92       122\n",
            "weighted avg       0.93      0.92      0.92       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8760330578512396, 'f1': 0.877160958225579, 'precision': 0.8887480173637199, 'recall': 0.8760330578512396}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       0.88      0.70      0.78        10\n",
            "           3       0.75      0.82      0.78        11\n",
            "           4       0.89      1.00      0.94        16\n",
            "           5       1.00      1.00      1.00         4\n",
            "           6       1.00      0.92      0.96        12\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.75      0.86         8\n",
            "          13       0.83      0.71      0.77         7\n",
            "          16       0.73      0.89      0.80         9\n",
            "          17       0.69      0.85      0.76        13\n",
            "          24       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.88       121\n",
            "   macro avg       0.90      0.87      0.88       121\n",
            "weighted avg       0.89      0.88      0.88       121\n",
            "\n",
            "Average validation scores: {'accuracy': 0.8736688795556157, 'f1': 0.875061656449444, 'precision': 0.8974507462610933, 'recall': 0.8736688795556157}\n",
            "Test set scores: {'accuracy': 0.9216061185468452, 'f1': 0.9212639675146906, 'precision': 0.9297227383751709, 'recall': 0.9216061185468452}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.95      1.00      0.97        36\n",
            "           2       0.94      0.71      0.81        48\n",
            "           3       0.76      1.00      0.86        53\n",
            "           4       0.97      1.00      0.98        61\n",
            "           5       1.00      1.00      1.00        13\n",
            "           6       0.98      0.96      0.97        48\n",
            "           7       0.98      0.92      0.95        60\n",
            "          12       0.94      0.89      0.92        38\n",
            "          13       0.96      0.89      0.93        28\n",
            "          16       0.94      0.82      0.88        39\n",
            "          17       0.85      0.95      0.90        66\n",
            "          24       1.00      0.91      0.95        33\n",
            "\n",
            "    accuracy                           0.92       523\n",
            "   macro avg       0.94      0.92      0.93       523\n",
            "weighted avg       0.93      0.92      0.92       523\n",
            "\n",
            "Evaluating model: SVM for subject 2\n",
            "Fold scores: {'accuracy': 0.8852459016393442, 'f1': 0.8844406097210238, 'precision': 0.8899817850637523, 'recall': 0.8852459016393442}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        12\n",
            "           2       0.80      0.80      0.80        10\n",
            "           3       0.73      0.92      0.81        12\n",
            "           4       0.88      0.88      0.88        16\n",
            "           5       1.00      1.00      1.00         4\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       0.86      0.75      0.80         8\n",
            "          16       0.78      0.70      0.74        10\n",
            "          17       0.86      0.92      0.89        13\n",
            "          24       1.00      0.67      0.80         6\n",
            "\n",
            "    accuracy                           0.89       122\n",
            "   macro avg       0.90      0.88      0.89       122\n",
            "weighted avg       0.89      0.89      0.88       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8770491803278688, 'f1': 0.8776550249465432, 'precision': 0.8834068936527952, 'recall': 0.8770491803278688}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.80      0.80      0.80        10\n",
            "           3       0.92      0.92      0.92        12\n",
            "           4       0.93      0.93      0.93        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      0.82      0.90        11\n",
            "           7       0.92      0.92      0.92        13\n",
            "          12       0.75      0.86      0.80         7\n",
            "          13       0.75      0.75      0.75         8\n",
            "          16       0.77      1.00      0.87        10\n",
            "          17       0.83      0.77      0.80        13\n",
            "          24       0.83      0.83      0.83         6\n",
            "\n",
            "    accuracy                           0.88       122\n",
            "   macro avg       0.88      0.88      0.87       122\n",
            "weighted avg       0.88      0.88      0.88       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9098360655737705, 'f1': 0.9101180786426688, 'precision': 0.9193013270882124, 'recall': 0.9098360655737705}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        12\n",
            "           2       0.67      0.80      0.73        10\n",
            "           3       0.71      0.83      0.77        12\n",
            "           4       1.00      1.00      1.00        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      1.00      1.00        14\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       1.00      0.57      0.73         7\n",
            "          16       0.90      0.90      0.90        10\n",
            "          17       0.92      0.85      0.88        13\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.91       122\n",
            "   macro avg       0.93      0.91      0.91       122\n",
            "weighted avg       0.92      0.91      0.91       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8442622950819673, 'f1': 0.8426433266206509, 'precision': 0.8547004425982246, 'recall': 0.8442622950819673}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.85      0.92      0.88        12\n",
            "           2       0.88      0.70      0.78        10\n",
            "           3       0.67      0.83      0.74        12\n",
            "           4       0.82      0.93      0.87        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      0.92      0.96        12\n",
            "           7       1.00      0.93      0.96        14\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       0.80      0.57      0.67         7\n",
            "          16       0.67      0.60      0.63        10\n",
            "          17       0.75      0.92      0.83        13\n",
            "          24       1.00      0.60      0.75         5\n",
            "\n",
            "    accuracy                           0.84       122\n",
            "   macro avg       0.87      0.83      0.84       122\n",
            "weighted avg       0.85      0.84      0.84       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8688524590163934, 'f1': 0.8685748717691822, 'precision': 0.8835815368602252, 'recall': 0.8688524590163934}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.86      1.00      0.92        12\n",
            "           2       1.00      0.70      0.82        10\n",
            "           3       0.73      0.92      0.81        12\n",
            "           4       0.92      0.80      0.86        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      1.00      1.00        14\n",
            "          12       0.67      0.57      0.62         7\n",
            "          13       0.56      0.71      0.63         7\n",
            "          16       1.00      0.70      0.82        10\n",
            "          17       0.86      0.92      0.89        13\n",
            "          24       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.87       122\n",
            "   macro avg       0.87      0.86      0.86       122\n",
            "weighted avg       0.88      0.87      0.87       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8770491803278688, 'f1': 0.8794981043876269, 'precision': 0.8881262180442508, 'recall': 0.8770491803278688}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      1.00      0.96        12\n",
            "           2       0.62      0.80      0.70        10\n",
            "           3       0.91      0.83      0.87        12\n",
            "           4       1.00      1.00      1.00        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       0.85      0.92      0.88        12\n",
            "           7       1.00      0.93      0.96        14\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.88      0.70      0.78        10\n",
            "          17       0.69      0.75      0.72        12\n",
            "          24       0.80      0.80      0.80         5\n",
            "\n",
            "    accuracy                           0.88       122\n",
            "   macro avg       0.89      0.87      0.88       122\n",
            "weighted avg       0.89      0.88      0.88       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8524590163934426, 'f1': 0.8528446465992063, 'precision': 0.8657853985722836, 'recall': 0.8524590163934426}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.75      0.86        12\n",
            "           2       0.75      0.60      0.67        10\n",
            "           3       0.64      0.82      0.72        11\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      0.80      0.89         5\n",
            "           6       0.91      0.83      0.87        12\n",
            "           7       1.00      0.93      0.96        14\n",
            "          12       0.78      0.88      0.82         8\n",
            "          13       0.83      0.71      0.77         7\n",
            "          16       0.77      1.00      0.87        10\n",
            "          17       0.77      0.83      0.80        12\n",
            "          24       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.85       122\n",
            "   macro avg       0.86      0.85      0.84       122\n",
            "weighted avg       0.87      0.85      0.85       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8770491803278688, 'f1': 0.8771739460540551, 'precision': 0.8891762608975724, 'recall': 0.8770491803278688}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.75      0.86        12\n",
            "           2       0.73      0.80      0.76        10\n",
            "           3       0.77      0.91      0.83        11\n",
            "           4       0.94      0.94      0.94        16\n",
            "           5       1.00      0.60      0.75         5\n",
            "           6       1.00      0.92      0.96        12\n",
            "           7       0.93      1.00      0.97        14\n",
            "          12       0.88      0.88      0.88         8\n",
            "          13       0.75      0.86      0.80         7\n",
            "          16       0.90      0.90      0.90        10\n",
            "          17       0.79      0.92      0.85        12\n",
            "          24       1.00      0.80      0.89         5\n",
            "\n",
            "    accuracy                           0.88       122\n",
            "   macro avg       0.89      0.86      0.86       122\n",
            "weighted avg       0.89      0.88      0.88       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9344262295081968, 'f1': 0.9341747008290505, 'precision': 0.9416771752837325, 'recall': 0.9344262295081968}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.89      0.80      0.84        10\n",
            "           3       0.85      1.00      0.92        11\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       0.83      1.00      0.91         5\n",
            "           6       0.92      1.00      0.96        12\n",
            "           7       0.93      0.93      0.93        14\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       0.78      1.00      0.88         7\n",
            "          16       1.00      0.78      0.88         9\n",
            "          17       1.00      0.92      0.96        12\n",
            "          24       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.93       122\n",
            "   macro avg       0.93      0.93      0.93       122\n",
            "weighted avg       0.94      0.93      0.93       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8677685950413223, 'f1': 0.8670945924946052, 'precision': 0.8853198225099053, 'recall': 0.8677685950413223}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.67      0.80        12\n",
            "           2       0.82      0.90      0.86        10\n",
            "           3       0.80      0.73      0.76        11\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       0.80      1.00      0.89         4\n",
            "           6       1.00      0.92      0.96        12\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       0.89      1.00      0.94         8\n",
            "          13       0.60      0.86      0.71         7\n",
            "          16       0.69      1.00      0.82         9\n",
            "          17       0.80      0.62      0.70        13\n",
            "          24       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.87       121\n",
            "   macro avg       0.87      0.88      0.86       121\n",
            "weighted avg       0.89      0.87      0.87       121\n",
            "\n",
            "Average validation scores: {'accuracy': 0.8793998103238042, 'f1': 0.8794217902064613, 'precision': 0.8901056860570954, 'recall': 0.8793998103238042}\n",
            "Test set scores: {'accuracy': 0.9024856596558317, 'f1': 0.9033170162886092, 'precision': 0.908830250474334, 'recall': 0.9024856596558317}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.88      0.97      0.92        36\n",
            "           2       0.84      0.85      0.85        48\n",
            "           3       0.90      0.87      0.88        53\n",
            "           4       0.97      1.00      0.98        61\n",
            "           5       0.87      1.00      0.93        13\n",
            "           6       0.98      1.00      0.99        48\n",
            "           7       0.98      0.88      0.93        60\n",
            "          12       0.79      0.87      0.82        38\n",
            "          13       0.69      0.86      0.76        28\n",
            "          16       0.97      0.77      0.86        39\n",
            "          17       0.91      0.88      0.89        66\n",
            "          24       1.00      0.91      0.95        33\n",
            "\n",
            "    accuracy                           0.90       523\n",
            "   macro avg       0.90      0.91      0.90       523\n",
            "weighted avg       0.91      0.90      0.90       523\n",
            "\n",
            "Evaluating model: Naive Bayes for subject 2\n",
            "Fold scores: {'accuracy': 0.8360655737704918, 'f1': 0.8418465272570231, 'precision': 0.8688110614340122, 'recall': 0.8360655737704918}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       0.67      0.60      0.63        10\n",
            "           3       1.00      0.75      0.86        12\n",
            "           4       1.00      0.81      0.90        16\n",
            "           5       1.00      1.00      1.00         4\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.78      1.00      0.88         7\n",
            "          13       0.58      0.88      0.70         8\n",
            "          16       0.73      0.80      0.76        10\n",
            "          17       0.61      0.85      0.71        13\n",
            "          24       1.00      0.67      0.80         6\n",
            "\n",
            "    accuracy                           0.84       122\n",
            "   macro avg       0.86      0.84      0.84       122\n",
            "weighted avg       0.87      0.84      0.84       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9016393442622951, 'f1': 0.90418057453425, 'precision': 0.9150929671421476, 'recall': 0.9016393442622951}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.73      0.80      0.76        10\n",
            "           3       0.91      0.83      0.87        12\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.86      0.86      0.86         7\n",
            "          13       0.80      1.00      0.89         8\n",
            "          16       0.71      1.00      0.83        10\n",
            "          17       0.92      0.85      0.88        13\n",
            "          24       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.90       122\n",
            "   macro avg       0.91      0.90      0.90       122\n",
            "weighted avg       0.92      0.90      0.90       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8934426229508197, 'f1': 0.8903943081152633, 'precision': 0.8967990115531098, 'recall': 0.8934426229508197}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.73      0.80      0.76        10\n",
            "           3       0.83      0.83      0.83        12\n",
            "           4       1.00      1.00      1.00        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      1.00      1.00        14\n",
            "          12       0.78      1.00      0.88         7\n",
            "          13       0.80      0.57      0.67         7\n",
            "          16       0.77      1.00      0.87        10\n",
            "          17       0.80      0.62      0.70        13\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.89       122\n",
            "   macro avg       0.89      0.89      0.89       122\n",
            "weighted avg       0.90      0.89      0.89       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8770491803278688, 'f1': 0.8812120761113068, 'precision': 0.8969892812105928, 'recall': 0.8770491803278688}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        12\n",
            "           2       0.90      0.90      0.90        10\n",
            "           3       0.85      0.92      0.88        12\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      0.92      0.96        12\n",
            "           7       1.00      0.93      0.96        14\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       0.62      0.80      0.70        10\n",
            "          17       0.62      0.77      0.69        13\n",
            "          24       1.00      0.60      0.75         5\n",
            "\n",
            "    accuracy                           0.88       122\n",
            "   macro avg       0.91      0.87      0.88       122\n",
            "weighted avg       0.90      0.88      0.88       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8852459016393442, 'f1': 0.8879494340214185, 'precision': 0.9011425732737208, 'recall': 0.8852459016393442}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.64      0.70      0.67        10\n",
            "           3       0.91      0.83      0.87        12\n",
            "           4       1.00      0.87      0.93        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      1.00      1.00        14\n",
            "          12       0.71      0.71      0.71         7\n",
            "          13       0.86      0.86      0.86         7\n",
            "          16       1.00      0.70      0.82        10\n",
            "          17       0.67      0.92      0.77        13\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.89       122\n",
            "   macro avg       0.90      0.88      0.89       122\n",
            "weighted avg       0.90      0.89      0.89       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9098360655737705, 'f1': 0.9117235553443679, 'precision': 0.9174022698612863, 'recall': 0.9098360655737705}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.70      0.70      0.70        10\n",
            "           3       1.00      1.00      1.00        12\n",
            "           4       1.00      1.00      1.00        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      0.92      0.96        12\n",
            "           7       1.00      0.93      0.96        14\n",
            "          12       0.88      0.88      0.88         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.69      0.90      0.78        10\n",
            "          17       0.75      0.75      0.75        12\n",
            "          24       1.00      0.80      0.89         5\n",
            "\n",
            "    accuracy                           0.91       122\n",
            "   macro avg       0.92      0.91      0.91       122\n",
            "weighted avg       0.92      0.91      0.91       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8852459016393442, 'f1': 0.8877544408549396, 'precision': 0.9029424127784783, 'recall': 0.8852459016393442}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.75      0.86        12\n",
            "           2       0.67      0.80      0.73        10\n",
            "           3       1.00      0.91      0.95        11\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      0.80      0.89         5\n",
            "           6       1.00      0.83      0.91        12\n",
            "           7       1.00      1.00      1.00        14\n",
            "          12       0.88      0.88      0.88         8\n",
            "          13       0.71      0.71      0.71         7\n",
            "          16       0.77      1.00      0.87        10\n",
            "          17       0.73      0.92      0.81        12\n",
            "          24       1.00      0.80      0.89         5\n",
            "\n",
            "    accuracy                           0.89       122\n",
            "   macro avg       0.90      0.87      0.87       122\n",
            "weighted avg       0.90      0.89      0.89       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8770491803278688, 'f1': 0.8805999881246946, 'precision': 0.9036710102283873, 'recall': 0.8770491803278688}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.75      0.86        12\n",
            "           2       0.80      0.80      0.80        10\n",
            "           3       1.00      0.91      0.95        11\n",
            "           4       1.00      0.94      0.97        16\n",
            "           5       1.00      0.60      0.75         5\n",
            "           6       1.00      0.83      0.91        12\n",
            "           7       1.00      1.00      1.00        14\n",
            "          12       0.78      0.88      0.82         8\n",
            "          13       0.86      0.86      0.86         7\n",
            "          16       0.77      1.00      0.87        10\n",
            "          17       0.61      0.92      0.73        12\n",
            "          24       1.00      0.80      0.89         5\n",
            "\n",
            "    accuracy                           0.88       122\n",
            "   macro avg       0.90      0.86      0.87       122\n",
            "weighted avg       0.90      0.88      0.88       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9180327868852459, 'f1': 0.9134103298037723, 'precision': 0.9219697652074701, 'recall': 0.9180327868852459}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.86      1.00      0.92        12\n",
            "           2       0.83      0.50      0.62        10\n",
            "           3       0.85      1.00      0.92        11\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      0.93      0.96        14\n",
            "          12       1.00      0.75      0.86         8\n",
            "          13       0.88      1.00      0.93         7\n",
            "          16       0.89      0.89      0.89         9\n",
            "          17       0.79      0.92      0.85        12\n",
            "          24       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.92       122\n",
            "   macro avg       0.92      0.92      0.91       122\n",
            "weighted avg       0.92      0.92      0.91       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8760330578512396, 'f1': 0.8801981417791694, 'precision': 0.8992768595041323, 'recall': 0.8760330578512396}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.75      0.86        12\n",
            "           2       0.70      0.70      0.70        10\n",
            "           3       1.00      0.82      0.90        11\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      1.00      1.00         4\n",
            "           6       1.00      0.92      0.96        12\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       0.88      0.88      0.88         8\n",
            "          13       0.86      0.86      0.86         7\n",
            "          16       0.56      1.00      0.72         9\n",
            "          17       0.75      0.69      0.72        13\n",
            "          24       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.88       121\n",
            "   macro avg       0.90      0.88      0.88       121\n",
            "weighted avg       0.90      0.88      0.88       121\n",
            "\n",
            "Average validation scores: {'accuracy': 0.8859639615228287, 'f1': 0.8879269375946206, 'precision': 0.9024097212193338, 'recall': 0.8859639615228287}\n",
            "Test set scores: {'accuracy': 0.8852772466539197, 'f1': 0.8881705455441274, 'precision': 0.9017047596319258, 'recall': 0.8852772466539197}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        36\n",
            "           2       0.91      0.65      0.76        48\n",
            "           3       0.94      0.96      0.95        53\n",
            "           4       1.00      0.98      0.99        61\n",
            "           5       1.00      1.00      1.00        13\n",
            "           6       1.00      0.92      0.96        48\n",
            "           7       1.00      0.87      0.93        60\n",
            "          12       0.87      0.87      0.87        38\n",
            "          13       0.70      0.93      0.80        28\n",
            "          16       0.60      0.85      0.70        39\n",
            "          17       0.77      0.80      0.79        66\n",
            "          24       1.00      0.94      0.97        33\n",
            "\n",
            "    accuracy                           0.89       523\n",
            "   macro avg       0.90      0.90      0.89       523\n",
            "weighted avg       0.90      0.89      0.89       523\n",
            "\n",
            "   subject_id        model  val_accuracy    val_f1  val_precision  val_recall  \\\n",
            "0           1         k-NN      0.895397  0.894804       0.909544    0.895397   \n",
            "1           1          SVM      0.887646  0.887347       0.899490    0.887646   \n",
            "2           1  Naive Bayes      0.898906  0.899955       0.914063    0.898906   \n",
            "3           2         k-NN      0.873669  0.875062       0.897451    0.873669   \n",
            "4           2          SVM      0.879400  0.879422       0.890106    0.879400   \n",
            "5           2  Naive Bayes      0.885964  0.887927       0.902410    0.885964   \n",
            "\n",
            "   test_accuracy   test_f1  test_precision  test_recall  \n",
            "0       0.883065  0.883872        0.888693     0.883065  \n",
            "1       0.889113  0.889325        0.893333     0.889113  \n",
            "2       0.911290  0.911860        0.918823     0.911290  \n",
            "3       0.921606  0.921264        0.929723     0.921606  \n",
            "4       0.902486  0.903317        0.908830     0.902486  \n",
            "5       0.885277  0.888171        0.901705     0.885277  \n"
          ]
        }
      ],
      "source": [
        "# Generate features and labels for each subject using PreProcessor and FeatureExtraction\n",
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "file_path =  '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject102.dat'\n",
        "\n",
        "preprocessor.initializeDataFrame(file_path)\n",
        "preprocessor.dataCleaning()\n",
        "preprocessor.applyPreProcessing()\n",
        "\n",
        "subject_id = int(file_path[-5])\n",
        "subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z8j4_Dbnmar",
        "outputId": "f2ef3a6e-e702-4818-9b02-114176efabdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame still contains some NAN values\n",
            "Evaluating model: k-NN for subject 3\n",
            "Fold scores: {'accuracy': 0.9012345679012346, 'f1': 0.8977942585995285, 'precision': 0.9147300895666909, 'recall': 0.9012345679012346}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       0.93      1.00      0.97        14\n",
            "           3       0.90      1.00      0.95         9\n",
            "           4       1.00      1.00      1.00        15\n",
            "          12       1.00      0.50      0.67         4\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       0.88      0.70      0.78        10\n",
            "          17       0.71      0.92      0.80        13\n",
            "\n",
            "    accuracy                           0.90        81\n",
            "   macro avg       0.93      0.85      0.87        81\n",
            "weighted avg       0.91      0.90      0.90        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.8888888888888888, 'f1': 0.8872067664182359, 'precision': 0.9095895480699402, 'recall': 0.8888888888888888}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.80      0.89        10\n",
            "           2       0.92      0.86      0.89        14\n",
            "           3       0.75      1.00      0.86         9\n",
            "           4       0.94      1.00      0.97        15\n",
            "          12       1.00      1.00      1.00         4\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       1.00      0.67      0.80         9\n",
            "          17       0.76      1.00      0.87        13\n",
            "\n",
            "    accuracy                           0.89        81\n",
            "   macro avg       0.92      0.88      0.89        81\n",
            "weighted avg       0.91      0.89      0.89        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.8641975308641975, 'f1': 0.8659203910665899, 'precision': 0.8931216931216931, 'recall': 0.8641975308641975}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.90      0.95        10\n",
            "           2       0.86      0.92      0.89        13\n",
            "           3       0.88      0.70      0.78        10\n",
            "           4       0.93      0.93      0.93        15\n",
            "          12       1.00      0.75      0.86         4\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       1.00      0.67      0.80         9\n",
            "          17       0.65      1.00      0.79        13\n",
            "\n",
            "    accuracy                           0.86        81\n",
            "   macro avg       0.91      0.84      0.86        81\n",
            "weighted avg       0.89      0.86      0.87        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.8641975308641975, 'f1': 0.862912425095661, 'precision': 0.8840958605664487, 'recall': 0.8641975308641975}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.90      0.95        10\n",
            "           2       0.92      0.92      0.92        13\n",
            "           3       0.89      0.89      0.89         9\n",
            "           4       1.00      1.00      1.00        15\n",
            "          12       0.80      1.00      0.89         4\n",
            "          13       1.00      0.50      0.67         8\n",
            "          16       0.78      0.78      0.78         9\n",
            "          17       0.65      0.85      0.73        13\n",
            "\n",
            "    accuracy                           0.86        81\n",
            "   macro avg       0.88      0.85      0.85        81\n",
            "weighted avg       0.88      0.86      0.86        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.9506172839506173, 'f1': 0.950695256660169, 'precision': 0.953615520282187, 'recall': 0.9506172839506173}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        10\n",
            "           2       1.00      0.92      0.96        13\n",
            "           3       0.90      1.00      0.95         9\n",
            "           4       1.00      1.00      1.00        15\n",
            "          12       1.00      0.80      0.89         5\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.89      0.89      0.89         9\n",
            "          17       0.86      0.92      0.89        13\n",
            "\n",
            "    accuracy                           0.95        81\n",
            "   macro avg       0.96      0.94      0.95        81\n",
            "weighted avg       0.95      0.95      0.95        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.8888888888888888, 'f1': 0.8909560731284156, 'precision': 0.9039276204308884, 'recall': 0.8888888888888888}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.90      0.95        10\n",
            "           2       0.85      0.85      0.85        13\n",
            "           3       1.00      0.78      0.88         9\n",
            "           4       1.00      1.00      1.00        15\n",
            "          12       0.83      1.00      0.91         5\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.88      0.78      0.82         9\n",
            "          17       0.71      0.92      0.80        13\n",
            "\n",
            "    accuracy                           0.89        81\n",
            "   macro avg       0.91      0.89      0.89        81\n",
            "weighted avg       0.90      0.89      0.89        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.875, 'f1': 0.8766653228931507, 'precision': 0.902549793956044, 'recall': 0.875}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.80      0.89        10\n",
            "           2       1.00      0.69      0.82        13\n",
            "           3       0.64      1.00      0.78         9\n",
            "           4       0.94      1.00      0.97        15\n",
            "          12       1.00      0.80      0.89         5\n",
            "          13       0.88      1.00      0.93         7\n",
            "          16       1.00      0.89      0.94         9\n",
            "          17       0.77      0.83      0.80        12\n",
            "\n",
            "    accuracy                           0.88        80\n",
            "   macro avg       0.90      0.88      0.88        80\n",
            "weighted avg       0.90      0.88      0.88        80\n",
            "\n",
            "Fold scores: {'accuracy': 0.8875, 'f1': 0.8882579588334106, 'precision': 0.8931473214285713, 'recall': 0.8875}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        10\n",
            "           2       1.00      0.92      0.96        13\n",
            "           3       0.70      0.78      0.74         9\n",
            "           4       0.94      1.00      0.97        15\n",
            "          12       1.00      0.75      0.86         4\n",
            "          13       0.86      0.86      0.86         7\n",
            "          16       0.88      0.78      0.82         9\n",
            "          17       0.79      0.85      0.81        13\n",
            "\n",
            "    accuracy                           0.89        80\n",
            "   macro avg       0.89      0.87      0.88        80\n",
            "weighted avg       0.89      0.89      0.89        80\n",
            "\n",
            "Fold scores: {'accuracy': 0.8625, 'f1': 0.8640716374269006, 'precision': 0.8705357142857142, 'recall': 0.8625}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        10\n",
            "           2       0.85      0.85      0.85        13\n",
            "           3       0.50      0.56      0.53         9\n",
            "           4       1.00      1.00      1.00        15\n",
            "          12       0.75      0.75      0.75         4\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       0.89      0.89      0.89         9\n",
            "          17       0.86      0.92      0.89        13\n",
            "\n",
            "    accuracy                           0.86        80\n",
            "   macro avg       0.86      0.83      0.84        80\n",
            "weighted avg       0.87      0.86      0.86        80\n",
            "\n",
            "Fold scores: {'accuracy': 0.875, 'f1': 0.8773383450720413, 'precision': 0.8973717948717947, 'recall': 0.875}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.89      0.94         9\n",
            "           2       0.92      0.86      0.89        14\n",
            "           3       0.80      0.89      0.84         9\n",
            "           4       0.93      0.93      0.93        15\n",
            "          12       1.00      0.75      0.86         4\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       1.00      0.67      0.80         9\n",
            "          17       0.67      0.92      0.77        13\n",
            "\n",
            "    accuracy                           0.88        80\n",
            "   macro avg       0.92      0.86      0.88        80\n",
            "weighted avg       0.90      0.88      0.88        80\n",
            "\n",
            "Average validation scores: {'accuracy': 0.8858024691358025, 'f1': 0.8861818435194102, 'precision': 0.9022684956579973, 'recall': 0.8858024691358025}\n",
            "Test set scores: {'accuracy': 0.8786127167630058, 'f1': 0.8796157084095687, 'precision': 0.8877130373884754, 'recall': 0.8786127167630058}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.98      0.88      0.92        48\n",
            "           2       0.96      0.93      0.95        58\n",
            "           3       0.74      0.89      0.81        45\n",
            "           4       0.91      0.98      0.94        43\n",
            "          12       0.91      0.83      0.87        24\n",
            "          13       0.95      0.75      0.84        28\n",
            "          16       0.89      0.79      0.84        43\n",
            "          17       0.78      0.89      0.84        57\n",
            "\n",
            "    accuracy                           0.88       346\n",
            "   macro avg       0.89      0.87      0.88       346\n",
            "weighted avg       0.89      0.88      0.88       346\n",
            "\n",
            "Evaluating model: SVM for subject 3\n",
            "Fold scores: {'accuracy': 0.8395061728395061, 'f1': 0.8388359788359787, 'precision': 0.8412832023943134, 'recall': 0.8395061728395061}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       0.86      0.86      0.86        14\n",
            "           3       0.64      0.78      0.70         9\n",
            "           4       1.00      1.00      1.00        15\n",
            "          12       0.67      0.50      0.57         4\n",
            "          13       0.86      0.86      0.86         7\n",
            "          16       0.80      0.80      0.80        10\n",
            "          17       0.75      0.69      0.72        13\n",
            "\n",
            "    accuracy                           0.84        81\n",
            "   macro avg       0.82      0.81      0.81        81\n",
            "weighted avg       0.84      0.84      0.84        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.9135802469135802, 'f1': 0.9151685574923327, 'precision': 0.9307270233196159, 'recall': 0.9135802469135802}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.80      0.89        10\n",
            "           2       0.93      0.93      0.93        14\n",
            "           3       0.89      0.89      0.89         9\n",
            "           4       1.00      1.00      1.00        15\n",
            "          12       1.00      1.00      1.00         4\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       1.00      0.78      0.88         9\n",
            "          17       0.72      1.00      0.84        13\n",
            "\n",
            "    accuracy                           0.91        81\n",
            "   macro avg       0.94      0.91      0.92        81\n",
            "weighted avg       0.93      0.91      0.92        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.8518518518518519, 'f1': 0.8519796428265153, 'precision': 0.874162257495591, 'recall': 0.8518518518518519}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.90      0.95        10\n",
            "           2       0.79      0.85      0.81        13\n",
            "           3       0.71      0.50      0.59        10\n",
            "           4       1.00      0.93      0.97        15\n",
            "          12       1.00      1.00      1.00         4\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       1.00      0.78      0.88         9\n",
            "          17       0.65      1.00      0.79        13\n",
            "\n",
            "    accuracy                           0.85        81\n",
            "   macro avg       0.89      0.85      0.86        81\n",
            "weighted avg       0.87      0.85      0.85        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.8148148148148148, 'f1': 0.8110972939738754, 'precision': 0.816901822457378, 'recall': 0.8148148148148148}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.90      0.90      0.90        10\n",
            "           2       0.73      0.85      0.79        13\n",
            "           3       0.75      0.67      0.71         9\n",
            "           4       1.00      1.00      1.00        15\n",
            "          12       0.75      0.75      0.75         4\n",
            "          13       0.80      0.50      0.62         8\n",
            "          16       0.80      0.89      0.84         9\n",
            "          17       0.71      0.77      0.74        13\n",
            "\n",
            "    accuracy                           0.81        81\n",
            "   macro avg       0.81      0.79      0.79        81\n",
            "weighted avg       0.82      0.81      0.81        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.8641975308641975, 'f1': 0.8646913580246912, 'precision': 0.8662551440329217, 'recall': 0.8641975308641975}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        10\n",
            "           2       0.85      0.85      0.85        13\n",
            "           3       0.56      0.56      0.56         9\n",
            "           4       1.00      1.00      1.00        15\n",
            "          12       0.80      0.80      0.80         5\n",
            "          13       0.75      0.86      0.80         7\n",
            "          16       0.89      0.89      0.89         9\n",
            "          17       0.92      0.85      0.88        13\n",
            "\n",
            "    accuracy                           0.86        81\n",
            "   macro avg       0.84      0.85      0.85        81\n",
            "weighted avg       0.87      0.86      0.86        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.9012345679012346, 'f1': 0.9001614005491454, 'precision': 0.9132716049382715, 'recall': 0.9012345679012346}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.90      0.95        10\n",
            "           2       0.80      0.92      0.86        13\n",
            "           3       1.00      0.78      0.88         9\n",
            "           4       1.00      1.00      1.00        15\n",
            "          12       1.00      1.00      1.00         5\n",
            "          13       0.88      1.00      0.93         7\n",
            "          16       0.75      1.00      0.86         9\n",
            "          17       0.90      0.69      0.78        13\n",
            "\n",
            "    accuracy                           0.90        81\n",
            "   macro avg       0.92      0.91      0.91        81\n",
            "weighted avg       0.91      0.90      0.90        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.8875, 'f1': 0.8879150087115872, 'precision': 0.8972332702020202, 'recall': 0.8875}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.89      0.80      0.84        10\n",
            "           2       0.91      0.77      0.83        13\n",
            "           3       0.67      0.89      0.76         9\n",
            "           4       0.94      1.00      0.97        15\n",
            "          12       1.00      0.80      0.89         5\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.90      1.00      0.95         9\n",
            "          17       0.91      0.83      0.87        12\n",
            "\n",
            "    accuracy                           0.89        80\n",
            "   macro avg       0.90      0.89      0.89        80\n",
            "weighted avg       0.90      0.89      0.89        80\n",
            "\n",
            "Fold scores: {'accuracy': 0.8875, 'f1': 0.8879227458008293, 'precision': 0.8962155032467531, 'recall': 0.8875}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        10\n",
            "           2       1.00      0.92      0.96        13\n",
            "           3       0.88      0.78      0.82         9\n",
            "           4       0.94      1.00      0.97        15\n",
            "          12       0.75      0.75      0.75         4\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       0.73      0.89      0.80         9\n",
            "          17       0.79      0.85      0.81        13\n",
            "\n",
            "    accuracy                           0.89        80\n",
            "   macro avg       0.88      0.86      0.87        80\n",
            "weighted avg       0.90      0.89      0.89        80\n",
            "\n",
            "Fold scores: {'accuracy': 0.825, 'f1': 0.8236113584972611, 'precision': 0.8358482142857142, 'recall': 0.825}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.83      1.00      0.91        10\n",
            "           2       0.86      0.92      0.89        13\n",
            "           3       0.62      0.56      0.59         9\n",
            "           4       1.00      0.93      0.97        15\n",
            "          12       0.60      0.75      0.67         4\n",
            "          13       0.83      0.71      0.77         7\n",
            "          16       1.00      0.67      0.80         9\n",
            "          17       0.73      0.85      0.79        13\n",
            "\n",
            "    accuracy                           0.82        80\n",
            "   macro avg       0.81      0.80      0.80        80\n",
            "weighted avg       0.84      0.82      0.82        80\n",
            "\n",
            "Fold scores: {'accuracy': 0.9375, 'f1': 0.9373056895676198, 'precision': 0.9417261904761904, 'recall': 0.9375}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.89      0.94         9\n",
            "           2       0.93      1.00      0.97        14\n",
            "           3       0.80      0.89      0.84         9\n",
            "           4       0.93      0.93      0.93        15\n",
            "          12       1.00      0.75      0.86         4\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       1.00      0.89      0.94         9\n",
            "          17       0.93      1.00      0.96        13\n",
            "\n",
            "    accuracy                           0.94        80\n",
            "   macro avg       0.95      0.92      0.93        80\n",
            "weighted avg       0.94      0.94      0.94        80\n",
            "\n",
            "Average validation scores: {'accuracy': 0.8722685185185185, 'f1': 0.8718689034279835, 'precision': 0.881362423284877, 'recall': 0.8722685185185185}\n",
            "Test set scores: {'accuracy': 0.8641618497109826, 'f1': 0.8640589107574779, 'precision': 0.8653332118467786, 'recall': 0.8641618497109826}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.88      0.90      0.89        48\n",
            "           2       0.88      0.90      0.89        58\n",
            "           3       0.74      0.76      0.75        45\n",
            "           4       0.96      1.00      0.98        43\n",
            "          12       0.86      0.79      0.83        24\n",
            "          13       0.96      0.82      0.88        28\n",
            "          16       0.88      0.86      0.87        43\n",
            "          17       0.81      0.84      0.83        57\n",
            "\n",
            "    accuracy                           0.86       346\n",
            "   macro avg       0.87      0.86      0.86       346\n",
            "weighted avg       0.87      0.86      0.86       346\n",
            "\n",
            "Evaluating model: Naive Bayes for subject 3\n",
            "Fold scores: {'accuracy': 0.9259259259259259, 'f1': 0.9261980529037058, 'precision': 0.9313932980599648, 'recall': 0.9259259259259259}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.90      1.00      0.95         9\n",
            "           2       1.00      0.86      0.92        14\n",
            "           3       0.89      0.89      0.89         9\n",
            "           4       1.00      1.00      1.00        15\n",
            "          12       0.80      1.00      0.89         4\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.90      0.90      0.90        10\n",
            "          17       0.86      0.92      0.89        13\n",
            "\n",
            "    accuracy                           0.93        81\n",
            "   macro avg       0.92      0.93      0.92        81\n",
            "weighted avg       0.93      0.93      0.93        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.9012345679012346, 'f1': 0.902419715416485, 'precision': 0.9158389450056117, 'recall': 0.9012345679012346}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.80      0.89        10\n",
            "           2       1.00      0.86      0.92        14\n",
            "           3       0.73      0.89      0.80         9\n",
            "           4       1.00      1.00      1.00        15\n",
            "          12       0.80      1.00      0.89         4\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.88      0.78      0.82         9\n",
            "          17       0.81      1.00      0.90        13\n",
            "\n",
            "    accuracy                           0.90        81\n",
            "   macro avg       0.90      0.90      0.89        81\n",
            "weighted avg       0.92      0.90      0.90        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.8641975308641975, 'f1': 0.8627107180320688, 'precision': 0.8794764689501531, 'recall': 0.8641975308641975}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.90      0.90      0.90        10\n",
            "           2       1.00      0.92      0.96        13\n",
            "           3       0.71      0.50      0.59        10\n",
            "           4       1.00      0.87      0.93        15\n",
            "          12       0.80      1.00      0.89         4\n",
            "          13       0.86      0.86      0.86         7\n",
            "          16       1.00      0.89      0.94         9\n",
            "          17       0.68      1.00      0.81        13\n",
            "\n",
            "    accuracy                           0.86        81\n",
            "   macro avg       0.87      0.87      0.86        81\n",
            "weighted avg       0.88      0.86      0.86        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.8395061728395061, 'f1': 0.8445311997943578, 'precision': 0.8855281207133059, 'recall': 0.8395061728395061}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.90      0.95        10\n",
            "           2       1.00      0.85      0.92        13\n",
            "           3       0.75      1.00      0.86         9\n",
            "           4       1.00      0.87      0.93        15\n",
            "          12       0.44      1.00      0.62         4\n",
            "          13       1.00      0.50      0.67         8\n",
            "          16       0.80      0.89      0.84         9\n",
            "          17       0.77      0.77      0.77        13\n",
            "\n",
            "    accuracy                           0.84        81\n",
            "   macro avg       0.85      0.85      0.82        81\n",
            "weighted avg       0.89      0.84      0.84        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.9135802469135802, 'f1': 0.9169476372924649, 'precision': 0.9276227887338999, 'recall': 0.9135802469135802}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        10\n",
            "           2       1.00      0.85      0.92        13\n",
            "           3       1.00      1.00      1.00         9\n",
            "           4       1.00      0.93      0.97        15\n",
            "          12       0.57      0.80      0.67         5\n",
            "          13       0.86      0.86      0.86         7\n",
            "          16       0.82      1.00      0.90         9\n",
            "          17       0.92      0.85      0.88        13\n",
            "\n",
            "    accuracy                           0.91        81\n",
            "   macro avg       0.90      0.91      0.90        81\n",
            "weighted avg       0.93      0.91      0.92        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.8888888888888888, 'f1': 0.8906742526358673, 'precision': 0.9004769921436588, 'recall': 0.8888888888888888}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.90      0.95        10\n",
            "           2       1.00      0.85      0.92        13\n",
            "           3       0.88      0.78      0.82         9\n",
            "           4       1.00      0.93      0.97        15\n",
            "          12       0.83      1.00      0.91         5\n",
            "          13       0.86      0.86      0.86         7\n",
            "          16       0.82      1.00      0.90         9\n",
            "          17       0.73      0.85      0.79        13\n",
            "\n",
            "    accuracy                           0.89        81\n",
            "   macro avg       0.89      0.90      0.89        81\n",
            "weighted avg       0.90      0.89      0.89        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.8625, 'f1': 0.8607979539365657, 'precision': 0.89625, 'recall': 0.8625}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.80      0.89        10\n",
            "           2       1.00      0.62      0.76        13\n",
            "           3       0.73      0.89      0.80         9\n",
            "           4       1.00      0.93      0.97        15\n",
            "          12       1.00      0.60      0.75         5\n",
            "          13       0.64      1.00      0.78         7\n",
            "          16       0.90      1.00      0.95         9\n",
            "          17       0.80      1.00      0.89        12\n",
            "\n",
            "    accuracy                           0.86        80\n",
            "   macro avg       0.88      0.85      0.85        80\n",
            "weighted avg       0.90      0.86      0.86        80\n",
            "\n",
            "Fold scores: {'accuracy': 0.8625, 'f1': 0.8609086887477314, 'precision': 0.865982142857143, 'recall': 0.8625}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        10\n",
            "           2       1.00      0.92      0.96        13\n",
            "           3       0.71      0.56      0.63         9\n",
            "           4       1.00      0.93      0.97        15\n",
            "          12       0.50      0.50      0.50         4\n",
            "          13       0.71      0.71      0.71         7\n",
            "          16       0.90      1.00      0.95         9\n",
            "          17       0.75      0.92      0.83        13\n",
            "\n",
            "    accuracy                           0.86        80\n",
            "   macro avg       0.82      0.82      0.82        80\n",
            "weighted avg       0.87      0.86      0.86        80\n",
            "\n",
            "Fold scores: {'accuracy': 0.8375, 'f1': 0.8413371143375681, 'precision': 0.8510037878787878, 'recall': 0.8375}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        10\n",
            "           2       0.92      0.85      0.88        13\n",
            "           3       0.60      0.67      0.63         9\n",
            "           4       1.00      0.93      0.97        15\n",
            "          12       0.60      0.75      0.67         4\n",
            "          13       0.71      0.71      0.71         7\n",
            "          16       0.73      0.89      0.80         9\n",
            "          17       0.91      0.77      0.83        13\n",
            "\n",
            "    accuracy                           0.84        80\n",
            "   macro avg       0.81      0.82      0.81        80\n",
            "weighted avg       0.85      0.84      0.84        80\n",
            "\n",
            "Fold scores: {'accuracy': 0.9125, 'f1': 0.914106490872211, 'precision': 0.9263494318181819, 'recall': 0.9125}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.89      0.94         9\n",
            "           2       1.00      0.79      0.88        14\n",
            "           3       0.73      0.89      0.80         9\n",
            "           4       1.00      0.93      0.97        15\n",
            "          12       1.00      1.00      1.00         4\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.89      0.89      0.89         9\n",
            "          17       0.81      1.00      0.90        13\n",
            "\n",
            "    accuracy                           0.91        80\n",
            "   macro avg       0.93      0.92      0.92        80\n",
            "weighted avg       0.93      0.91      0.91        80\n",
            "\n",
            "Average validation scores: {'accuracy': 0.8808333333333334, 'f1': 0.8820631823969025, 'precision': 0.8979921976160707, 'recall': 0.8808333333333334}\n",
            "Test set scores: {'accuracy': 0.8959537572254336, 'f1': 0.8971016582675342, 'precision': 0.904920749530901, 'recall': 0.8959537572254336}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.98      0.88      0.92        48\n",
            "           2       1.00      0.90      0.95        58\n",
            "           3       0.77      0.91      0.84        45\n",
            "           4       1.00      0.95      0.98        43\n",
            "          12       0.81      0.92      0.86        24\n",
            "          13       0.91      0.75      0.82        28\n",
            "          16       0.82      0.98      0.89        43\n",
            "          17       0.88      0.86      0.87        57\n",
            "\n",
            "    accuracy                           0.90       346\n",
            "   macro avg       0.90      0.89      0.89       346\n",
            "weighted avg       0.90      0.90      0.90       346\n",
            "\n",
            "   subject_id        model  val_accuracy    val_f1  val_precision  val_recall  \\\n",
            "0           1         k-NN      0.895397  0.894804       0.909544    0.895397   \n",
            "1           1          SVM      0.887646  0.887347       0.899490    0.887646   \n",
            "2           1  Naive Bayes      0.898906  0.899955       0.914063    0.898906   \n",
            "3           2         k-NN      0.873669  0.875062       0.897451    0.873669   \n",
            "4           2          SVM      0.879400  0.879422       0.890106    0.879400   \n",
            "5           2  Naive Bayes      0.885964  0.887927       0.902410    0.885964   \n",
            "6           3         k-NN      0.885802  0.886182       0.902268    0.885802   \n",
            "7           3          SVM      0.872269  0.871869       0.881362    0.872269   \n",
            "8           3  Naive Bayes      0.880833  0.882063       0.897992    0.880833   \n",
            "\n",
            "   test_accuracy   test_f1  test_precision  test_recall  \n",
            "0       0.883065  0.883872        0.888693     0.883065  \n",
            "1       0.889113  0.889325        0.893333     0.889113  \n",
            "2       0.911290  0.911860        0.918823     0.911290  \n",
            "3       0.921606  0.921264        0.929723     0.921606  \n",
            "4       0.902486  0.903317        0.908830     0.902486  \n",
            "5       0.885277  0.888171        0.901705     0.885277  \n",
            "6       0.878613  0.879616        0.887713     0.878613  \n",
            "7       0.864162  0.864059        0.865333     0.864162  \n",
            "8       0.895954  0.897102        0.904921     0.895954  \n"
          ]
        }
      ],
      "source": [
        "# Generate features and labels for each subject using PreProcessor and FeatureExtraction\n",
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "file_path =  '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject103.dat'\n",
        "\n",
        "preprocessor.initializeDataFrame(file_path)\n",
        "preprocessor.dataCleaning()\n",
        "preprocessor.applyPreProcessing()\n",
        "\n",
        "subject_id = int(file_path[-5])\n",
        "subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPOUKwfIqXlO",
        "outputId": "8a52dd4f-14d1-4ce7-fc61-533d40185e1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame still contains some NAN values\n",
            "Evaluating model: k-NN for subject 4\n",
            "Fold scores: {'accuracy': 0.9259259259259259, 'f1': 0.9264572142519426, 'precision': 0.9309003753448197, 'recall': 0.9259259259259259}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.92      1.00      0.96        12\n",
            "           3       0.75      0.90      0.82        10\n",
            "           4       0.93      1.00      0.96        13\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       0.88      0.88      0.88         8\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.89      0.80      0.84        10\n",
            "          17       0.92      0.92      0.92        12\n",
            "\n",
            "    accuracy                           0.93       108\n",
            "   macro avg       0.93      0.92      0.92       108\n",
            "weighted avg       0.93      0.93      0.93       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9345794392523364, 'f1': 0.9340081863446349, 'precision': 0.9407209612817088, 'recall': 0.9345794392523364}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.90      0.75      0.82        12\n",
            "           3       0.75      0.90      0.82        10\n",
            "           4       0.93      1.00      0.96        13\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.83      0.91         6\n",
            "          16       1.00      0.80      0.89        10\n",
            "          17       0.86      1.00      0.92        12\n",
            "\n",
            "    accuracy                           0.93       107\n",
            "   macro avg       0.94      0.93      0.93       107\n",
            "weighted avg       0.94      0.93      0.93       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9065420560747663, 'f1': 0.9097436242122826, 'precision': 0.9272919448153092, 'recall': 0.9065420560747663}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.75      0.86        12\n",
            "           2       1.00      0.92      0.96        12\n",
            "           3       0.67      1.00      0.80        10\n",
            "           4       0.92      0.92      0.92        13\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       0.88      1.00      0.93         7\n",
            "          16       1.00      0.90      0.95        10\n",
            "          17       0.79      0.92      0.85        12\n",
            "\n",
            "    accuracy                           0.91       107\n",
            "   macro avg       0.93      0.91      0.91       107\n",
            "weighted avg       0.93      0.91      0.91       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.8691588785046729, 'f1': 0.8695365322143055, 'precision': 0.9018178083598645, 'recall': 0.8691588785046729}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      0.75      0.86        12\n",
            "           3       0.69      0.90      0.78        10\n",
            "           4       0.93      1.00      0.96        13\n",
            "           6       0.83      0.91      0.87        11\n",
            "           7       1.00      0.85      0.92        13\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       1.00      0.50      0.67        10\n",
            "          17       0.61      0.92      0.73        12\n",
            "\n",
            "    accuracy                           0.87       107\n",
            "   macro avg       0.91      0.87      0.87       107\n",
            "weighted avg       0.90      0.87      0.87       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9252336448598131, 'f1': 0.9246668872837097, 'precision': 0.926742727677307, 'recall': 0.9252336448598131}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.83      0.91      0.87        11\n",
            "           2       0.91      0.83      0.87        12\n",
            "           3       0.80      0.73      0.76        11\n",
            "           4       1.00      0.93      0.96        14\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.90      0.90      0.90        10\n",
            "          17       0.86      1.00      0.92        12\n",
            "\n",
            "    accuracy                           0.93       107\n",
            "   macro avg       0.93      0.93      0.93       107\n",
            "weighted avg       0.93      0.93      0.92       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9158878504672897, 'f1': 0.9155353229550709, 'precision': 0.9275437957680949, 'recall': 0.9158878504672897}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.82      0.90        11\n",
            "           2       0.91      0.83      0.87        12\n",
            "           3       0.79      1.00      0.88        11\n",
            "           4       0.87      1.00      0.93        13\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       1.00      0.80      0.89        10\n",
            "          17       0.79      0.92      0.85        12\n",
            "\n",
            "    accuracy                           0.92       107\n",
            "   macro avg       0.93      0.91      0.91       107\n",
            "weighted avg       0.93      0.92      0.92       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.8691588785046729, 'f1': 0.8722028082531942, 'precision': 0.8925982506589983, 'recall': 0.8691588785046729}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.64      0.78        11\n",
            "           2       0.83      0.83      0.83        12\n",
            "           3       0.56      0.82      0.67        11\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       0.90      0.90      0.90        10\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       0.83      0.91      0.87        11\n",
            "          17       0.85      0.92      0.88        12\n",
            "\n",
            "    accuracy                           0.87       107\n",
            "   macro avg       0.90      0.86      0.87       107\n",
            "weighted avg       0.89      0.87      0.87       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.897196261682243, 'f1': 0.8965537295591404, 'precision': 0.9153336927869639, 'recall': 0.897196261682243}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      1.00      0.96        11\n",
            "           2       1.00      0.92      0.96        12\n",
            "           3       0.77      0.91      0.83        11\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       0.90      0.90      0.90        10\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.62      0.77         8\n",
            "          13       0.83      0.71      0.77         7\n",
            "          16       1.00      0.73      0.84        11\n",
            "          17       0.69      1.00      0.81        11\n",
            "\n",
            "    accuracy                           0.90       107\n",
            "   macro avg       0.91      0.88      0.88       107\n",
            "weighted avg       0.92      0.90      0.90       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.897196261682243, 'f1': 0.8982953910056714, 'precision': 0.9179761048919928, 'recall': 0.897196261682243}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.79      0.92      0.85        12\n",
            "           3       0.67      0.91      0.77        11\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       1.00      0.60      0.75        10\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       1.00      0.80      0.89        10\n",
            "          17       0.77      0.91      0.83        11\n",
            "\n",
            "    accuracy                           0.90       107\n",
            "   macro avg       0.92      0.89      0.90       107\n",
            "weighted avg       0.92      0.90      0.90       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9065420560747663, 'f1': 0.9079057456725927, 'precision': 0.916789337350085, 'recall': 0.9065420560747663}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.92      0.92      0.92        12\n",
            "           3       0.71      0.91      0.80        11\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       0.89      0.80      0.84        10\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       1.00      0.75      0.86         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.89      0.80      0.84        10\n",
            "          17       0.77      0.91      0.83        11\n",
            "\n",
            "    accuracy                           0.91       107\n",
            "   macro avg       0.92      0.90      0.91       107\n",
            "weighted avg       0.92      0.91      0.91       107\n",
            "\n",
            "Average validation scores: {'accuracy': 0.9047421253028729, 'f1': 0.9054905441752545, 'precision': 0.9197714998935144, 'recall': 0.9047421253028729}\n",
            "Test set scores: {'accuracy': 0.9108695652173913, 'f1': 0.9094951747173888, 'precision': 0.9185491585856373, 'recall': 0.9108695652173913}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        37\n",
            "           2       0.92      0.98      0.95        49\n",
            "           3       0.76      0.93      0.84        58\n",
            "           4       0.95      0.96      0.96        80\n",
            "           6       0.92      1.00      0.96        44\n",
            "           7       1.00      0.96      0.98        56\n",
            "          12       0.81      0.78      0.79        32\n",
            "          13       1.00      0.64      0.78        25\n",
            "          16       1.00      0.71      0.83        31\n",
            "          17       0.88      0.88      0.88        48\n",
            "\n",
            "    accuracy                           0.91       460\n",
            "   macro avg       0.92      0.88      0.90       460\n",
            "weighted avg       0.92      0.91      0.91       460\n",
            "\n",
            "Evaluating model: SVM for subject 4\n",
            "Fold scores: {'accuracy': 0.9074074074074074, 'f1': 0.9089428493615288, 'precision': 0.913399871733205, 'recall': 0.9074074074074074}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.91      0.83      0.87        12\n",
            "           3       0.67      0.80      0.73        10\n",
            "           4       0.93      1.00      0.96        13\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       0.88      0.88      0.88         8\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.90      0.90      0.90        10\n",
            "          17       0.92      0.92      0.92        12\n",
            "\n",
            "    accuracy                           0.91       108\n",
            "   macro avg       0.91      0.90      0.90       108\n",
            "weighted avg       0.91      0.91      0.91       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9065420560747663, 'f1': 0.9053226163900044, 'precision': 0.9106272751132563, 'recall': 0.9065420560747663}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.86      1.00      0.92        12\n",
            "           2       1.00      0.75      0.86        12\n",
            "           3       0.90      0.90      0.90        10\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       0.86      1.00      0.92         6\n",
            "          16       0.78      0.70      0.74        10\n",
            "          17       0.77      0.83      0.80        12\n",
            "\n",
            "    accuracy                           0.91       107\n",
            "   macro avg       0.91      0.91      0.90       107\n",
            "weighted avg       0.91      0.91      0.91       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9158878504672897, 'f1': 0.916772364130092, 'precision': 0.9247388125892799, 'recall': 0.9158878504672897}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.82      0.75      0.78        12\n",
            "           2       0.91      0.83      0.87        12\n",
            "           3       0.71      1.00      0.83        10\n",
            "           4       1.00      0.92      0.96        13\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       1.00      0.90      0.95        10\n",
            "          17       0.92      1.00      0.96        12\n",
            "\n",
            "    accuracy                           0.92       107\n",
            "   macro avg       0.93      0.92      0.92       107\n",
            "weighted avg       0.92      0.92      0.92       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.8785046728971962, 'f1': 0.874503768807753, 'precision': 0.8817454611847134, 'recall': 0.8785046728971962}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      1.00      0.96        12\n",
            "           2       0.89      0.67      0.76        12\n",
            "           3       0.75      0.60      0.67        10\n",
            "           4       0.93      1.00      0.96        13\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       0.86      0.92      0.89        13\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.89      0.80      0.84        10\n",
            "          17       0.75      1.00      0.86        12\n",
            "\n",
            "    accuracy                           0.88       107\n",
            "   macro avg       0.89      0.88      0.88       107\n",
            "weighted avg       0.88      0.88      0.87       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9065420560747663, 'f1': 0.9023154346202316, 'precision': 0.9094850113541701, 'recall': 0.9065420560747663}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.83      0.91      0.87        11\n",
            "           2       0.85      0.92      0.88        12\n",
            "           3       0.86      0.55      0.67        11\n",
            "           4       1.00      0.93      0.96        14\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       0.92      1.00      0.96        12\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.89      0.80      0.84        10\n",
            "          17       0.80      1.00      0.89        12\n",
            "\n",
            "    accuracy                           0.91       107\n",
            "   macro avg       0.91      0.91      0.91       107\n",
            "weighted avg       0.91      0.91      0.90       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9158878504672897, 'f1': 0.915538234515116, 'precision': 0.9177849668503875, 'recall': 0.9158878504672897}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.91      0.91        11\n",
            "           2       1.00      0.92      0.96        12\n",
            "           3       0.82      0.82      0.82        11\n",
            "           4       0.92      0.92      0.92        13\n",
            "           6       0.92      1.00      0.96        11\n",
            "           7       0.92      1.00      0.96        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.89      0.80      0.84        10\n",
            "          17       0.85      0.92      0.88        12\n",
            "\n",
            "    accuracy                           0.92       107\n",
            "   macro avg       0.92      0.91      0.92       107\n",
            "weighted avg       0.92      0.92      0.92       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.8504672897196262, 'f1': 0.8553896274459161, 'precision': 0.8705496217178461, 'recall': 0.8504672897196262}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.88      0.64      0.74        11\n",
            "           2       0.57      0.67      0.62        12\n",
            "           3       0.50      0.64      0.56        11\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       0.83      0.91      0.87        11\n",
            "          17       1.00      1.00      1.00        12\n",
            "\n",
            "    accuracy                           0.85       107\n",
            "   macro avg       0.88      0.85      0.86       107\n",
            "weighted avg       0.87      0.85      0.86       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9158878504672897, 'f1': 0.9149859914792867, 'precision': 0.9251052685632125, 'recall': 0.9158878504672897}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      1.00      0.96        11\n",
            "           2       0.79      0.92      0.85        12\n",
            "           3       0.91      0.91      0.91        11\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       1.00      0.80      0.89        10\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.75      0.86         8\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       0.83      0.91      0.87        11\n",
            "          17       0.85      1.00      0.92        11\n",
            "\n",
            "    accuracy                           0.92       107\n",
            "   macro avg       0.93      0.90      0.91       107\n",
            "weighted avg       0.93      0.92      0.91       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.8785046728971962, 'f1': 0.8771476856578561, 'precision': 0.8914385847797064, 'recall': 0.8785046728971962}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        12\n",
            "           2       0.80      1.00      0.89        12\n",
            "           3       0.69      1.00      0.81        11\n",
            "           4       1.00      0.92      0.96        13\n",
            "           6       0.86      0.60      0.71        10\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.88      0.88      0.88         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.88      0.70      0.78        10\n",
            "          17       0.90      0.82      0.86        11\n",
            "\n",
            "    accuracy                           0.88       107\n",
            "   macro avg       0.89      0.88      0.88       107\n",
            "weighted avg       0.89      0.88      0.88       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9158878504672897, 'f1': 0.9152995594610736, 'precision': 0.9275101845195304, 'recall': 0.9158878504672897}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      1.00      0.96        12\n",
            "           2       0.75      1.00      0.86        12\n",
            "           3       0.83      0.91      0.87        11\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       1.00      0.70      0.82        10\n",
            "           7       0.92      0.92      0.92        13\n",
            "          12       1.00      0.75      0.86         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       1.00      0.90      0.95        10\n",
            "          17       0.91      0.91      0.91        11\n",
            "\n",
            "    accuracy                           0.92       107\n",
            "   macro avg       0.93      0.91      0.91       107\n",
            "weighted avg       0.93      0.92      0.92       107\n",
            "\n",
            "Average validation scores: {'accuracy': 0.8991519556940117, 'f1': 0.8986218131868858, 'precision': 0.9072385058405308, 'recall': 0.8991519556940117}\n",
            "Test set scores: {'accuracy': 0.9108695652173913, 'f1': 0.9103627798783295, 'precision': 0.9130239267451948, 'recall': 0.9108695652173913}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      1.00      0.96        37\n",
            "           2       0.88      0.92      0.90        49\n",
            "           3       0.80      0.91      0.85        58\n",
            "           4       0.96      0.95      0.96        80\n",
            "           6       0.98      1.00      0.99        44\n",
            "           7       1.00      0.96      0.98        56\n",
            "          12       0.82      0.84      0.83        32\n",
            "          13       0.90      0.72      0.80        25\n",
            "          16       0.89      0.77      0.83        31\n",
            "          17       0.91      0.85      0.88        48\n",
            "\n",
            "    accuracy                           0.91       460\n",
            "   macro avg       0.91      0.89      0.90       460\n",
            "weighted avg       0.91      0.91      0.91       460\n",
            "\n",
            "Evaluating model: Naive Bayes for subject 4\n",
            "Fold scores: {'accuracy': 0.9074074074074074, 'f1': 0.9078944774435919, 'precision': 0.9118048618048618, 'recall': 0.9074074074074074}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.92      1.00      0.96        12\n",
            "           3       0.73      0.80      0.76        10\n",
            "           4       0.93      1.00      0.96        13\n",
            "           6       0.90      0.82      0.86        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.80      0.80      0.80        10\n",
            "          17       0.85      0.92      0.88        12\n",
            "\n",
            "    accuracy                           0.91       108\n",
            "   macro avg       0.91      0.90      0.90       108\n",
            "weighted avg       0.91      0.91      0.91       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9345794392523364, 'f1': 0.9349176680017802, 'precision': 0.9388209920920201, 'recall': 0.9345794392523364}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.90      0.75      0.82        12\n",
            "           3       0.90      0.90      0.90        10\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      1.00      1.00         6\n",
            "          16       0.75      0.90      0.82        10\n",
            "          17       0.85      0.92      0.88        12\n",
            "\n",
            "    accuracy                           0.93       107\n",
            "   macro avg       0.94      0.94      0.94       107\n",
            "weighted avg       0.94      0.93      0.93       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.8878504672897196, 'f1': 0.8894630521855227, 'precision': 0.9078771695594126, 'recall': 0.8878504672897196}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.75      0.86        12\n",
            "           2       1.00      0.92      0.96        12\n",
            "           3       0.60      0.60      0.60        10\n",
            "           4       1.00      0.92      0.96        13\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.71      0.83         7\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.71      1.00      0.83        10\n",
            "          17       0.75      1.00      0.86        12\n",
            "\n",
            "    accuracy                           0.89       107\n",
            "   macro avg       0.91      0.88      0.88       107\n",
            "weighted avg       0.91      0.89      0.89       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.8878504672897196, 'f1': 0.8911738826839664, 'precision': 0.9070007873746191, 'recall': 0.8878504672897196}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.90      0.75      0.82        12\n",
            "           3       0.67      0.80      0.73        10\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       1.00      0.73      0.84        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.64      0.90      0.75        10\n",
            "          17       0.85      0.92      0.88        12\n",
            "\n",
            "    accuracy                           0.89       107\n",
            "   macro avg       0.91      0.89      0.89       107\n",
            "weighted avg       0.91      0.89      0.89       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9158878504672897, 'f1': 0.9139791326707215, 'precision': 0.9169640328518834, 'recall': 0.9158878504672897}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.91      0.95        11\n",
            "           2       0.92      0.92      0.92        12\n",
            "           3       0.67      0.55      0.60        11\n",
            "           4       1.00      0.93      0.96        14\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.82      0.90      0.86        10\n",
            "          17       0.80      1.00      0.89        12\n",
            "\n",
            "    accuracy                           0.92       107\n",
            "   macro avg       0.92      0.92      0.92       107\n",
            "weighted avg       0.92      0.92      0.91       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9345794392523364, 'f1': 0.9349606238269383, 'precision': 0.9379071084678561, 'recall': 0.9345794392523364}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.82      0.90        11\n",
            "           2       0.92      0.92      0.92        12\n",
            "           3       0.91      0.91      0.91        11\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       0.92      1.00      0.96        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.73      0.80      0.76        10\n",
            "          17       0.92      0.92      0.92        12\n",
            "\n",
            "    accuracy                           0.93       107\n",
            "   macro avg       0.94      0.94      0.94       107\n",
            "weighted avg       0.94      0.93      0.93       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.8598130841121495, 'f1': 0.860974553200221, 'precision': 0.8825904624970046, 'recall': 0.8598130841121495}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.64      0.78        11\n",
            "           2       0.69      0.92      0.79        12\n",
            "           3       0.70      0.64      0.67        11\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       0.67      0.91      0.77        11\n",
            "          17       0.85      0.92      0.88        12\n",
            "\n",
            "    accuracy                           0.86       107\n",
            "   macro avg       0.89      0.85      0.86       107\n",
            "weighted avg       0.88      0.86      0.86       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.8878504672897196, 'f1': 0.8875367048711218, 'precision': 0.9016744548286605, 'recall': 0.8878504672897196}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      1.00      0.96        11\n",
            "           2       0.92      0.92      0.92        12\n",
            "           3       0.82      0.82      0.82        11\n",
            "           4       1.00      0.92      0.96        13\n",
            "           6       1.00      0.80      0.89        10\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       0.83      0.62      0.71         8\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       0.83      0.91      0.87        11\n",
            "          17       0.69      1.00      0.81        11\n",
            "\n",
            "    accuracy                           0.89       107\n",
            "   macro avg       0.90      0.87      0.88       107\n",
            "weighted avg       0.90      0.89      0.89       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.8878504672897196, 'f1': 0.8863564893966213, 'precision': 0.9072770427910616, 'recall': 0.8878504672897196}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.86      1.00      0.92        12\n",
            "           2       1.00      0.75      0.86        12\n",
            "           3       0.79      1.00      0.88        11\n",
            "           4       1.00      0.85      0.92        13\n",
            "           6       1.00      0.60      0.75        10\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.89      1.00      0.94         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.82      0.90      0.86        10\n",
            "          17       0.71      0.91      0.80        11\n",
            "\n",
            "    accuracy                           0.89       107\n",
            "   macro avg       0.91      0.89      0.89       107\n",
            "weighted avg       0.91      0.89      0.89       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.8598130841121495, 'f1': 0.8698072599678257, 'precision': 0.9022134776192818, 'recall': 0.8598130841121495}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      0.83      0.91        12\n",
            "           3       0.80      0.73      0.76        11\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       1.00      0.70      0.82        10\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       1.00      0.75      0.86         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.47      0.90      0.62        10\n",
            "          17       0.73      0.73      0.73        11\n",
            "\n",
            "    accuracy                           0.86       107\n",
            "   macro avg       0.90      0.86      0.87       107\n",
            "weighted avg       0.90      0.86      0.87       107\n",
            "\n",
            "Average validation scores: {'accuracy': 0.8963482173762548, 'f1': 0.897706384424831, 'precision': 0.9114130389886663, 'recall': 0.8963482173762548}\n",
            "Test set scores: {'accuracy': 0.9108695652173913, 'f1': 0.9114063524081315, 'precision': 0.9162243949451023, 'recall': 0.9108695652173913}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        37\n",
            "           2       0.92      0.98      0.95        49\n",
            "           3       0.81      0.83      0.82        58\n",
            "           4       0.99      0.95      0.97        80\n",
            "           6       1.00      0.95      0.98        44\n",
            "           7       1.00      0.95      0.97        56\n",
            "          12       0.88      0.91      0.89        32\n",
            "          13       0.89      0.64      0.74        25\n",
            "          16       0.69      0.87      0.77        31\n",
            "          17       0.86      0.90      0.88        48\n",
            "\n",
            "    accuracy                           0.91       460\n",
            "   macro avg       0.90      0.90      0.90       460\n",
            "weighted avg       0.92      0.91      0.91       460\n",
            "\n",
            "    subject_id        model  val_accuracy    val_f1  val_precision  \\\n",
            "0            1         k-NN      0.895397  0.894804       0.909544   \n",
            "1            1          SVM      0.887646  0.887347       0.899490   \n",
            "2            1  Naive Bayes      0.898906  0.899955       0.914063   \n",
            "3            2         k-NN      0.873669  0.875062       0.897451   \n",
            "4            2          SVM      0.879400  0.879422       0.890106   \n",
            "5            2  Naive Bayes      0.885964  0.887927       0.902410   \n",
            "6            3         k-NN      0.885802  0.886182       0.902268   \n",
            "7            3          SVM      0.872269  0.871869       0.881362   \n",
            "8            3  Naive Bayes      0.880833  0.882063       0.897992   \n",
            "9            4         k-NN      0.904742  0.905491       0.919771   \n",
            "10           4          SVM      0.899152  0.898622       0.907239   \n",
            "11           4  Naive Bayes      0.896348  0.897706       0.911413   \n",
            "\n",
            "    val_recall  test_accuracy   test_f1  test_precision  test_recall  \n",
            "0     0.895397       0.883065  0.883872        0.888693     0.883065  \n",
            "1     0.887646       0.889113  0.889325        0.893333     0.889113  \n",
            "2     0.898906       0.911290  0.911860        0.918823     0.911290  \n",
            "3     0.873669       0.921606  0.921264        0.929723     0.921606  \n",
            "4     0.879400       0.902486  0.903317        0.908830     0.902486  \n",
            "5     0.885964       0.885277  0.888171        0.901705     0.885277  \n",
            "6     0.885802       0.878613  0.879616        0.887713     0.878613  \n",
            "7     0.872269       0.864162  0.864059        0.865333     0.864162  \n",
            "8     0.880833       0.895954  0.897102        0.904921     0.895954  \n",
            "9     0.904742       0.910870  0.909495        0.918549     0.910870  \n",
            "10    0.899152       0.910870  0.910363        0.913024     0.910870  \n",
            "11    0.896348       0.910870  0.911406        0.916224     0.910870  \n"
          ]
        }
      ],
      "source": [
        "# Generate features and labels for each subject using PreProcessor and FeatureExtraction\n",
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "file_path =  '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject104.dat'\n",
        "\n",
        "preprocessor.initializeDataFrame(file_path)\n",
        "preprocessor.dataCleaning()\n",
        "preprocessor.applyPreProcessing()\n",
        "\n",
        "subject_id = int(file_path[-5])\n",
        "subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iYa5Pz6qZGW",
        "outputId": "915c808f-5188-4a8b-eba3-114203b8d307"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame still contains some NAN values\n",
            "Evaluating model: k-NN for subject 5\n",
            "Fold scores: {'accuracy': 0.889763779527559, 'f1': 0.8912987531696879, 'precision': 0.9084626865080778, 'recall': 0.889763779527559}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        12\n",
            "           2       0.80      1.00      0.89        12\n",
            "           3       0.62      0.80      0.70        10\n",
            "           4       1.00      1.00      1.00        15\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      0.83      0.91        12\n",
            "          12       0.78      1.00      0.88         7\n",
            "          13       1.00      0.67      0.80         6\n",
            "          16       1.00      0.75      0.86        12\n",
            "          17       0.82      0.88      0.85        16\n",
            "          24       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.89       127\n",
            "   macro avg       0.91      0.87      0.88       127\n",
            "weighted avg       0.91      0.89      0.89       127\n",
            "\n",
            "Fold scores: {'accuracy': 0.889763779527559, 'f1': 0.8906144861097124, 'precision': 0.9008898035472839, 'recall': 0.889763779527559}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.73      0.92      0.81        12\n",
            "           2       0.83      0.77      0.80        13\n",
            "           3       0.73      0.80      0.76        10\n",
            "           4       0.94      1.00      0.97        15\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        11\n",
            "          12       1.00      0.71      0.83         7\n",
            "          13       1.00      1.00      1.00         6\n",
            "          16       1.00      0.83      0.91        12\n",
            "          17       0.78      0.88      0.82        16\n",
            "          24       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.89       127\n",
            "   macro avg       0.92      0.87      0.89       127\n",
            "weighted avg       0.90      0.89      0.89       127\n",
            "\n",
            "Fold scores: {'accuracy': 0.873015873015873, 'f1': 0.878794451465259, 'precision': 0.8940030557677616, 'recall': 0.873015873015873}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.83      0.83      0.83        12\n",
            "           3       0.50      0.78      0.61         9\n",
            "           4       0.93      0.93      0.93        15\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       0.92      0.92      0.92        12\n",
            "           7       1.00      0.91      0.95        11\n",
            "          12       1.00      0.83      0.91         6\n",
            "          13       1.00      0.67      0.80         6\n",
            "          16       0.91      0.83      0.87        12\n",
            "          17       0.76      0.81      0.79        16\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.87       126\n",
            "   macro avg       0.90      0.87      0.88       126\n",
            "weighted avg       0.89      0.87      0.88       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.8968253968253969, 'f1': 0.8957642138675367, 'precision': 0.9007908757908758, 'recall': 0.8968253968253969}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.80      0.92      0.86        13\n",
            "           2       0.92      1.00      0.96        12\n",
            "           3       0.73      0.80      0.76        10\n",
            "           4       0.88      0.93      0.90        15\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      1.00      1.00        11\n",
            "          12       0.83      0.83      0.83         6\n",
            "          13       1.00      0.83      0.91         6\n",
            "          16       0.88      0.64      0.74        11\n",
            "          17       0.87      0.87      0.87        15\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.90       126\n",
            "   macro avg       0.91      0.89      0.90       126\n",
            "weighted avg       0.90      0.90      0.90       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.9365079365079365, 'f1': 0.934989444711667, 'precision': 0.940342803788182, 'recall': 0.9365079365079365}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      1.00      0.96        13\n",
            "           2       0.92      0.92      0.92        12\n",
            "           3       0.90      0.90      0.90        10\n",
            "           4       0.94      1.00      0.97        16\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.86      0.86      0.86         7\n",
            "          13       1.00      0.60      0.75         5\n",
            "          16       1.00      0.82      0.90        11\n",
            "          17       0.82      0.93      0.87        15\n",
            "          24       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.94       126\n",
            "   macro avg       0.95      0.92      0.93       126\n",
            "weighted avg       0.94      0.94      0.93       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.9126984126984127, 'f1': 0.9126098682775701, 'precision': 0.9174995755878108, 'recall': 0.9126984126984127}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.83      0.87        12\n",
            "           2       1.00      0.92      0.96        12\n",
            "           3       0.75      0.90      0.82        10\n",
            "           4       0.94      1.00      0.97        16\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.88      1.00      0.93         7\n",
            "          13       0.75      0.60      0.67         5\n",
            "          16       0.91      0.83      0.87        12\n",
            "          17       0.82      0.93      0.87        15\n",
            "          24       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.91       126\n",
            "   macro avg       0.91      0.90      0.91       126\n",
            "weighted avg       0.92      0.91      0.91       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.8968253968253969, 'f1': 0.8911511786679245, 'precision': 0.9080587622254289, 'recall': 0.8968253968253969}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        12\n",
            "           2       0.82      0.75      0.78        12\n",
            "           3       0.90      0.90      0.90        10\n",
            "           4       0.89      1.00      0.94        16\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.88      1.00      0.93         7\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       1.00      0.50      0.67        12\n",
            "          17       0.75      1.00      0.86        15\n",
            "          24       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.90       126\n",
            "   macro avg       0.92      0.90      0.90       126\n",
            "weighted avg       0.91      0.90      0.89       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.9047619047619048, 'f1': 0.9055570007628541, 'precision': 0.9126404349618635, 'recall': 0.9047619047619048}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.79      0.92      0.85        12\n",
            "           2       0.86      1.00      0.92        12\n",
            "           3       0.82      0.90      0.86        10\n",
            "           4       1.00      0.81      0.90        16\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       0.80      0.80      0.80         5\n",
            "          16       0.91      0.83      0.87        12\n",
            "          17       0.81      0.87      0.84        15\n",
            "          24       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.90       126\n",
            "   macro avg       0.92      0.91      0.91       126\n",
            "weighted avg       0.91      0.90      0.91       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.8571428571428571, 'f1': 0.8614704797158212, 'precision': 0.8891010949834479, 'recall': 0.8571428571428571}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.83      0.87        12\n",
            "           2       1.00      0.83      0.91        12\n",
            "           3       0.56      1.00      0.71        10\n",
            "           4       0.88      0.94      0.91        16\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.78      1.00      0.88         7\n",
            "          13       1.00      0.60      0.75         5\n",
            "          16       1.00      0.75      0.86        12\n",
            "          17       0.67      0.67      0.67        15\n",
            "          24       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.86       126\n",
            "   macro avg       0.90      0.84      0.85       126\n",
            "weighted avg       0.89      0.86      0.86       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.8888888888888888, 'f1': 0.8882899942095381, 'precision': 0.9162906988951881, 'recall': 0.8888888888888888}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.91      0.83      0.87        12\n",
            "           3       0.59      1.00      0.74        10\n",
            "           4       0.84      1.00      0.91        16\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       1.00      0.40      0.57         5\n",
            "          16       1.00      0.67      0.80        12\n",
            "          17       0.81      0.87      0.84        15\n",
            "          24       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.89       126\n",
            "   macro avg       0.93      0.87      0.88       126\n",
            "weighted avg       0.92      0.89      0.89       126\n",
            "\n",
            "Average validation scores: {'accuracy': 0.8946194225721786, 'f1': 0.895053987095757, 'precision': 0.9088079792055922, 'recall': 0.8946194225721786}\n",
            "Test set scores: {'accuracy': 0.8853974121996303, 'f1': 0.8835764919625496, 'precision': 0.896439684673543, 'recall': 0.8853974121996303}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      1.00      0.99        35\n",
            "           2       0.82      0.88      0.85        58\n",
            "           3       0.74      0.79      0.76        47\n",
            "           4       0.83      0.96      0.89        57\n",
            "           5       1.00      0.94      0.97        53\n",
            "           6       0.98      0.98      0.98        51\n",
            "           7       1.00      0.96      0.98        57\n",
            "          12       0.82      0.92      0.87        25\n",
            "          13       0.94      0.55      0.70        29\n",
            "          16       1.00      0.66      0.79        44\n",
            "          17       0.76      0.91      0.83        66\n",
            "          24       1.00      0.95      0.97        19\n",
            "\n",
            "    accuracy                           0.89       541\n",
            "   macro avg       0.91      0.88      0.88       541\n",
            "weighted avg       0.90      0.89      0.88       541\n",
            "\n",
            "Evaluating model: SVM for subject 5\n",
            "Fold scores: {'accuracy': 0.8582677165354331, 'f1': 0.8605623840218709, 'precision': 0.872407775951083, 'recall': 0.8582677165354331}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.71      0.83      0.77        12\n",
            "           2       0.69      0.75      0.72        12\n",
            "           3       0.80      0.80      0.80        10\n",
            "           4       1.00      1.00      1.00        15\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      0.82      0.90        11\n",
            "           7       1.00      0.83      0.91        12\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       0.80      0.67      0.73         6\n",
            "          16       0.69      0.92      0.79        12\n",
            "          17       0.87      0.81      0.84        16\n",
            "          24       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.86       127\n",
            "   macro avg       0.88      0.84      0.85       127\n",
            "weighted avg       0.87      0.86      0.86       127\n",
            "\n",
            "Fold scores: {'accuracy': 0.8976377952755905, 'f1': 0.8975293591733527, 'precision': 0.9120162864257353, 'recall': 0.8976377952755905}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.67      1.00      0.80        12\n",
            "           2       0.90      0.69      0.78        13\n",
            "           3       0.89      0.80      0.84        10\n",
            "           4       1.00      1.00      1.00        15\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       0.92      1.00      0.96        11\n",
            "           7       1.00      1.00      1.00        11\n",
            "          12       1.00      0.71      0.83         7\n",
            "          13       1.00      1.00      1.00         6\n",
            "          16       0.85      0.92      0.88        12\n",
            "          17       0.88      0.88      0.88        16\n",
            "          24       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.90       127\n",
            "   macro avg       0.92      0.88      0.89       127\n",
            "weighted avg       0.91      0.90      0.90       127\n",
            "\n",
            "Fold scores: {'accuracy': 0.8571428571428571, 'f1': 0.8556342645360636, 'precision': 0.865351419674728, 'recall': 0.8571428571428571}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.90      0.75      0.82        12\n",
            "           2       0.79      0.92      0.85        12\n",
            "           3       0.71      0.56      0.63         9\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       0.92      1.00      0.96        11\n",
            "           6       0.91      0.83      0.87        12\n",
            "           7       0.83      0.91      0.87        11\n",
            "          12       1.00      0.83      0.91         6\n",
            "          13       1.00      0.67      0.80         6\n",
            "          16       0.79      0.92      0.85        12\n",
            "          17       0.74      0.88      0.80        16\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.86       126\n",
            "   macro avg       0.88      0.85      0.86       126\n",
            "weighted avg       0.87      0.86      0.86       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.9047619047619048, 'f1': 0.9050224569250771, 'precision': 0.9108654572940288, 'recall': 0.9047619047619048}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.75      0.92      0.83        13\n",
            "           2       0.92      0.92      0.92        12\n",
            "           3       0.88      0.70      0.78        10\n",
            "           4       0.93      0.93      0.93        15\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       0.92      1.00      0.96        11\n",
            "          12       1.00      0.83      0.91         6\n",
            "          13       0.71      0.83      0.77         6\n",
            "          16       0.90      0.82      0.86        11\n",
            "          17       0.93      0.93      0.93        15\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.90       126\n",
            "   macro avg       0.91      0.90      0.90       126\n",
            "weighted avg       0.91      0.90      0.91       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.9603174603174603, 'f1': 0.9595543345543346, 'precision': 0.963718820861678, 'recall': 0.9603174603174603}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        13\n",
            "           2       0.79      0.92      0.85        12\n",
            "           3       0.90      0.90      0.90        10\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       1.00      0.60      0.75         5\n",
            "          16       1.00      1.00      1.00        11\n",
            "          17       1.00      1.00      1.00        15\n",
            "          24       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.96       126\n",
            "   macro avg       0.97      0.94      0.95       126\n",
            "weighted avg       0.96      0.96      0.96       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.9126984126984127, 'f1': 0.9131786596821466, 'precision': 0.9207406026383618, 'recall': 0.9126984126984127}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.83      0.87        12\n",
            "           2       1.00      0.83      0.91        12\n",
            "           3       0.89      0.80      0.84        10\n",
            "           4       0.94      1.00      0.97        16\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.88      1.00      0.93         7\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       0.79      0.92      0.85        12\n",
            "          17       0.82      0.93      0.87        15\n",
            "          24       0.75      1.00      0.86         3\n",
            "\n",
            "    accuracy                           0.91       126\n",
            "   macro avg       0.91      0.91      0.91       126\n",
            "weighted avg       0.92      0.91      0.91       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.8809523809523809, 'f1': 0.8744556334009506, 'precision': 0.9004765659177423, 'recall': 0.8809523809523809}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.77      0.83      0.80        12\n",
            "           2       0.82      0.75      0.78        12\n",
            "           3       0.90      0.90      0.90        10\n",
            "           4       0.94      1.00      0.97        16\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.88      1.00      0.93         7\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       1.00      0.42      0.59        12\n",
            "          17       0.68      1.00      0.81        15\n",
            "          24       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.88       126\n",
            "   macro avg       0.92      0.88      0.89       126\n",
            "weighted avg       0.90      0.88      0.87       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.8968253968253969, 'f1': 0.8990907757988504, 'precision': 0.9083865869580156, 'recall': 0.8968253968253969}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.79      0.92      0.85        12\n",
            "           2       1.00      0.92      0.96        12\n",
            "           3       0.75      0.90      0.82        10\n",
            "           4       1.00      0.88      0.93        16\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       0.82      0.82      0.82        11\n",
            "           7       0.86      1.00      0.92        12\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       0.67      0.80      0.73         5\n",
            "          16       0.91      0.83      0.87        12\n",
            "          17       1.00      0.87      0.93        15\n",
            "          24       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.90       126\n",
            "   macro avg       0.90      0.90      0.90       126\n",
            "weighted avg       0.91      0.90      0.90       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.8888888888888888, 'f1': 0.8883646915068178, 'precision': 0.8998144556968086, 'recall': 0.8888888888888888}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       0.92      0.92      0.92        12\n",
            "           3       0.77      1.00      0.87        10\n",
            "           4       0.88      0.94      0.91        16\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.70      1.00      0.82         7\n",
            "          13       0.80      0.80      0.80         5\n",
            "          16       0.89      0.67      0.76        12\n",
            "          17       0.87      0.87      0.87        15\n",
            "          24       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.89       126\n",
            "   macro avg       0.89      0.88      0.88       126\n",
            "weighted avg       0.90      0.89      0.89       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.8571428571428571, 'f1': 0.8563095807773998, 'precision': 0.8722285210380448, 'recall': 0.8571428571428571}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.79      0.92      0.85        12\n",
            "           2       0.75      0.75      0.75        12\n",
            "           3       0.75      0.90      0.82        10\n",
            "           4       0.89      1.00      0.94        16\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       0.75      0.60      0.67         5\n",
            "          16       1.00      0.58      0.74        12\n",
            "          17       0.67      0.80      0.73        15\n",
            "          24       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.86       126\n",
            "   macro avg       0.88      0.85      0.86       126\n",
            "weighted avg       0.87      0.86      0.86       126\n",
            "\n",
            "Average validation scores: {'accuracy': 0.8914635670541182, 'f1': 0.8909702140376863, 'precision': 0.9026006492456226, 'recall': 0.8914635670541182}\n",
            "Test set scores: {'accuracy': 0.878003696857671, 'f1': 0.8770612645708813, 'precision': 0.87942846037417, 'recall': 0.878003696857671}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      1.00      0.96        35\n",
            "           2       0.74      0.84      0.79        58\n",
            "           3       0.84      0.66      0.74        47\n",
            "           4       0.95      0.95      0.95        57\n",
            "           5       0.98      0.94      0.96        53\n",
            "           6       0.94      0.94      0.94        51\n",
            "           7       0.95      0.98      0.97        57\n",
            "          12       0.88      0.84      0.86        25\n",
            "          13       0.79      0.79      0.79        29\n",
            "          16       0.80      0.75      0.78        44\n",
            "          17       0.81      0.86      0.84        66\n",
            "          24       1.00      0.95      0.97        19\n",
            "\n",
            "    accuracy                           0.88       541\n",
            "   macro avg       0.88      0.88      0.88       541\n",
            "weighted avg       0.88      0.88      0.88       541\n",
            "\n",
            "Evaluating model: Naive Bayes for subject 5\n",
            "Fold scores: {'accuracy': 0.84251968503937, 'f1': 0.8457429008281431, 'precision': 0.8576677915260593, 'recall': 0.84251968503937}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.79      0.92      0.85        12\n",
            "           2       0.75      0.75      0.75        12\n",
            "           3       0.67      0.60      0.63        10\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      0.82      0.90        11\n",
            "           7       1.00      0.83      0.91        12\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       0.57      0.67      0.62         6\n",
            "          16       0.92      0.92      0.92        12\n",
            "          17       0.65      0.81      0.72        16\n",
            "          24       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.84       127\n",
            "   macro avg       0.86      0.83      0.84       127\n",
            "weighted avg       0.86      0.84      0.85       127\n",
            "\n",
            "Fold scores: {'accuracy': 0.8661417322834646, 'f1': 0.8653034219140041, 'precision': 0.8853674540682416, 'recall': 0.8661417322834646}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.62      0.83      0.71        12\n",
            "           2       0.88      0.54      0.67        13\n",
            "           3       0.83      1.00      0.91        10\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       1.00      1.00      1.00        11\n",
            "          12       1.00      0.71      0.83         7\n",
            "          13       0.75      1.00      0.86         6\n",
            "          16       0.73      0.92      0.81        12\n",
            "          17       0.93      0.88      0.90        16\n",
            "          24       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.87       127\n",
            "   macro avg       0.89      0.86      0.86       127\n",
            "weighted avg       0.89      0.87      0.87       127\n",
            "\n",
            "Fold scores: {'accuracy': 0.8412698412698413, 'f1': 0.8430954734151875, 'precision': 0.855006105006105, 'recall': 0.8412698412698413}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       0.77      0.83      0.80        12\n",
            "           3       0.50      0.44      0.47         9\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      0.83      0.91        12\n",
            "           7       1.00      0.91      0.95        11\n",
            "          12       0.83      0.83      0.83         6\n",
            "          13       0.80      0.67      0.73         6\n",
            "          16       0.73      0.92      0.81        12\n",
            "          17       0.70      0.88      0.78        16\n",
            "          24       0.80      1.00      0.89         4\n",
            "\n",
            "    accuracy                           0.84       126\n",
            "   macro avg       0.84      0.83      0.83       126\n",
            "weighted avg       0.86      0.84      0.84       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.873015873015873, 'f1': 0.8733609835695696, 'precision': 0.8829755121421788, 'recall': 0.873015873015873}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        13\n",
            "           2       0.77      0.83      0.80        12\n",
            "           3       0.67      0.60      0.63        10\n",
            "           4       1.00      0.87      0.93        15\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       0.92      1.00      0.96        12\n",
            "           7       1.00      1.00      1.00        11\n",
            "          12       1.00      0.83      0.91         6\n",
            "          13       0.60      1.00      0.75         6\n",
            "          16       0.78      0.64      0.70        11\n",
            "          17       0.88      0.93      0.90        15\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.87       126\n",
            "   macro avg       0.88      0.88      0.87       126\n",
            "weighted avg       0.88      0.87      0.87       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.9523809523809523, 'f1': 0.9512529766984452, 'precision': 0.9545558608058609, 'recall': 0.9523809523809523}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       0.85      0.92      0.88        12\n",
            "           3       1.00      0.80      0.89        10\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       0.75      0.60      0.67         5\n",
            "          16       0.85      1.00      0.92        11\n",
            "          17       0.94      1.00      0.97        15\n",
            "          24       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.95       126\n",
            "   macro avg       0.95      0.94      0.94       126\n",
            "weighted avg       0.95      0.95      0.95       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.9126984126984127, 'f1': 0.9124527966423145, 'precision': 0.9212641646852172, 'recall': 0.9126984126984127}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       1.00      0.83      0.91        12\n",
            "           3       0.89      0.80      0.84        10\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.78      1.00      0.88         7\n",
            "          13       0.75      0.60      0.67         5\n",
            "          16       0.85      0.92      0.88        12\n",
            "          17       0.79      1.00      0.88        15\n",
            "          24       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.91       126\n",
            "   macro avg       0.91      0.90      0.90       126\n",
            "weighted avg       0.92      0.91      0.91       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.9126984126984127, 'f1': 0.9145042963284219, 'precision': 0.9370421245421245, 'recall': 0.9126984126984127}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       1.00      0.83      0.91        12\n",
            "           3       0.77      1.00      0.87        10\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      0.73      0.84        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       0.62      1.00      0.77         5\n",
            "          16       1.00      0.75      0.86        12\n",
            "          17       0.75      1.00      0.86        15\n",
            "          24       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.91       126\n",
            "   macro avg       0.93      0.92      0.91       126\n",
            "weighted avg       0.94      0.91      0.91       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.8968253968253969, 'f1': 0.8980301427799484, 'precision': 0.9114170920893611, 'recall': 0.8968253968253969}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        12\n",
            "           2       0.71      1.00      0.83        12\n",
            "           3       0.73      0.80      0.76        10\n",
            "           4       1.00      0.81      0.90        16\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      0.73      0.84        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.86      0.86      0.86         7\n",
            "          13       0.83      1.00      0.91         5\n",
            "          16       0.92      0.92      0.92        12\n",
            "          17       0.93      0.87      0.90        15\n",
            "          24       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.90       126\n",
            "   macro avg       0.91      0.91      0.90       126\n",
            "weighted avg       0.91      0.90      0.90       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.873015873015873, 'f1': 0.8743476048571053, 'precision': 0.881865625037894, 'recall': 0.873015873015873}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.82      0.75      0.78        12\n",
            "           2       0.83      0.83      0.83        12\n",
            "           3       0.73      0.80      0.76        10\n",
            "           4       1.00      0.94      0.97        16\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       0.88      1.00      0.93         7\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       0.79      0.92      0.85        12\n",
            "          17       0.76      0.87      0.81        15\n",
            "          24       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.87       126\n",
            "   macro avg       0.89      0.86      0.87       126\n",
            "weighted avg       0.88      0.87      0.87       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.873015873015873, 'f1': 0.8763036365520838, 'precision': 0.8862711362711362, 'recall': 0.873015873015873}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.89      0.67      0.76        12\n",
            "           3       0.73      0.80      0.76        10\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       0.50      0.60      0.55         5\n",
            "          16       0.77      0.83      0.80        12\n",
            "          17       0.67      0.80      0.73        15\n",
            "          24       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.87       126\n",
            "   macro avg       0.88      0.87      0.87       126\n",
            "weighted avg       0.89      0.87      0.88       126\n",
            "\n",
            "Average validation scores: {'accuracy': 0.8843582052243472, 'f1': 0.8854394233585223, 'precision': 0.8973432866174178, 'recall': 0.8843582052243472}\n",
            "Test set scores: {'accuracy': 0.8835489833641405, 'f1': 0.8841058471102378, 'precision': 0.8872439158134079, 'recall': 0.8835489833641405}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.85      1.00      0.92        35\n",
            "           2       0.77      0.76      0.77        58\n",
            "           3       0.76      0.68      0.72        47\n",
            "           4       1.00      0.95      0.97        57\n",
            "           5       1.00      0.92      0.96        53\n",
            "           6       0.98      0.96      0.97        51\n",
            "           7       1.00      0.96      0.98        57\n",
            "          12       0.92      0.92      0.92        25\n",
            "          13       0.77      0.83      0.80        29\n",
            "          16       0.75      0.86      0.80        44\n",
            "          17       0.84      0.86      0.85        66\n",
            "          24       1.00      0.95      0.97        19\n",
            "\n",
            "    accuracy                           0.88       541\n",
            "   macro avg       0.89      0.89      0.89       541\n",
            "weighted avg       0.89      0.88      0.88       541\n",
            "\n",
            "    subject_id        model  val_accuracy    val_f1  val_precision  \\\n",
            "0            1         k-NN      0.895397  0.894804       0.909544   \n",
            "1            1          SVM      0.887646  0.887347       0.899490   \n",
            "2            1  Naive Bayes      0.898906  0.899955       0.914063   \n",
            "3            2         k-NN      0.873669  0.875062       0.897451   \n",
            "4            2          SVM      0.879400  0.879422       0.890106   \n",
            "5            2  Naive Bayes      0.885964  0.887927       0.902410   \n",
            "6            3         k-NN      0.885802  0.886182       0.902268   \n",
            "7            3          SVM      0.872269  0.871869       0.881362   \n",
            "8            3  Naive Bayes      0.880833  0.882063       0.897992   \n",
            "9            4         k-NN      0.904742  0.905491       0.919771   \n",
            "10           4          SVM      0.899152  0.898622       0.907239   \n",
            "11           4  Naive Bayes      0.896348  0.897706       0.911413   \n",
            "12           5         k-NN      0.894619  0.895054       0.908808   \n",
            "13           5          SVM      0.891464  0.890970       0.902601   \n",
            "14           5  Naive Bayes      0.884358  0.885439       0.897343   \n",
            "\n",
            "    val_recall  test_accuracy   test_f1  test_precision  test_recall  \n",
            "0     0.895397       0.883065  0.883872        0.888693     0.883065  \n",
            "1     0.887646       0.889113  0.889325        0.893333     0.889113  \n",
            "2     0.898906       0.911290  0.911860        0.918823     0.911290  \n",
            "3     0.873669       0.921606  0.921264        0.929723     0.921606  \n",
            "4     0.879400       0.902486  0.903317        0.908830     0.902486  \n",
            "5     0.885964       0.885277  0.888171        0.901705     0.885277  \n",
            "6     0.885802       0.878613  0.879616        0.887713     0.878613  \n",
            "7     0.872269       0.864162  0.864059        0.865333     0.864162  \n",
            "8     0.880833       0.895954  0.897102        0.904921     0.895954  \n",
            "9     0.904742       0.910870  0.909495        0.918549     0.910870  \n",
            "10    0.899152       0.910870  0.910363        0.913024     0.910870  \n",
            "11    0.896348       0.910870  0.911406        0.916224     0.910870  \n",
            "12    0.894619       0.885397  0.883576        0.896440     0.885397  \n",
            "13    0.891464       0.878004  0.877061        0.879428     0.878004  \n",
            "14    0.884358       0.883549  0.884106        0.887244     0.883549  \n"
          ]
        }
      ],
      "source": [
        "# Generate features and labels for each subject using PreProcessor and FeatureExtraction\n",
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "file_path =  '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject105.dat'\n",
        "\n",
        "preprocessor.initializeDataFrame(file_path)\n",
        "preprocessor.dataCleaning()\n",
        "preprocessor.applyPreProcessing()\n",
        "\n",
        "subject_id = int(file_path[-5])\n",
        "subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZfqAfddqc05",
        "outputId": "2e356b2f-ca98-4f21-f998-3c642976e8a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame still contains some NAN values\n",
            "Evaluating model: k-NN for subject 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8793103448275862, 'f1': 0.8782108916319442, 'precision': 0.9061627668308703, 'recall': 0.8793103448275862}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.91      0.95        11\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       0.69      1.00      0.81        11\n",
            "           4       0.86      1.00      0.92        12\n",
            "           5       1.00      0.67      0.80         9\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.67      0.86      0.75         7\n",
            "          13       1.00      0.60      0.75         5\n",
            "          16       1.00      0.60      0.75        10\n",
            "          17       0.80      0.94      0.86        17\n",
            "\n",
            "    accuracy                           0.88       116\n",
            "   macro avg       0.91      0.85      0.86       116\n",
            "weighted avg       0.91      0.88      0.88       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.9051724137931034, 'f1': 0.9083875894220721, 'precision': 0.9201184591270798, 'recall': 0.9051724137931034}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.91      0.95        11\n",
            "           2       1.00      0.80      0.89        10\n",
            "           3       0.60      0.82      0.69        11\n",
            "           4       0.92      1.00      0.96        12\n",
            "           5       0.91      1.00      0.95        10\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       1.00      1.00      1.00         6\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       0.91      1.00      0.95        10\n",
            "          17       0.88      0.82      0.85        17\n",
            "\n",
            "    accuracy                           0.91       116\n",
            "   macro avg       0.93      0.91      0.91       116\n",
            "weighted avg       0.92      0.91      0.91       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8275862068965517, 'f1': 0.8339403033921973, 'precision': 0.8614532019704433, 'recall': 0.8275862068965517}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.71      0.50      0.59        10\n",
            "           3       0.45      0.82      0.58        11\n",
            "           4       0.86      1.00      0.92        12\n",
            "           5       1.00      0.90      0.95        10\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       0.80      0.67      0.73         6\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       1.00      0.70      0.82        10\n",
            "          17       0.75      0.71      0.73        17\n",
            "\n",
            "    accuracy                           0.83       116\n",
            "   macro avg       0.87      0.83      0.84       116\n",
            "weighted avg       0.86      0.83      0.83       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8706896551724138, 'f1': 0.87129636935918, 'precision': 0.8922755883962781, 'recall': 0.8706896551724138}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.89      0.73      0.80        11\n",
            "           3       0.71      0.91      0.80        11\n",
            "           4       0.83      0.91      0.87        11\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.83      0.83      0.83         6\n",
            "          13       1.00      0.40      0.57         5\n",
            "          16       0.88      0.70      0.78        10\n",
            "          17       0.76      0.94      0.84        17\n",
            "          24       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.87       116\n",
            "   macro avg       0.83      0.77      0.78       116\n",
            "weighted avg       0.89      0.87      0.87       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.8706896551724138, 'f1': 0.8722376704888388, 'precision': 0.8866310892172962, 'recall': 0.8706896551724138}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       0.89      0.73      0.80        11\n",
            "           3       0.64      0.82      0.72        11\n",
            "           4       0.92      1.00      0.96        11\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       0.83      0.91      0.87        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.83      0.83      0.83         6\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       1.00      0.70      0.82        10\n",
            "          17       0.75      0.88      0.81        17\n",
            "\n",
            "    accuracy                           0.87       116\n",
            "   macro avg       0.90      0.86      0.87       116\n",
            "weighted avg       0.89      0.87      0.87       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8879310344827587, 'f1': 0.891354762528995, 'precision': 0.9129237902057374, 'recall': 0.8879310344827587}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       1.00      0.82      0.90        11\n",
            "           3       0.59      0.91      0.71        11\n",
            "           4       0.79      1.00      0.88        11\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       0.90      0.90      0.90        10\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.86      0.86      0.86         7\n",
            "          13       1.00      0.60      0.75         5\n",
            "          16       1.00      0.90      0.95        10\n",
            "          17       0.93      0.76      0.84        17\n",
            "\n",
            "    accuracy                           0.89       116\n",
            "   macro avg       0.91      0.88      0.89       116\n",
            "weighted avg       0.91      0.89      0.89       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8793103448275862, 'f1': 0.8785808065585824, 'precision': 0.8821979026720407, 'recall': 0.8793103448275862}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.90      0.90      0.90        10\n",
            "           3       0.57      0.73      0.64        11\n",
            "           4       0.92      1.00      0.96        11\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       0.91      1.00      0.95        10\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       0.88      0.78      0.82         9\n",
            "          17       0.78      0.78      0.78        18\n",
            "          24       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.88       116\n",
            "   macro avg       0.83      0.82      0.82       116\n",
            "weighted avg       0.88      0.88      0.88       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.8434782608695652, 'f1': 0.8543313229513607, 'precision': 0.8757885763000853, 'recall': 0.8434782608695652}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.88      0.70      0.78        10\n",
            "           3       0.35      0.55      0.43        11\n",
            "           4       0.92      1.00      0.96        11\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      0.71      0.83         7\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       1.00      1.00      1.00         9\n",
            "          17       0.72      0.72      0.72        18\n",
            "\n",
            "    accuracy                           0.84       115\n",
            "   macro avg       0.90      0.85      0.87       115\n",
            "weighted avg       0.88      0.84      0.85       115\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8956521739130435, 'f1': 0.8971782026428378, 'precision': 0.9292028985507246, 'recall': 0.8956521739130435}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       1.00      0.50      0.67        10\n",
            "           3       0.55      1.00      0.71        11\n",
            "           4       1.00      1.00      1.00        11\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.83      0.71      0.77         7\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       0.90      1.00      0.95         9\n",
            "          17       0.94      0.83      0.88        18\n",
            "\n",
            "    accuracy                           0.90       115\n",
            "   macro avg       0.93      0.90      0.90       115\n",
            "weighted avg       0.93      0.90      0.90       115\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8869565217391304, 'f1': 0.8887740411854723, 'precision': 0.9104037267080746, 'recall': 0.8869565217391304}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       1.00      0.70      0.82        10\n",
            "           3       0.64      0.82      0.72        11\n",
            "           4       1.00      0.82      0.90        11\n",
            "           5       1.00      1.00      1.00         9\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       0.88      1.00      0.93         7\n",
            "          13       1.00      1.00      1.00         4\n",
            "          16       1.00      0.70      0.82        10\n",
            "          17       0.75      1.00      0.86        18\n",
            "\n",
            "    accuracy                           0.89       115\n",
            "   macro avg       0.93      0.89      0.90       115\n",
            "weighted avg       0.91      0.89      0.89       115\n",
            "\n",
            "Average validation scores: {'accuracy': 0.8746776611694151, 'f1': 0.8774291960161481, 'precision': 0.8977157999978628, 'recall': 0.8746776611694151}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set scores: {'accuracy': 0.9074446680080482, 'f1': 0.9080039899044542, 'precision': 0.9154349730620918, 'recall': 0.9074446680080482}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        37\n",
            "           2       0.97      0.76      0.85        50\n",
            "           3       0.71      0.82      0.76        51\n",
            "           4       0.93      0.98      0.96        57\n",
            "           5       1.00      0.96      0.98        53\n",
            "           6       1.00      0.93      0.97        30\n",
            "           7       0.98      0.96      0.97        55\n",
            "          12       0.80      0.76      0.78        21\n",
            "          13       1.00      0.79      0.88        24\n",
            "          16       0.90      0.86      0.88        42\n",
            "          17       0.83      0.97      0.90        77\n",
            "\n",
            "    accuracy                           0.91       497\n",
            "   macro avg       0.92      0.89      0.90       497\n",
            "weighted avg       0.92      0.91      0.91       497\n",
            "\n",
            "Evaluating model: SVM for subject 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8879310344827587, 'f1': 0.890476810206008, 'precision': 0.9061947391688772, 'recall': 0.8879310344827587}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.83      0.91      0.87        11\n",
            "           2       0.90      0.90      0.90        10\n",
            "           3       0.62      0.91      0.74        11\n",
            "           4       0.92      1.00      0.96        12\n",
            "           5       1.00      0.67      0.80         9\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.86      0.86      0.86         7\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       0.80      0.80      0.80        10\n",
            "          17       1.00      0.88      0.94        17\n",
            "\n",
            "    accuracy                           0.89       116\n",
            "   macro avg       0.90      0.88      0.88       116\n",
            "weighted avg       0.91      0.89      0.89       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.9224137931034483, 'f1': 0.9247960307488439, 'precision': 0.9319239189928845, 'recall': 0.9224137931034483}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.91      0.95        11\n",
            "           2       0.89      0.80      0.84        10\n",
            "           3       0.64      0.82      0.72        11\n",
            "           4       1.00      1.00      1.00        12\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       0.86      1.00      0.92         6\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       0.90      0.90      0.90        10\n",
            "          17       0.94      0.94      0.94        17\n",
            "\n",
            "    accuracy                           0.92       116\n",
            "   macro avg       0.93      0.92      0.92       116\n",
            "weighted avg       0.93      0.92      0.92       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8879310344827587, 'f1': 0.8877696139968294, 'precision': 0.8960783230179782, 'recall': 0.8879310344827587}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.80      1.00      0.89        12\n",
            "           2       0.78      0.70      0.74        10\n",
            "           3       0.69      0.82      0.75        11\n",
            "           4       0.92      1.00      0.96        12\n",
            "           5       1.00      0.90      0.95        10\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      0.67      0.80         6\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       0.90      0.90      0.90        10\n",
            "          17       0.88      0.82      0.85        17\n",
            "\n",
            "    accuracy                           0.89       116\n",
            "   macro avg       0.91      0.88      0.89       116\n",
            "weighted avg       0.90      0.89      0.89       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8879310344827587, 'f1': 0.8872503500817285, 'precision': 0.9004476127320955, 'recall': 0.8879310344827587}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        12\n",
            "           2       0.83      0.91      0.87        11\n",
            "           3       0.62      0.91      0.74        11\n",
            "           4       1.00      0.91      0.95        11\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       0.92      1.00      0.96        12\n",
            "          12       1.00      1.00      1.00         6\n",
            "          13       0.67      0.40      0.50         5\n",
            "          16       1.00      0.70      0.82        10\n",
            "          17       0.88      0.88      0.88        17\n",
            "\n",
            "    accuracy                           0.89       116\n",
            "   macro avg       0.90      0.87      0.87       116\n",
            "weighted avg       0.90      0.89      0.89       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8793103448275862, 'f1': 0.8771769977227903, 'precision': 0.8904454022988506, 'recall': 0.8793103448275862}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        12\n",
            "           2       1.00      0.73      0.84        11\n",
            "           3       0.75      0.55      0.63        11\n",
            "           4       1.00      1.00      1.00        11\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.83      0.83      0.83         6\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       0.80      0.80      0.80        10\n",
            "          17       0.71      1.00      0.83        17\n",
            "\n",
            "    accuracy                           0.88       116\n",
            "   macro avg       0.90      0.87      0.88       116\n",
            "weighted avg       0.89      0.88      0.88       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8706896551724138, 'f1': 0.8713231223303819, 'precision': 0.8817141909814324, 'recall': 0.8706896551724138}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      1.00      0.96        12\n",
            "           2       0.73      0.73      0.73        11\n",
            "           3       0.62      0.73      0.67        11\n",
            "           4       0.85      1.00      0.92        11\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       1.00      0.80      0.89        10\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.75      0.86      0.80         7\n",
            "          13       1.00      0.60      0.75         5\n",
            "          16       1.00      0.90      0.95        10\n",
            "          17       0.88      0.82      0.85        17\n",
            "\n",
            "    accuracy                           0.87       116\n",
            "   macro avg       0.89      0.86      0.86       116\n",
            "weighted avg       0.88      0.87      0.87       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8793103448275862, 'f1': 0.8763385224680893, 'precision': 0.8767045454545455, 'recall': 0.8793103448275862}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.73      0.80      0.76        10\n",
            "           3       0.70      0.64      0.67        11\n",
            "           4       1.00      0.91      0.95        11\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       0.90      0.90      0.90        10\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       0.88      1.00      0.93         7\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       0.80      0.89      0.84         9\n",
            "          17       0.80      0.89      0.84        18\n",
            "          24       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.88       116\n",
            "   macro avg       0.82      0.82      0.82       116\n",
            "weighted avg       0.88      0.88      0.88       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.8347826086956521, 'f1': 0.837337952510572, 'precision': 0.8455279503105589, 'recall': 0.8347826086956521}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.86      1.00      0.92        12\n",
            "           2       0.88      0.70      0.78        10\n",
            "           3       0.50      0.55      0.52        11\n",
            "           4       1.00      1.00      1.00        11\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       0.90      0.90      0.90        10\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       0.78      0.78      0.78         9\n",
            "          17       0.65      0.72      0.68        18\n",
            "\n",
            "    accuracy                           0.83       115\n",
            "   macro avg       0.87      0.84      0.85       115\n",
            "weighted avg       0.85      0.83      0.84       115\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.9304347826086956, 'f1': 0.9321489342084307, 'precision': 0.9410059676044331, 'recall': 0.9304347826086956}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       0.67      0.91      0.77        11\n",
            "           4       1.00      1.00      1.00        11\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      0.71      0.83         7\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       0.89      0.89      0.89         9\n",
            "          17       0.88      0.83      0.86        18\n",
            "\n",
            "    accuracy                           0.93       115\n",
            "   macro avg       0.95      0.93      0.94       115\n",
            "weighted avg       0.94      0.93      0.93       115\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8956521739130435, 'f1': 0.8959524724558348, 'precision': 0.905448585231194, 'recall': 0.8956521739130435}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.90      0.90      0.90        10\n",
            "           3       0.71      0.91      0.80        11\n",
            "           4       1.00      0.73      0.84        11\n",
            "           5       1.00      0.89      0.94         9\n",
            "           6       0.83      0.91      0.87        11\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       0.88      1.00      0.93         7\n",
            "          13       0.80      1.00      0.89         4\n",
            "          16       0.78      0.70      0.74        10\n",
            "          17       0.94      0.94      0.94        18\n",
            "\n",
            "    accuracy                           0.90       115\n",
            "   macro avg       0.89      0.90      0.89       115\n",
            "weighted avg       0.91      0.90      0.90       115\n",
            "\n",
            "Average validation scores: {'accuracy': 0.8876386806596702, 'f1': 0.8880570806729509, 'precision': 0.8975491235792848, 'recall': 0.8876386806596702}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set scores: {'accuracy': 0.9074446680080482, 'f1': 0.9080216872278104, 'precision': 0.9117302473248665, 'recall': 0.9074446680080482}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        37\n",
            "           2       0.92      0.90      0.91        50\n",
            "           3       0.71      0.78      0.75        51\n",
            "           4       0.92      0.98      0.95        57\n",
            "           5       0.98      0.92      0.95        53\n",
            "           6       0.88      1.00      0.94        30\n",
            "           7       1.00      0.96      0.98        55\n",
            "          12       0.73      0.76      0.74        21\n",
            "          13       1.00      0.79      0.88        24\n",
            "          16       0.92      0.81      0.86        42\n",
            "          17       0.91      0.94      0.92        77\n",
            "\n",
            "    accuracy                           0.91       497\n",
            "   macro avg       0.91      0.90      0.90       497\n",
            "weighted avg       0.91      0.91      0.91       497\n",
            "\n",
            "Evaluating model: Naive Bayes for subject 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8706896551724138, 'f1': 0.8754917451626992, 'precision': 0.892378873521115, 'recall': 0.8706896551724138}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.91      0.95        11\n",
            "           2       0.89      0.80      0.84        10\n",
            "           3       0.57      0.73      0.64        11\n",
            "           4       1.00      1.00      1.00        12\n",
            "           5       1.00      0.67      0.80         9\n",
            "           6       0.92      1.00      0.96        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       0.83      1.00      0.91         5\n",
            "          16       0.62      0.80      0.70        10\n",
            "          17       0.94      0.88      0.91        17\n",
            "\n",
            "    accuracy                           0.87       116\n",
            "   macro avg       0.89      0.87      0.87       116\n",
            "weighted avg       0.89      0.87      0.88       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8879310344827587, 'f1': 0.8912625701972052, 'precision': 0.9067828723001137, 'recall': 0.8879310344827587}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.73      0.84        11\n",
            "           2       0.90      0.90      0.90        10\n",
            "           3       0.69      0.82      0.75        11\n",
            "           4       1.00      1.00      1.00        12\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.86      1.00      0.92         6\n",
            "          13       0.80      0.80      0.80         5\n",
            "          16       0.64      0.90      0.75        10\n",
            "          17       1.00      0.82      0.90        17\n",
            "\n",
            "    accuracy                           0.89       116\n",
            "   macro avg       0.89      0.89      0.89       116\n",
            "weighted avg       0.91      0.89      0.89       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8620689655172413, 'f1': 0.8630842891786925, 'precision': 0.8764470443349753, 'recall': 0.8620689655172413}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.70      0.70      0.70        10\n",
            "           3       0.79      1.00      0.88        11\n",
            "           4       1.00      0.92      0.96        12\n",
            "           5       1.00      0.90      0.95        10\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       0.75      0.50      0.60         6\n",
            "          13       0.62      1.00      0.77         5\n",
            "          16       0.67      0.80      0.73        10\n",
            "          17       0.87      0.76      0.81        17\n",
            "\n",
            "    accuracy                           0.86       116\n",
            "   macro avg       0.85      0.86      0.85       116\n",
            "weighted avg       0.88      0.86      0.86       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8793103448275862, 'f1': 0.876495268849092, 'precision': 0.8896230685023788, 'recall': 0.8793103448275862}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.75      0.82      0.78        11\n",
            "           3       0.55      0.55      0.55        11\n",
            "           4       1.00      0.91      0.95        11\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.86      1.00      0.92         6\n",
            "          13       1.00      0.40      0.57         5\n",
            "          16       0.77      1.00      0.87        10\n",
            "          17       0.89      0.94      0.91        17\n",
            "\n",
            "    accuracy                           0.88       116\n",
            "   macro avg       0.89      0.86      0.86       116\n",
            "weighted avg       0.89      0.88      0.88       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8448275862068966, 'f1': 0.8486570966054907, 'precision': 0.8620107962213224, 'recall': 0.8448275862068966}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       1.00      0.73      0.84        11\n",
            "           3       0.64      0.64      0.64        11\n",
            "           4       1.00      1.00      1.00        11\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.83      0.83      0.83         6\n",
            "          13       0.67      0.80      0.73         5\n",
            "          16       0.69      0.90      0.78        10\n",
            "          17       0.63      0.71      0.67        17\n",
            "\n",
            "    accuracy                           0.84       116\n",
            "   macro avg       0.86      0.85      0.85       116\n",
            "weighted avg       0.86      0.84      0.85       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8448275862068966, 'f1': 0.8487005429274427, 'precision': 0.8572592637247809, 'recall': 0.8448275862068966}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       0.75      0.82      0.78        11\n",
            "           3       0.46      0.55      0.50        11\n",
            "           4       1.00      1.00      1.00        11\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.86      0.86      0.86         7\n",
            "          13       0.67      0.80      0.73         5\n",
            "          16       0.82      0.90      0.86        10\n",
            "          17       0.80      0.71      0.75        17\n",
            "\n",
            "    accuracy                           0.84       116\n",
            "   macro avg       0.85      0.85      0.85       116\n",
            "weighted avg       0.86      0.84      0.85       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.7931034482758621, 'f1': 0.7921498791836842, 'precision': 0.8016522988505748, 'recall': 0.7931034482758621}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.70      0.70      0.70        10\n",
            "           3       0.40      0.36      0.38        11\n",
            "           4       1.00      0.91      0.95        11\n",
            "           5       1.00      0.90      0.95        10\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       0.75      0.86      0.80         7\n",
            "          13       0.83      1.00      0.91         5\n",
            "          16       0.53      0.89      0.67         9\n",
            "          17       0.69      0.61      0.65        18\n",
            "          24       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.79       116\n",
            "   macro avg       0.74      0.76      0.74       116\n",
            "weighted avg       0.80      0.79      0.79       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.8521739130434782, 'f1': 0.8525256857912313, 'precision': 0.8637857794379534, 'recall': 0.8521739130434782}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      1.00      0.96        12\n",
            "           2       0.73      0.80      0.76        10\n",
            "           3       0.64      0.64      0.64        11\n",
            "           4       1.00      1.00      1.00        11\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       0.64      1.00      0.78         9\n",
            "          17       0.73      0.61      0.67        18\n",
            "\n",
            "    accuracy                           0.85       115\n",
            "   macro avg       0.88      0.87      0.87       115\n",
            "weighted avg       0.86      0.85      0.85       115\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8608695652173913, 'f1': 0.8615302841680083, 'precision': 0.8706906861254688, 'recall': 0.8608695652173913}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       0.77      1.00      0.87        10\n",
            "           3       0.60      0.55      0.57        11\n",
            "           4       1.00      0.91      0.95        11\n",
            "           5       1.00      0.90      0.95        10\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.62      0.71      0.67         7\n",
            "          13       0.83      1.00      0.91         5\n",
            "          16       0.73      0.89      0.80         9\n",
            "          17       0.88      0.78      0.82        18\n",
            "\n",
            "    accuracy                           0.86       115\n",
            "   macro avg       0.86      0.87      0.86       115\n",
            "weighted avg       0.87      0.86      0.86       115\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8608695652173913, 'f1': 0.8621145405862409, 'precision': 0.8820259450694233, 'recall': 0.8608695652173913}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      1.00      0.96        12\n",
            "           2       0.73      0.80      0.76        10\n",
            "           3       0.73      0.73      0.73        11\n",
            "           4       1.00      0.64      0.78        11\n",
            "           5       1.00      0.89      0.94         9\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       0.67      1.00      0.80         4\n",
            "          16       0.67      1.00      0.80        10\n",
            "          17       0.88      0.78      0.82        18\n",
            "\n",
            "    accuracy                           0.86       115\n",
            "   macro avg       0.87      0.88      0.86       115\n",
            "weighted avg       0.88      0.86      0.86       115\n",
            "\n",
            "Average validation scores: {'accuracy': 0.8556671664167916, 'f1': 0.8572011902649788, 'precision': 0.8702656628088107, 'recall': 0.8556671664167916}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set scores: {'accuracy': 0.8752515090543259, 'f1': 0.8777175898511889, 'precision': 0.8829527461550789, 'recall': 0.8752515090543259}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      1.00      0.99        37\n",
            "           2       0.96      0.86      0.91        50\n",
            "           3       0.67      0.71      0.69        51\n",
            "           4       0.98      0.96      0.97        57\n",
            "           5       1.00      0.92      0.96        53\n",
            "           6       1.00      0.93      0.97        30\n",
            "           7       1.00      0.96      0.98        55\n",
            "          12       0.74      0.81      0.77        21\n",
            "          13       0.91      0.83      0.87        24\n",
            "          16       0.73      0.88      0.80        42\n",
            "          17       0.77      0.78      0.77        77\n",
            "\n",
            "    accuracy                           0.88       497\n",
            "   macro avg       0.88      0.88      0.88       497\n",
            "weighted avg       0.88      0.88      0.88       497\n",
            "\n",
            "   subject_id        model  val_accuracy    val_f1  val_precision  val_recall  \\\n",
            "0           6         k-NN      0.874678  0.877429       0.897716    0.874678   \n",
            "1           6          SVM      0.887639  0.888057       0.897549    0.887639   \n",
            "2           6  Naive Bayes      0.855667  0.857201       0.870266    0.855667   \n",
            "\n",
            "   test_accuracy   test_f1  test_precision  test_recall  \n",
            "0       0.907445  0.908004        0.915435     0.907445  \n",
            "1       0.907445  0.908022        0.911730     0.907445  \n",
            "2       0.875252  0.877718        0.882953     0.875252  \n"
          ]
        }
      ],
      "source": [
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "file_path =  '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject106.dat'\n",
        "\n",
        "preprocessor.initializeDataFrame(file_path)\n",
        "preprocessor.dataCleaning()\n",
        "preprocessor.applyPreProcessing()\n",
        "\n",
        "subject_id = int(file_path[-5])\n",
        "subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zS8CoQ_qett",
        "outputId": "88f99c6c-4850-42c2-e9d5-2b4156240b27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame still contains some NAN values\n",
            "Evaluating model: k-NN for subject 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.9259259259259259, 'f1': 0.9221682546390149, 'precision': 0.9269275386922445, 'recall': 0.9259259259259259}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       1.00      0.80      0.89         5\n",
            "           3       0.86      1.00      0.92        12\n",
            "           4       0.94      1.00      0.97        16\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      0.85      0.92        13\n",
            "          12       0.82      1.00      0.90         9\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       1.00      0.90      0.95        10\n",
            "          17       0.80      0.92      0.86        13\n",
            "\n",
            "    accuracy                           0.93       108\n",
            "   macro avg       0.86      0.84      0.84       108\n",
            "weighted avg       0.93      0.93      0.92       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9166666666666666, 'f1': 0.916393559639747, 'precision': 0.9294385655496766, 'recall': 0.9166666666666666}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      0.60      0.75         5\n",
            "           3       0.73      0.92      0.81        12\n",
            "           4       0.89      1.00      0.94        16\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      0.85      0.92        13\n",
            "          12       1.00      0.75      0.86         8\n",
            "          13       0.71      0.83      0.77         6\n",
            "          16       1.00      1.00      1.00        11\n",
            "          17       0.93      1.00      0.96        13\n",
            "\n",
            "    accuracy                           0.92       108\n",
            "   macro avg       0.93      0.90      0.91       108\n",
            "weighted avg       0.93      0.92      0.92       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9351851851851852, 'f1': 0.935801434726166, 'precision': 0.9420479302832243, 'recall': 0.9351851851851852}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       0.80      0.67      0.73         6\n",
            "           3       0.91      0.91      0.91        11\n",
            "           4       1.00      0.94      0.97        16\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       0.83      0.83      0.83         6\n",
            "          16       1.00      0.91      0.95        11\n",
            "          17       0.76      1.00      0.87        13\n",
            "\n",
            "    accuracy                           0.94       108\n",
            "   macro avg       0.94      0.92      0.93       108\n",
            "weighted avg       0.94      0.94      0.94       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9074074074074074, 'f1': 0.9093886377486682, 'precision': 0.9247976968565204, 'recall': 0.9074074074074074}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       0.83      0.83      0.83         6\n",
            "           3       0.79      1.00      0.88        11\n",
            "           4       0.94      1.00      0.97        16\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       1.00      0.83      0.91         6\n",
            "          16       1.00      0.73      0.84        11\n",
            "          17       0.71      0.92      0.80        13\n",
            "\n",
            "    accuracy                           0.91       108\n",
            "   macro avg       0.93      0.90      0.91       108\n",
            "weighted avg       0.92      0.91      0.91       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9074074074074074, 'f1': 0.9078466321058913, 'precision': 0.9128960273568116, 'recall': 0.9074074074074074}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       0.83      0.83      0.83         6\n",
            "           3       0.77      0.91      0.83        11\n",
            "           4       0.82      0.88      0.85        16\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       0.80      0.67      0.73         6\n",
            "          16       0.92      1.00      0.96        11\n",
            "          17       0.93      1.00      0.96        13\n",
            "\n",
            "    accuracy                           0.91       108\n",
            "   macro avg       0.92      0.90      0.91       108\n",
            "weighted avg       0.91      0.91      0.91       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9166666666666666, 'f1': 0.9170619229194545, 'precision': 0.9301081543728602, 'recall': 0.9166666666666666}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.85      0.92        13\n",
            "           2       1.00      0.83      0.91         6\n",
            "           3       0.79      1.00      0.88        11\n",
            "           4       0.94      1.00      0.97        16\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.88      0.88      0.88         8\n",
            "          13       1.00      0.83      0.91         6\n",
            "          16       1.00      0.73      0.84        11\n",
            "          17       0.75      0.92      0.83        13\n",
            "\n",
            "    accuracy                           0.92       108\n",
            "   macro avg       0.94      0.91      0.92       108\n",
            "weighted avg       0.93      0.92      0.92       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.8611111111111112, 'f1': 0.8606176465120767, 'precision': 0.8794590643274853, 'recall': 0.8611111111111112}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        13\n",
            "           2       0.80      0.67      0.73         6\n",
            "           3       0.82      0.82      0.82        11\n",
            "           4       0.79      0.94      0.86        16\n",
            "           5       1.00      1.00      1.00         2\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      0.75      0.86         8\n",
            "          13       1.00      0.60      0.75         5\n",
            "          16       0.88      0.70      0.78        10\n",
            "          17       0.70      1.00      0.82        14\n",
            "\n",
            "    accuracy                           0.86       108\n",
            "   macro avg       0.90      0.84      0.86       108\n",
            "weighted avg       0.88      0.86      0.86       108\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8878504672897196, 'f1': 0.8846438973558738, 'precision': 0.8931014773510649, 'recall': 0.8878504672897196}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.85      0.88        13\n",
            "           2       0.71      0.83      0.77         6\n",
            "           3       0.71      1.00      0.83        12\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       1.00      0.82      0.90        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       0.75      0.60      0.67         5\n",
            "          16       0.89      0.80      0.84        10\n",
            "          17       0.88      1.00      0.93        14\n",
            "\n",
            "    accuracy                           0.89       107\n",
            "   macro avg       0.80      0.79      0.79       107\n",
            "weighted avg       0.89      0.89      0.88       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.8878504672897196, 'f1': 0.8894210480741541, 'precision': 0.8966696335855214, 'recall': 0.8878504672897196}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.85      0.92        13\n",
            "           2       1.00      1.00      1.00         6\n",
            "           3       0.71      0.83      0.77        12\n",
            "           4       0.93      0.93      0.93        15\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.78      0.88      0.82         8\n",
            "          13       0.75      0.60      0.67         5\n",
            "          16       0.90      0.90      0.90        10\n",
            "          17       0.80      0.92      0.86        13\n",
            "\n",
            "    accuracy                           0.89       107\n",
            "   macro avg       0.90      0.89      0.89       107\n",
            "weighted avg       0.90      0.89      0.89       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9719626168224299, 'f1': 0.9719883983242025, 'precision': 0.9726815240833933, 'recall': 0.9719626168224299}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00         6\n",
            "           3       0.92      1.00      0.96        12\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       0.90      0.90      0.90        10\n",
            "          17       0.92      0.92      0.92        13\n",
            "\n",
            "    accuracy                           0.97       107\n",
            "   macro avg       0.98      0.98      0.98       107\n",
            "weighted avg       0.97      0.97      0.97       107\n",
            "\n",
            "Average validation scores: {'accuracy': 0.911803392177224, 'f1': 0.9115331432045248, 'precision': 0.9208127612458803, 'recall': 0.911803392177224}\n",
            "Test set scores: {'accuracy': 0.9307359307359307, 'f1': 0.9306963274582555, 'precision': 0.9352839612348456, 'recall': 0.9307359307359307}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.98      0.98      0.98        41\n",
            "           2       1.00      0.96      0.98        23\n",
            "           3       0.79      0.98      0.87        56\n",
            "           4       0.97      1.00      0.99        67\n",
            "           5       1.00      0.75      0.86        12\n",
            "           6       1.00      0.97      0.99        40\n",
            "           7       1.00      0.97      0.98        67\n",
            "          12       0.94      0.89      0.91        35\n",
            "          13       0.95      0.95      0.95        20\n",
            "          16       0.88      0.76      0.82        38\n",
            "          17       0.89      0.86      0.87        63\n",
            "\n",
            "    accuracy                           0.93       462\n",
            "   macro avg       0.94      0.92      0.93       462\n",
            "weighted avg       0.94      0.93      0.93       462\n",
            "\n",
            "Evaluating model: SVM for subject 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.9259259259259259, 'f1': 0.9216183599809332, 'precision': 0.9225529100529101, 'recall': 0.9259259259259259}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       1.00      0.80      0.89         5\n",
            "           3       0.86      1.00      0.92        12\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       0.92      0.85      0.88        13\n",
            "          12       0.90      1.00      0.95         9\n",
            "          13       0.80      0.80      0.80         5\n",
            "          16       0.83      1.00      0.91        10\n",
            "          17       0.92      0.92      0.92        13\n",
            "\n",
            "    accuracy                           0.93       108\n",
            "   macro avg       0.84      0.84      0.83       108\n",
            "weighted avg       0.92      0.93      0.92       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9074074074074074, 'f1': 0.9067497718357338, 'precision': 0.9102366255144032, 'recall': 0.9074074074074074}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        12\n",
            "           2       1.00      1.00      1.00         5\n",
            "           3       0.83      0.83      0.83        12\n",
            "           4       0.89      1.00      0.94        16\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      0.85      0.92        13\n",
            "          12       0.86      0.75      0.80         8\n",
            "          13       0.83      0.83      0.83         6\n",
            "          16       0.92      1.00      0.96        11\n",
            "          17       0.86      0.92      0.89        13\n",
            "\n",
            "    accuracy                           0.91       108\n",
            "   macro avg       0.92      0.91      0.91       108\n",
            "weighted avg       0.91      0.91      0.91       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9166666666666666, 'f1': 0.9144129466710111, 'precision': 0.9160493827160494, 'recall': 0.9166666666666666}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.87      1.00      0.93        13\n",
            "           2       0.60      0.50      0.55         6\n",
            "           3       0.80      0.73      0.76        11\n",
            "           4       1.00      0.94      0.97        16\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       0.83      0.83      0.83         6\n",
            "          16       1.00      1.00      1.00        11\n",
            "          17       0.87      1.00      0.93        13\n",
            "\n",
            "    accuracy                           0.92       108\n",
            "   macro avg       0.91      0.90      0.90       108\n",
            "weighted avg       0.92      0.92      0.91       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.8981481481481481, 'f1': 0.8970162879966802, 'precision': 0.8992283950617285, 'recall': 0.8981481481481481}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       0.83      0.83      0.83         6\n",
            "           3       0.80      0.73      0.76        11\n",
            "           4       0.89      1.00      0.94        16\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       0.92      1.00      0.96        11\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       0.89      1.00      0.94         8\n",
            "          13       0.83      0.83      0.83         6\n",
            "          16       0.90      0.82      0.86        11\n",
            "          17       0.85      0.85      0.85        13\n",
            "\n",
            "    accuracy                           0.90       108\n",
            "   macro avg       0.90      0.90      0.90       108\n",
            "weighted avg       0.90      0.90      0.90       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9074074074074074, 'f1': 0.909438866502915, 'precision': 0.9153371320037986, 'recall': 0.9074074074074074}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        13\n",
            "           2       0.83      0.83      0.83         6\n",
            "           3       0.69      0.82      0.75        11\n",
            "           4       0.93      0.88      0.90        16\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       0.83      0.83      0.83         6\n",
            "          16       0.85      1.00      0.92        11\n",
            "          17       1.00      0.92      0.96        13\n",
            "\n",
            "    accuracy                           0.91       108\n",
            "   macro avg       0.91      0.91      0.91       108\n",
            "weighted avg       0.92      0.91      0.91       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9259259259259259, 'f1': 0.9254231143489455, 'precision': 0.929803735359291, 'recall': 0.9259259259259259}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.85      0.92        13\n",
            "           2       0.83      0.83      0.83         6\n",
            "           3       0.85      1.00      0.92        11\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       0.92      1.00      0.96        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.89      1.00      0.94         8\n",
            "          13       1.00      0.83      0.91         6\n",
            "          16       0.82      0.82      0.82        11\n",
            "          17       0.92      0.85      0.88        13\n",
            "\n",
            "    accuracy                           0.93       108\n",
            "   macro avg       0.93      0.93      0.92       108\n",
            "weighted avg       0.93      0.93      0.93       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9074074074074074, 'f1': 0.9066431510875955, 'precision': 0.9170019795019796, 'recall': 0.9074074074074074}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.86      0.92      0.89        13\n",
            "           2       1.00      0.67      0.80         6\n",
            "           3       0.77      0.91      0.83        11\n",
            "           4       0.94      0.94      0.94        16\n",
            "           5       1.00      1.00      1.00         2\n",
            "           6       1.00      0.82      0.90        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      0.75      0.86         8\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       0.82      0.90      0.86        10\n",
            "          17       0.88      1.00      0.93        14\n",
            "\n",
            "    accuracy                           0.91       108\n",
            "   macro avg       0.93      0.90      0.91       108\n",
            "weighted avg       0.92      0.91      0.91       108\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8878504672897196, 'f1': 0.8875780734465878, 'precision': 0.9020107618238461, 'recall': 0.8878504672897196}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        13\n",
            "           2       0.83      0.83      0.83         6\n",
            "           3       0.61      0.92      0.73        12\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       1.00      0.82      0.90        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       1.00      0.60      0.75         5\n",
            "          16       0.82      0.90      0.86        10\n",
            "          17       0.93      0.93      0.93        14\n",
            "\n",
            "    accuracy                           0.89       107\n",
            "   macro avg       0.83      0.79      0.80       107\n",
            "weighted avg       0.90      0.89      0.89       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9252336448598131, 'f1': 0.9254908079948364, 'precision': 0.9355625682728486, 'recall': 0.9252336448598131}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       0.86      1.00      0.92         6\n",
            "           3       0.73      0.92      0.81        12\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.88      0.88      0.88         8\n",
            "          13       1.00      0.60      0.75         5\n",
            "          16       0.91      1.00      0.95        10\n",
            "          17       0.93      1.00      0.96        13\n",
            "\n",
            "    accuracy                           0.93       107\n",
            "   macro avg       0.94      0.92      0.92       107\n",
            "weighted avg       0.94      0.93      0.93       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9252336448598131, 'f1': 0.9252961585346795, 'precision': 0.9262046364850103, 'recall': 0.9252336448598131}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       0.71      0.83      0.77         6\n",
            "           3       0.82      0.75      0.78        12\n",
            "           4       0.93      0.93      0.93        15\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       0.80      0.80      0.80         5\n",
            "          16       0.90      0.90      0.90        10\n",
            "          17       0.92      0.92      0.92        13\n",
            "\n",
            "    accuracy                           0.93       107\n",
            "   macro avg       0.92      0.92      0.92       107\n",
            "weighted avg       0.93      0.93      0.93       107\n",
            "\n",
            "Average validation scores: {'accuracy': 0.9127206645898234, 'f1': 0.911966753839992, 'precision': 0.9173988126791865, 'recall': 0.9127206645898234}\n",
            "Test set scores: {'accuracy': 0.9307359307359307, 'f1': 0.9315277716470884, 'precision': 0.9372202771105592, 'recall': 0.9307359307359307}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.87      0.98      0.92        41\n",
            "           2       0.95      0.83      0.88        23\n",
            "           3       0.77      0.95      0.85        56\n",
            "           4       1.00      0.99      0.99        67\n",
            "           5       1.00      0.75      0.86        12\n",
            "           6       1.00      0.97      0.99        40\n",
            "           7       0.99      0.99      0.99        67\n",
            "          12       0.91      0.86      0.88        35\n",
            "          13       1.00      0.95      0.97        20\n",
            "          16       0.92      0.87      0.89        38\n",
            "          17       0.97      0.89      0.93        63\n",
            "\n",
            "    accuracy                           0.93       462\n",
            "   macro avg       0.94      0.91      0.92       462\n",
            "weighted avg       0.94      0.93      0.93       462\n",
            "\n",
            "Evaluating model: Naive Bayes for subject 7\n",
            "Fold scores: {'accuracy': 0.8981481481481481, 'f1': 0.8963123455444838, 'precision': 0.9036335578002245, 'recall': 0.8981481481481481}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       0.80      0.80      0.80         5\n",
            "           3       0.91      0.83      0.87        12\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       0.92      0.85      0.88        13\n",
            "          12       0.90      1.00      0.95         9\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       0.67      1.00      0.80        10\n",
            "          17       0.85      0.85      0.85        13\n",
            "\n",
            "    accuracy                           0.90       108\n",
            "   macro avg       0.82      0.81      0.81       108\n",
            "weighted avg       0.90      0.90      0.90       108\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.9074074074074074, 'f1': 0.9063371232453358, 'precision': 0.9093542260208928, 'recall': 0.9074074074074074}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      1.00      0.96        12\n",
            "           2       0.83      1.00      0.91         5\n",
            "           3       0.90      0.75      0.82        12\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.86      0.75      0.80         8\n",
            "          13       0.83      0.83      0.83         6\n",
            "          16       0.83      0.91      0.87        11\n",
            "          17       0.86      0.92      0.89        13\n",
            "\n",
            "    accuracy                           0.91       108\n",
            "   macro avg       0.90      0.91      0.90       108\n",
            "weighted avg       0.91      0.91      0.91       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.8796296296296297, 'f1': 0.8786815242370799, 'precision': 0.8933862433862435, 'recall': 0.8796296296296297}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.86      0.92      0.89        13\n",
            "           2       0.80      0.67      0.73         6\n",
            "           3       1.00      0.64      0.78        11\n",
            "           4       1.00      0.88      0.93        16\n",
            "           5       0.50      1.00      0.67         1\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.88      0.88      0.88         8\n",
            "          13       0.83      0.83      0.83         6\n",
            "          16       0.79      1.00      0.88        11\n",
            "          17       0.80      0.92      0.86        13\n",
            "\n",
            "    accuracy                           0.88       108\n",
            "   macro avg       0.85      0.88      0.85       108\n",
            "weighted avg       0.89      0.88      0.88       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9166666666666666, 'f1': 0.9197782037312272, 'precision': 0.9284336419753088, 'recall': 0.9166666666666666}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       1.00      0.83      0.91         6\n",
            "           3       0.83      0.91      0.87        11\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.83      0.91         6\n",
            "          16       0.83      0.91      0.87        11\n",
            "          17       0.69      0.85      0.76        13\n",
            "\n",
            "    accuracy                           0.92       108\n",
            "   macro avg       0.94      0.92      0.93       108\n",
            "weighted avg       0.93      0.92      0.92       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9259259259259259, 'f1': 0.9262706927550313, 'precision': 0.9359567901234568, 'recall': 0.9259259259259259}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       1.00      1.00      1.00         6\n",
            "           3       0.92      1.00      0.96        11\n",
            "           4       0.93      0.88      0.90        16\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.67      0.80         6\n",
            "          16       0.73      1.00      0.85        11\n",
            "          17       0.85      0.85      0.85        13\n",
            "\n",
            "    accuracy                           0.93       108\n",
            "   macro avg       0.95      0.93      0.93       108\n",
            "weighted avg       0.94      0.93      0.93       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9444444444444444, 'f1': 0.9446274337578685, 'precision': 0.9488366571699905, 'recall': 0.9444444444444444}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.85      0.92        13\n",
            "           2       1.00      0.83      0.91         6\n",
            "           3       0.85      1.00      0.92        11\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       0.83      0.83      0.83         6\n",
            "          16       0.83      0.91      0.87        11\n",
            "          17       0.92      0.92      0.92        13\n",
            "\n",
            "    accuracy                           0.94       108\n",
            "   macro avg       0.95      0.94      0.94       108\n",
            "weighted avg       0.95      0.94      0.94       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9351851851851852, 'f1': 0.9364359545273524, 'precision': 0.9434156378600823, 'recall': 0.9351851851851852}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       1.00      0.83      0.91         6\n",
            "           3       0.82      0.82      0.82        11\n",
            "           4       1.00      0.94      0.97        16\n",
            "           5       1.00      1.00      1.00         2\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       1.00      1.00      1.00        10\n",
            "          17       0.78      1.00      0.88        14\n",
            "\n",
            "    accuracy                           0.94       108\n",
            "   macro avg       0.96      0.94      0.94       108\n",
            "weighted avg       0.94      0.94      0.94       108\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8878504672897196, 'f1': 0.8851364340890606, 'precision': 0.8962616822429907, 'recall': 0.8878504672897196}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.85      0.92        13\n",
            "           2       1.00      0.83      0.91         6\n",
            "           3       0.69      0.92      0.79        12\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.90      0.82      0.86        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.88      0.88      0.88         8\n",
            "          13       1.00      0.60      0.75         5\n",
            "          16       0.75      0.90      0.82        10\n",
            "          17       0.88      1.00      0.93        14\n",
            "\n",
            "    accuracy                           0.89       107\n",
            "   macro avg       0.83      0.79      0.80       107\n",
            "weighted avg       0.90      0.89      0.89       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9065420560747663, 'f1': 0.90714370175878, 'precision': 0.9156322908659358, 'recall': 0.9065420560747663}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.85      0.88        13\n",
            "           2       0.86      1.00      0.92         6\n",
            "           3       0.80      1.00      0.89        12\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      0.82      0.90        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.78      0.88      0.82         8\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       0.91      1.00      0.95        10\n",
            "          17       0.85      0.85      0.85        13\n",
            "\n",
            "    accuracy                           0.91       107\n",
            "   macro avg       0.92      0.91      0.91       107\n",
            "weighted avg       0.92      0.91      0.91       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9532710280373832, 'f1': 0.952511841651384, 'precision': 0.9549217138002185, 'recall': 0.9532710280373832}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       0.86      1.00      0.92         6\n",
            "           3       0.90      0.75      0.82        12\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       0.91      1.00      0.95        10\n",
            "          17       0.86      0.92      0.89        13\n",
            "\n",
            "    accuracy                           0.95       107\n",
            "   macro avg       0.96      0.96      0.96       107\n",
            "weighted avg       0.95      0.95      0.95       107\n",
            "\n",
            "Average validation scores: {'accuracy': 0.9155070958809276, 'f1': 0.9153235255297604, 'precision': 0.9229832441245345, 'recall': 0.9155070958809276}\n",
            "Test set scores: {'accuracy': 0.9112554112554112, 'f1': 0.9122912575531323, 'precision': 0.9189507050889403, 'recall': 0.9112554112554112}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.98      0.99        41\n",
            "           2       0.83      0.87      0.85        23\n",
            "           3       0.86      0.91      0.89        56\n",
            "           4       1.00      0.99      0.99        67\n",
            "           5       0.82      0.75      0.78        12\n",
            "           6       1.00      1.00      1.00        40\n",
            "           7       0.99      0.99      0.99        67\n",
            "          12       0.91      0.83      0.87        35\n",
            "          13       1.00      0.90      0.95        20\n",
            "          16       0.67      0.92      0.78        38\n",
            "          17       0.89      0.75      0.81        63\n",
            "\n",
            "    accuracy                           0.91       462\n",
            "   macro avg       0.91      0.90      0.90       462\n",
            "weighted avg       0.92      0.91      0.91       462\n",
            "\n",
            "   subject_id        model  val_accuracy    val_f1  val_precision  val_recall  \\\n",
            "0           6         k-NN      0.874678  0.877429       0.897716    0.874678   \n",
            "1           6          SVM      0.887639  0.888057       0.897549    0.887639   \n",
            "2           6  Naive Bayes      0.855667  0.857201       0.870266    0.855667   \n",
            "3           7         k-NN      0.911803  0.911533       0.920813    0.911803   \n",
            "4           7          SVM      0.912721  0.911967       0.917399    0.912721   \n",
            "5           7  Naive Bayes      0.915507  0.915324       0.922983    0.915507   \n",
            "\n",
            "   test_accuracy   test_f1  test_precision  test_recall  \n",
            "0       0.907445  0.908004        0.915435     0.907445  \n",
            "1       0.907445  0.908022        0.911730     0.907445  \n",
            "2       0.875252  0.877718        0.882953     0.875252  \n",
            "3       0.930736  0.930696        0.935284     0.930736  \n",
            "4       0.930736  0.931528        0.937220     0.930736  \n",
            "5       0.911255  0.912291        0.918951     0.911255  \n"
          ]
        }
      ],
      "source": [
        "# Generate features and labels for each subject using PreProcessor and FeatureExtraction\n",
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "file_path =  '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject107.dat'\n",
        "\n",
        "preprocessor.initializeDataFrame(file_path)\n",
        "preprocessor.dataCleaning()\n",
        "preprocessor.applyPreProcessing()\n",
        "\n",
        "subject_id = int(file_path[-5])\n",
        "subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PeZI_grqlpd",
        "outputId": "32ad712d-9cad-4461-a2bb-7d8c4ab1649d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model: k-NN for subject 8\n",
            "Fold scores: {'accuracy': 0.9016393442622951, 'f1': 0.9004550751990147, 'precision': 0.9179303278688524, 'recall': 0.9016393442622951}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.85      0.92        13\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       0.73      0.92      0.81        12\n",
            "           4       0.94      1.00      0.97        15\n",
            "           5       1.00      1.00      1.00         9\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.80      0.89         5\n",
            "          13       1.00      0.50      0.67         4\n",
            "          16       0.88      0.64      0.74        11\n",
            "          17       0.70      0.93      0.80        15\n",
            "          24       1.00      0.75      0.86         4\n",
            "\n",
            "    accuracy                           0.90       122\n",
            "   macro avg       0.94      0.87      0.89       122\n",
            "weighted avg       0.92      0.90      0.90       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8852459016393442, 'f1': 0.8856147024867278, 'precision': 0.9026929127338965, 'recall': 0.8852459016393442}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.85      0.88        13\n",
            "           2       0.82      0.90      0.86        10\n",
            "           3       0.89      0.73      0.80        11\n",
            "           4       0.88      0.93      0.90        15\n",
            "           5       1.00      1.00      1.00         9\n",
            "           6       1.00      0.82      0.90        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.80      0.89         5\n",
            "          13       1.00      1.00      1.00         4\n",
            "          16       0.90      0.82      0.86        11\n",
            "          17       0.68      1.00      0.81        15\n",
            "          24       1.00      0.60      0.75         5\n",
            "\n",
            "    accuracy                           0.89       122\n",
            "   macro avg       0.92      0.87      0.89       122\n",
            "weighted avg       0.90      0.89      0.89       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9180327868852459, 'f1': 0.9180347153440526, 'precision': 0.9256725514922236, 'recall': 0.9180327868852459}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.77      0.87        13\n",
            "           2       0.90      0.90      0.90        10\n",
            "           3       0.69      0.82      0.75        11\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       0.93      1.00      0.97        14\n",
            "          12       1.00      1.00      1.00         5\n",
            "          13       0.75      0.60      0.67         5\n",
            "          16       1.00      0.91      0.95        11\n",
            "          17       0.83      1.00      0.91        15\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.92       122\n",
            "   macro avg       0.93      0.91      0.91       122\n",
            "weighted avg       0.93      0.92      0.92       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9669421487603306, 'f1': 0.9669350906010985, 'precision': 0.9702641387133366, 'recall': 0.9669421487603306}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       0.83      0.91      0.87        11\n",
            "           4       1.00      1.00      1.00        15\n",
            "           5       1.00      0.88      0.93         8\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      1.00      1.00         5\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       1.00      1.00      1.00        11\n",
            "          17       0.88      1.00      0.94        15\n",
            "          24       1.00      0.75      0.86         4\n",
            "\n",
            "    accuracy                           0.97       121\n",
            "   macro avg       0.98      0.95      0.96       121\n",
            "weighted avg       0.97      0.97      0.97       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.8677685950413223, 'f1': 0.8649951899951901, 'precision': 0.8949724517906337, 'recall': 0.8677685950413223}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      0.80      0.89        10\n",
            "           3       0.62      0.91      0.74        11\n",
            "           4       1.00      1.00      1.00        15\n",
            "           5       1.00      0.88      0.93         8\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       0.75      0.60      0.67         5\n",
            "          13       0.80      0.80      0.80         5\n",
            "          16       1.00      0.45      0.62        11\n",
            "          17       0.67      0.93      0.78        15\n",
            "          24       0.67      0.50      0.57         4\n",
            "\n",
            "    accuracy                           0.87       121\n",
            "   macro avg       0.88      0.82      0.83       121\n",
            "weighted avg       0.89      0.87      0.86       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.8925619834710744, 'f1': 0.8902020523255361, 'precision': 0.9104250014556284, 'recall': 0.8925619834710744}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       1.00      0.60      0.75        10\n",
            "           3       0.71      1.00      0.83        12\n",
            "           4       1.00      0.93      0.96        14\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       0.86      0.92      0.89        13\n",
            "          12       0.75      0.60      0.67         5\n",
            "          13       1.00      0.60      0.75         5\n",
            "          16       0.91      0.83      0.87        12\n",
            "          17       0.78      1.00      0.88        14\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.89       121\n",
            "   macro avg       0.92      0.87      0.88       121\n",
            "weighted avg       0.91      0.89      0.89       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.9338842975206612, 'f1': 0.9328250924226489, 'precision': 0.9401023219205038, 'recall': 0.9338842975206612}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       0.86      1.00      0.92        12\n",
            "           4       0.88      1.00      0.93        14\n",
            "           5       1.00      0.88      0.93         8\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.83      1.00      0.91         5\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       0.90      0.75      0.82        12\n",
            "          17       0.88      1.00      0.93        14\n",
            "          24       1.00      0.75      0.86         4\n",
            "\n",
            "    accuracy                           0.93       121\n",
            "   macro avg       0.95      0.92      0.93       121\n",
            "weighted avg       0.94      0.93      0.93       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.8760330578512396, 'f1': 0.8777971403908436, 'precision': 0.8941879381354344, 'recall': 0.8760330578512396}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        12\n",
            "           2       0.90      0.90      0.90        10\n",
            "           3       0.65      0.92      0.76        12\n",
            "           4       0.93      0.93      0.93        14\n",
            "           5       1.00      0.88      0.93         8\n",
            "           6       1.00      0.92      0.96        12\n",
            "           7       0.91      0.77      0.83        13\n",
            "          12       0.71      1.00      0.83         5\n",
            "          13       1.00      0.60      0.75         5\n",
            "          16       0.91      0.83      0.87        12\n",
            "          17       0.87      0.93      0.90        14\n",
            "          24       1.00      0.75      0.86         4\n",
            "\n",
            "    accuracy                           0.88       121\n",
            "   macro avg       0.90      0.86      0.87       121\n",
            "weighted avg       0.89      0.88      0.88       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.9421487603305785, 'f1': 0.9416661485790877, 'precision': 0.9476259925457787, 'recall': 0.9421487603305785}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.83      1.00      0.91        10\n",
            "           3       0.90      0.75      0.82        12\n",
            "           4       0.93      0.93      0.93        14\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      1.00      1.00         5\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       1.00      0.83      0.91        12\n",
            "          17       0.82      1.00      0.90        14\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.94       121\n",
            "   macro avg       0.96      0.95      0.95       121\n",
            "weighted avg       0.95      0.94      0.94       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.8016528925619835, 'f1': 0.7992248561731993, 'precision': 0.8347419959719424, 'recall': 0.8016528925619835}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        13\n",
            "           2       0.86      0.60      0.71        10\n",
            "           3       0.50      0.83      0.62        12\n",
            "           4       0.82      1.00      0.90        14\n",
            "           5       1.00      0.62      0.77         8\n",
            "           6       1.00      0.83      0.91        12\n",
            "           7       0.85      0.85      0.85        13\n",
            "          12       0.75      0.60      0.67         5\n",
            "          13       0.75      0.75      0.75         4\n",
            "          16       0.80      0.73      0.76        11\n",
            "          17       0.82      0.93      0.87        15\n",
            "          24       1.00      0.25      0.40         4\n",
            "\n",
            "    accuracy                           0.80       121\n",
            "   macro avg       0.84      0.74      0.76       121\n",
            "weighted avg       0.83      0.80      0.80       121\n",
            "\n",
            "Average validation scores: {'accuracy': 0.8985909768324076, 'f1': 0.8977750063517398, 'precision': 0.9138615632628231, 'recall': 0.8985909768324076}\n",
            "Test set scores: {'accuracy': 0.9117082533589251, 'f1': 0.9128803123681026, 'precision': 0.9232347489032247, 'recall': 0.9117082533589251}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        36\n",
            "           2       1.00      0.86      0.93        51\n",
            "           3       0.72      0.92      0.81        51\n",
            "           4       0.94      0.95      0.95        65\n",
            "           5       1.00      0.85      0.92        27\n",
            "           6       0.96      0.96      0.96        52\n",
            "           7       0.98      0.98      0.98        61\n",
            "          12       1.00      0.80      0.89        25\n",
            "          13       0.93      0.81      0.87        16\n",
            "          16       0.93      0.79      0.85        47\n",
            "          17       0.80      0.96      0.88        73\n",
            "          24       1.00      0.76      0.87        17\n",
            "\n",
            "    accuracy                           0.91       521\n",
            "   macro avg       0.94      0.89      0.91       521\n",
            "weighted avg       0.92      0.91      0.91       521\n",
            "\n",
            "Evaluating model: SVM for subject 8\n",
            "Fold scores: {'accuracy': 0.8934426229508197, 'f1': 0.893558481962, 'precision': 0.8966530054644809, 'recall': 0.8934426229508197}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.85      0.85      0.85        13\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       0.83      0.83      0.83        12\n",
            "           4       0.93      0.93      0.93        15\n",
            "           5       1.00      1.00      1.00         9\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       0.87      1.00      0.93        13\n",
            "          12       1.00      0.80      0.89         5\n",
            "          13       0.75      0.75      0.75         4\n",
            "          16       0.73      0.73      0.73        11\n",
            "          17       0.88      0.93      0.90        15\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.89       122\n",
            "   macro avg       0.90      0.89      0.89       122\n",
            "weighted avg       0.90      0.89      0.89       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9262295081967213, 'f1': 0.9268422128088607, 'precision': 0.9327868852459016, 'recall': 0.9262295081967213}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.85      0.92        13\n",
            "           2       0.83      1.00      0.91        10\n",
            "           3       0.90      0.82      0.86        11\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       1.00      1.00      1.00         9\n",
            "           6       0.90      0.82      0.86        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      1.00      1.00         5\n",
            "          13       1.00      1.00      1.00         4\n",
            "          16       0.91      0.91      0.91        11\n",
            "          17       0.78      0.93      0.85        15\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.93       122\n",
            "   macro avg       0.94      0.94      0.94       122\n",
            "weighted avg       0.93      0.93      0.93       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9344262295081968, 'f1': 0.9354185729149477, 'precision': 0.9439535873962104, 'recall': 0.9344262295081968}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.85      0.88        13\n",
            "           2       0.91      1.00      0.95        10\n",
            "           3       0.64      0.82      0.72        11\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       0.92      1.00      0.96        11\n",
            "           7       1.00      1.00      1.00        14\n",
            "          12       1.00      1.00      1.00         5\n",
            "          13       1.00      0.60      0.75         5\n",
            "          16       1.00      1.00      1.00        11\n",
            "          17       1.00      0.93      0.97        15\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.93       122\n",
            "   macro avg       0.95      0.93      0.93       122\n",
            "weighted avg       0.94      0.93      0.94       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9256198347107438, 'f1': 0.9240117076686396, 'precision': 0.9289882294014525, 'recall': 0.9256198347107438}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.87      1.00      0.93        13\n",
            "           2       0.91      1.00      0.95        10\n",
            "           3       0.80      0.73      0.76        11\n",
            "           4       1.00      1.00      1.00        15\n",
            "           5       1.00      0.88      0.93         8\n",
            "           6       1.00      0.82      0.90        11\n",
            "           7       0.93      1.00      0.96        13\n",
            "          12       1.00      1.00      1.00         5\n",
            "          13       0.83      1.00      0.91         5\n",
            "          16       0.92      1.00      0.96        11\n",
            "          17       0.93      0.87      0.90        15\n",
            "          24       1.00      0.75      0.86         4\n",
            "\n",
            "    accuracy                           0.93       121\n",
            "   macro avg       0.93      0.92      0.92       121\n",
            "weighted avg       0.93      0.93      0.92       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.8925619834710744, 'f1': 0.8888484589736413, 'precision': 0.9102938060157312, 'recall': 0.8925619834710744}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      1.00      0.96        12\n",
            "           2       1.00      0.80      0.89        10\n",
            "           3       0.67      0.91      0.77        11\n",
            "           4       0.88      1.00      0.94        15\n",
            "           5       1.00      0.88      0.93         8\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.60      0.75         5\n",
            "          13       0.60      0.60      0.60         5\n",
            "          16       1.00      0.55      0.71        11\n",
            "          17       0.83      1.00      0.91        15\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.89       121\n",
            "   macro avg       0.91      0.86      0.87       121\n",
            "weighted avg       0.91      0.89      0.89       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.8925619834710744, 'f1': 0.8925937596293329, 'precision': 0.9058703922340284, 'recall': 0.8925619834710744}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       1.00      0.80      0.89        10\n",
            "           3       0.71      0.83      0.77        12\n",
            "           4       1.00      0.93      0.96        14\n",
            "           5       0.80      1.00      0.89         8\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.75      0.60      0.67         5\n",
            "          13       1.00      0.60      0.75         5\n",
            "          16       0.83      0.83      0.83        12\n",
            "          17       0.78      1.00      0.88        14\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.89       121\n",
            "   macro avg       0.91      0.87      0.88       121\n",
            "weighted avg       0.91      0.89      0.89       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.9173553719008265, 'f1': 0.9176540987392586, 'precision': 0.9224714679260134, 'recall': 0.9173553719008265}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.83      1.00      0.91        10\n",
            "           3       0.75      0.75      0.75        12\n",
            "           4       1.00      0.93      0.96        14\n",
            "           5       0.88      0.88      0.88         8\n",
            "           6       0.86      1.00      0.92        12\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       1.00      1.00      1.00         5\n",
            "          13       0.80      0.80      0.80         5\n",
            "          16       0.92      0.92      0.92        12\n",
            "          17       1.00      1.00      1.00        14\n",
            "          24       1.00      0.75      0.86         4\n",
            "\n",
            "    accuracy                           0.92       121\n",
            "   macro avg       0.92      0.90      0.91       121\n",
            "weighted avg       0.92      0.92      0.92       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.859504132231405, 'f1': 0.8642423746565892, 'precision': 0.8860255447032307, 'recall': 0.859504132231405}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       0.60      0.90      0.72        10\n",
            "           3       0.67      0.83      0.74        12\n",
            "           4       1.00      0.93      0.96        14\n",
            "           5       1.00      0.88      0.93         8\n",
            "           6       0.91      0.83      0.87        12\n",
            "           7       1.00      0.85      0.92        13\n",
            "          12       0.83      1.00      0.91         5\n",
            "          13       1.00      0.60      0.75         5\n",
            "          16       0.83      0.83      0.83        12\n",
            "          17       0.87      0.93      0.90        14\n",
            "          24       1.00      0.75      0.86         4\n",
            "\n",
            "    accuracy                           0.86       121\n",
            "   macro avg       0.89      0.85      0.86       121\n",
            "weighted avg       0.89      0.86      0.86       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.9173553719008265, 'f1': 0.91690073188721, 'precision': 0.9205147469610281, 'recall': 0.9173553719008265}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.85      0.92      0.88        12\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       0.82      0.75      0.78        12\n",
            "           4       1.00      1.00      1.00        14\n",
            "           5       0.88      0.88      0.88         8\n",
            "           6       0.92      1.00      0.96        12\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       0.83      1.00      0.91         5\n",
            "          13       0.83      1.00      0.91         5\n",
            "          16       1.00      0.83      0.91        12\n",
            "          17       0.86      0.86      0.86        14\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.92       121\n",
            "   macro avg       0.92      0.93      0.92       121\n",
            "weighted avg       0.92      0.92      0.92       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.7933884297520661, 'f1': 0.7896776548734459, 'precision': 0.8207464972887281, 'recall': 0.7933884297520661}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       0.73      0.80      0.76        10\n",
            "           3       0.56      0.75      0.64        12\n",
            "           4       0.82      1.00      0.90        14\n",
            "           5       1.00      0.62      0.77         8\n",
            "           6       1.00      0.75      0.86        12\n",
            "           7       0.85      0.85      0.85        13\n",
            "          12       0.75      0.60      0.67         5\n",
            "          13       0.60      0.75      0.67         4\n",
            "          16       0.78      0.64      0.70        11\n",
            "          17       0.74      0.93      0.82        15\n",
            "          24       1.00      0.25      0.40         4\n",
            "\n",
            "    accuracy                           0.79       121\n",
            "   macro avg       0.82      0.74      0.75       121\n",
            "weighted avg       0.82      0.79      0.79       121\n",
            "\n",
            "Average validation scores: {'accuracy': 0.8952445468093753, 'f1': 0.8949748054113925, 'precision': 0.9068304162636804, 'recall': 0.8952445468093753}\n",
            "Test set scores: {'accuracy': 0.8963531669865643, 'f1': 0.8978180526111061, 'precision': 0.9041477060445021, 'recall': 0.8963531669865643}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        36\n",
            "           2       0.98      0.84      0.91        51\n",
            "           3       0.74      0.88      0.80        51\n",
            "           4       0.95      0.95      0.95        65\n",
            "           5       0.82      0.85      0.84        27\n",
            "           6       1.00      0.94      0.97        52\n",
            "           7       0.95      0.98      0.97        61\n",
            "          12       0.95      0.76      0.84        25\n",
            "          13       0.78      0.88      0.82        16\n",
            "          16       0.75      0.85      0.80        47\n",
            "          17       0.89      0.85      0.87        73\n",
            "          24       1.00      0.82      0.90        17\n",
            "\n",
            "    accuracy                           0.90       521\n",
            "   macro avg       0.90      0.88      0.89       521\n",
            "weighted avg       0.90      0.90      0.90       521\n",
            "\n",
            "Evaluating model: Naive Bayes for subject 8\n",
            "Fold scores: {'accuracy': 0.8852459016393442, 'f1': 0.8879094525842096, 'precision': 0.8972332312496246, 'recall': 0.8852459016393442}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.85      0.92        13\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       0.69      0.75      0.72        12\n",
            "           4       0.93      0.93      0.93        15\n",
            "           5       1.00      1.00      1.00         9\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       0.93      1.00      0.96        13\n",
            "          12       1.00      0.80      0.89         5\n",
            "          13       1.00      0.75      0.86         4\n",
            "          16       0.75      0.82      0.78        11\n",
            "          17       0.72      0.87      0.79        15\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.89       122\n",
            "   macro avg       0.92      0.88      0.90       122\n",
            "weighted avg       0.90      0.89      0.89       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9180327868852459, 'f1': 0.9216599811654742, 'precision': 0.9381227900996464, 'recall': 0.9180327868852459}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.77      0.87        13\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       1.00      0.91      0.95        11\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       1.00      1.00      1.00         9\n",
            "           6       1.00      0.82      0.90        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      1.00      1.00         5\n",
            "          13       1.00      1.00      1.00         4\n",
            "          16       0.65      1.00      0.79        11\n",
            "          17       0.87      0.87      0.87        15\n",
            "          24       0.67      0.80      0.73         5\n",
            "\n",
            "    accuracy                           0.92       122\n",
            "   macro avg       0.93      0.92      0.92       122\n",
            "weighted avg       0.94      0.92      0.92       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9180327868852459, 'f1': 0.9201360939769239, 'precision': 0.9375487900078064, 'recall': 0.9180327868852459}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.77      0.87        13\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       0.64      0.82      0.72        11\n",
            "           4       1.00      0.87      0.93        15\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        14\n",
            "          12       1.00      1.00      1.00         5\n",
            "          13       1.00      0.60      0.75         5\n",
            "          16       0.79      1.00      0.88        11\n",
            "          17       1.00      1.00      1.00        15\n",
            "          24       0.67      1.00      0.80         4\n",
            "\n",
            "    accuracy                           0.92       122\n",
            "   macro avg       0.92      0.91      0.91       122\n",
            "weighted avg       0.94      0.92      0.92       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9504132231404959, 'f1': 0.9493800486254673, 'precision': 0.9547750229568412, 'recall': 0.9504132231404959}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       0.89      0.73      0.80        11\n",
            "           4       1.00      1.00      1.00        15\n",
            "           5       1.00      0.88      0.93         8\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       0.83      1.00      0.91         5\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       0.92      1.00      0.96        11\n",
            "          17       0.83      1.00      0.91        15\n",
            "          24       1.00      0.75      0.86         4\n",
            "\n",
            "    accuracy                           0.95       121\n",
            "   macro avg       0.96      0.94      0.94       121\n",
            "weighted avg       0.95      0.95      0.95       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.8925619834710744, 'f1': 0.8978520390285096, 'precision': 0.9200095359186268, 'recall': 0.8925619834710744}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      0.70      0.82        10\n",
            "           3       0.60      0.82      0.69        11\n",
            "           4       1.00      1.00      1.00        15\n",
            "           5       1.00      0.88      0.93         8\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.80      0.89         5\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       0.62      0.91      0.74        11\n",
            "          17       0.92      0.80      0.86        15\n",
            "          24       1.00      0.75      0.86         4\n",
            "\n",
            "    accuracy                           0.89       121\n",
            "   macro avg       0.93      0.87      0.89       121\n",
            "weighted avg       0.92      0.89      0.90       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.8925619834710744, 'f1': 0.8925822397370022, 'precision': 0.9170586988768807, 'recall': 0.8925619834710744}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       1.00      0.70      0.82        10\n",
            "           3       0.61      0.92      0.73        12\n",
            "           4       1.00      0.93      0.96        14\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       0.92      1.00      0.96        12\n",
            "           7       1.00      0.85      0.92        13\n",
            "          12       0.67      0.80      0.73         5\n",
            "          13       1.00      0.40      0.57         5\n",
            "          16       0.85      0.92      0.88        12\n",
            "          17       0.93      1.00      0.97        14\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.89       121\n",
            "   macro avg       0.92      0.87      0.87       121\n",
            "weighted avg       0.92      0.89      0.89       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.9338842975206612, 'f1': 0.9349625694895942, 'precision': 0.9415441955548909, 'recall': 0.9338842975206612}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       0.77      0.83      0.80        12\n",
            "           4       1.00      1.00      1.00        14\n",
            "           5       1.00      0.88      0.93         8\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      0.85      0.92        13\n",
            "          12       0.83      1.00      0.91         5\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       1.00      0.92      0.96        12\n",
            "          17       0.82      1.00      0.90        14\n",
            "          24       0.75      0.75      0.75         4\n",
            "\n",
            "    accuracy                           0.93       121\n",
            "   macro avg       0.93      0.93      0.93       121\n",
            "weighted avg       0.94      0.93      0.93       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.8677685950413223, 'f1': 0.8733452219545123, 'precision': 0.9026494895478854, 'recall': 0.8677685950413223}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       1.00      0.80      0.89        10\n",
            "           3       0.61      0.92      0.73        12\n",
            "           4       1.00      0.79      0.88        14\n",
            "           5       1.00      0.88      0.93         8\n",
            "           6       1.00      0.83      0.91        12\n",
            "           7       1.00      0.85      0.92        13\n",
            "          12       1.00      1.00      1.00         5\n",
            "          13       0.75      0.60      0.67         5\n",
            "          16       0.71      1.00      0.83        12\n",
            "          17       0.93      0.93      0.93        14\n",
            "          24       0.67      1.00      0.80         4\n",
            "\n",
            "    accuracy                           0.87       121\n",
            "   macro avg       0.89      0.87      0.87       121\n",
            "weighted avg       0.90      0.87      0.87       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.9586776859504132, 'f1': 0.9590541138321836, 'precision': 0.9621212121212122, 'recall': 0.9586776859504132}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       0.92      0.92      0.92        12\n",
            "           4       1.00      0.93      0.96        14\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       0.83      1.00      0.91         5\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       0.92      0.92      0.92        12\n",
            "          17       0.88      1.00      0.93        14\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.96       121\n",
            "   macro avg       0.96      0.96      0.96       121\n",
            "weighted avg       0.96      0.96      0.96       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.859504132231405, 'f1': 0.866953579985333, 'precision': 0.8931696645600389, 'recall': 0.859504132231405}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       0.62      0.83      0.71        12\n",
            "           4       1.00      1.00      1.00        14\n",
            "           5       1.00      0.62      0.77         8\n",
            "           6       1.00      0.83      0.91        12\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.75      0.60      0.67         5\n",
            "          13       0.75      0.75      0.75         4\n",
            "          16       0.53      0.82      0.64        11\n",
            "          17       0.93      0.93      0.93        15\n",
            "          24       1.00      0.75      0.86         4\n",
            "\n",
            "    accuracy                           0.86       121\n",
            "   macro avg       0.88      0.82      0.84       121\n",
            "weighted avg       0.89      0.86      0.87       121\n",
            "\n",
            "Average validation scores: {'accuracy': 0.9076683376236282, 'f1': 0.9103835340379209, 'precision': 0.9264232630893454, 'recall': 0.9076683376236282}\n",
            "Test set scores: {'accuracy': 0.9136276391554703, 'f1': 0.9168140245786843, 'precision': 0.926710245712165, 'recall': 0.9136276391554703}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      1.00      0.99        36\n",
            "           2       1.00      0.90      0.95        51\n",
            "           3       0.82      0.90      0.86        51\n",
            "           4       1.00      0.91      0.95        65\n",
            "           5       1.00      0.85      0.92        27\n",
            "           6       1.00      0.94      0.97        52\n",
            "           7       1.00      0.97      0.98        61\n",
            "          12       0.77      0.80      0.78        25\n",
            "          13       0.93      0.88      0.90        16\n",
            "          16       0.68      0.94      0.79        47\n",
            "          17       0.92      0.90      0.91        73\n",
            "          24       1.00      0.82      0.90        17\n",
            "\n",
            "    accuracy                           0.91       521\n",
            "   macro avg       0.92      0.90      0.91       521\n",
            "weighted avg       0.93      0.91      0.92       521\n",
            "\n",
            "   subject_id        model  val_accuracy    val_f1  val_precision  val_recall  \\\n",
            "0           6         k-NN      0.874678  0.877429       0.897716    0.874678   \n",
            "1           6          SVM      0.887639  0.888057       0.897549    0.887639   \n",
            "2           6  Naive Bayes      0.855667  0.857201       0.870266    0.855667   \n",
            "3           7         k-NN      0.911803  0.911533       0.920813    0.911803   \n",
            "4           7          SVM      0.912721  0.911967       0.917399    0.912721   \n",
            "5           7  Naive Bayes      0.915507  0.915324       0.922983    0.915507   \n",
            "6           8         k-NN      0.898591  0.897775       0.913862    0.898591   \n",
            "7           8          SVM      0.895245  0.894975       0.906830    0.895245   \n",
            "8           8  Naive Bayes      0.907668  0.910384       0.926423    0.907668   \n",
            "\n",
            "   test_accuracy   test_f1  test_precision  test_recall  \n",
            "0       0.907445  0.908004        0.915435     0.907445  \n",
            "1       0.907445  0.908022        0.911730     0.907445  \n",
            "2       0.875252  0.877718        0.882953     0.875252  \n",
            "3       0.930736  0.930696        0.935284     0.930736  \n",
            "4       0.930736  0.931528        0.937220     0.930736  \n",
            "5       0.911255  0.912291        0.918951     0.911255  \n",
            "6       0.911708  0.912880        0.923235     0.911708  \n",
            "7       0.896353  0.897818        0.904148     0.896353  \n",
            "8       0.913628  0.916814        0.926710     0.913628  \n"
          ]
        }
      ],
      "source": [
        "# Generate features and labels for each subject using PreProcessor and FeatureExtraction\n",
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "file_path =  '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject108.dat'\n",
        "\n",
        "preprocessor.initializeDataFrame(file_path)\n",
        "preprocessor.dataCleaning()\n",
        "preprocessor.applyPreProcessing()\n",
        "\n",
        "subject_id = int(file_path[-5])\n",
        "subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z9Au7TM-9lx"
      },
      "source": [
        "## Evaluating on another Classifier for all subjects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuQMBzDa7DDp",
        "outputId": "9bd6b101-21b9-40e7-e66c-a5de12685ad3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model: Decision Tree for subject 1\n",
            "Fold scores: {'accuracy': 0.9137931034482759, 'f1': 0.9135487027083508, 'precision': 0.9192768199233716, 'recall': 0.9137931034482759}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.86      0.92        14\n",
            "           2       0.83      1.00      0.91        10\n",
            "           3       0.88      0.78      0.82         9\n",
            "           4       0.90      0.82      0.86        11\n",
            "           5       0.91      0.91      0.91        11\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      0.89      0.94         9\n",
            "          12       0.88      0.88      0.88         8\n",
            "          13       0.78      1.00      0.88         7\n",
            "          16       0.92      1.00      0.96        11\n",
            "          17       0.90      0.90      0.90        10\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.91       116\n",
            "   macro avg       0.92      0.92      0.91       116\n",
            "weighted avg       0.92      0.91      0.91       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.8362068965517241, 'f1': 0.836953093002371, 'precision': 0.8581494654770517, 'recall': 0.8362068965517241}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      0.93      0.93        14\n",
            "           2       1.00      0.73      0.84        11\n",
            "           3       0.78      0.78      0.78         9\n",
            "           4       1.00      0.90      0.95        10\n",
            "           5       0.83      0.91      0.87        11\n",
            "           6       1.00      0.73      0.84        11\n",
            "           7       0.73      0.89      0.80         9\n",
            "          12       0.64      0.88      0.74         8\n",
            "          13       0.75      0.86      0.80         7\n",
            "          16       0.80      0.73      0.76        11\n",
            "          17       0.77      1.00      0.87        10\n",
            "          24       1.00      0.60      0.75         5\n",
            "\n",
            "    accuracy                           0.84       116\n",
            "   macro avg       0.85      0.83      0.83       116\n",
            "weighted avg       0.86      0.84      0.84       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.9137931034482759, 'f1': 0.9114887423190509, 'precision': 0.9169792850827333, 'recall': 0.9137931034482759}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      1.00      0.96        13\n",
            "           2       1.00      0.91      0.95        11\n",
            "           3       1.00      1.00      1.00        10\n",
            "           4       0.83      1.00      0.91        10\n",
            "           5       0.85      1.00      0.92        11\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       0.80      0.89      0.84         9\n",
            "          12       0.86      0.75      0.80         8\n",
            "          13       0.80      0.57      0.67         7\n",
            "          16       0.91      0.91      0.91        11\n",
            "          17       1.00      0.90      0.95        10\n",
            "          24       1.00      0.80      0.89         5\n",
            "\n",
            "    accuracy                           0.91       116\n",
            "   macro avg       0.91      0.89      0.90       116\n",
            "weighted avg       0.92      0.91      0.91       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.896551724137931, 'f1': 0.8944684403829831, 'precision': 0.8985258993879685, 'recall': 0.896551724137931}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      1.00      0.96        13\n",
            "           2       1.00      1.00      1.00        11\n",
            "           3       0.91      1.00      0.95        10\n",
            "           4       0.90      0.90      0.90        10\n",
            "           5       0.90      0.82      0.86        11\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00         9\n",
            "          12       0.60      0.75      0.67         8\n",
            "          13       0.60      0.43      0.50         7\n",
            "          16       0.83      0.91      0.87        11\n",
            "          17       1.00      0.80      0.89        10\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.90       116\n",
            "   macro avg       0.89      0.88      0.88       116\n",
            "weighted avg       0.90      0.90      0.89       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.8620689655172413, 'f1': 0.8622622383338775, 'precision': 0.8719211822660098, 'recall': 0.8620689655172413}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        13\n",
            "           2       0.83      0.91      0.87        11\n",
            "           3       0.71      0.50      0.59        10\n",
            "           4       1.00      0.90      0.95        10\n",
            "           5       0.90      0.90      0.90        10\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00         9\n",
            "          12       0.67      0.75      0.71         8\n",
            "          13       0.86      0.86      0.86         7\n",
            "          16       0.83      0.91      0.87        11\n",
            "          17       1.00      0.80      0.89        10\n",
            "          24       0.56      0.83      0.67         6\n",
            "\n",
            "    accuracy                           0.86       116\n",
            "   macro avg       0.86      0.86      0.85       116\n",
            "weighted avg       0.87      0.86      0.86       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.9224137931034483, 'f1': 0.9193803314709096, 'precision': 0.9304358237547893, 'recall': 0.9224137931034483}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       0.92      1.00      0.96        11\n",
            "           3       0.90      0.90      0.90        10\n",
            "           4       0.83      1.00      0.91        10\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      0.78      0.88         9\n",
            "          12       0.78      0.88      0.82         8\n",
            "          13       0.88      1.00      0.93         7\n",
            "          16       0.83      0.91      0.87        11\n",
            "          17       1.00      0.90      0.95        10\n",
            "          24       1.00      0.50      0.67         6\n",
            "\n",
            "    accuracy                           0.92       116\n",
            "   macro avg       0.93      0.91      0.91       116\n",
            "weighted avg       0.93      0.92      0.92       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.8793103448275862, 'f1': 0.8803896496727712, 'precision': 0.8950044208664898, 'recall': 0.8793103448275862}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.86      0.89        14\n",
            "           2       0.75      0.90      0.82        10\n",
            "           3       1.00      0.80      0.89        10\n",
            "           4       1.00      1.00      1.00        10\n",
            "           5       1.00      0.90      0.95        10\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       0.90      0.90      0.90        10\n",
            "          12       0.69      1.00      0.82         9\n",
            "          13       0.75      0.50      0.60         6\n",
            "          16       1.00      0.82      0.90        11\n",
            "          17       0.67      0.80      0.73        10\n",
            "          24       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.88       116\n",
            "   macro avg       0.89      0.87      0.87       116\n",
            "weighted avg       0.90      0.88      0.88       116\n",
            "\n",
            "Fold scores: {'accuracy': 0.9043478260869565, 'f1': 0.9049632606665854, 'precision': 0.919696342305038, 'recall': 0.9043478260869565}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      0.93      0.93        14\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       1.00      1.00      1.00        10\n",
            "           4       1.00      0.80      0.89        10\n",
            "           5       0.71      1.00      0.83        10\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      0.80      0.89        10\n",
            "          12       0.78      0.88      0.82         8\n",
            "          13       0.75      1.00      0.86         6\n",
            "          16       0.90      0.82      0.86        11\n",
            "          17       0.90      0.90      0.90        10\n",
            "          24       1.00      0.67      0.80         6\n",
            "\n",
            "    accuracy                           0.90       115\n",
            "   macro avg       0.91      0.90      0.90       115\n",
            "weighted avg       0.92      0.90      0.90       115\n",
            "\n",
            "Fold scores: {'accuracy': 0.8956521739130435, 'f1': 0.8958994797642522, 'precision': 0.9019678147939016, 'recall': 0.8956521739130435}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      1.00      0.97        14\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       1.00      1.00      1.00        10\n",
            "           4       0.82      0.90      0.86        10\n",
            "           5       1.00      0.90      0.95        10\n",
            "           6       0.91      1.00      0.95        10\n",
            "           7       0.88      0.78      0.82         9\n",
            "          12       0.78      0.88      0.82         8\n",
            "          13       0.57      0.67      0.62         6\n",
            "          16       0.89      0.73      0.80        11\n",
            "          17       0.92      1.00      0.96        11\n",
            "          24       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.90       115\n",
            "   macro avg       0.89      0.88      0.88       115\n",
            "weighted avg       0.90      0.90      0.90       115\n",
            "\n",
            "Fold scores: {'accuracy': 0.8869565217391304, 'f1': 0.8867306606437042, 'precision': 0.8906982872200265, 'recall': 0.8869565217391304}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      0.93      0.93        14\n",
            "           2       0.90      0.90      0.90        10\n",
            "           3       0.90      0.90      0.90        10\n",
            "           4       0.90      0.90      0.90        10\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       0.82      0.90      0.86        10\n",
            "           7       0.89      0.89      0.89         9\n",
            "          12       1.00      0.75      0.86         8\n",
            "          13       0.71      0.71      0.71         7\n",
            "          16       0.90      0.82      0.86        11\n",
            "          17       0.82      0.90      0.86        10\n",
            "          24       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.89       115\n",
            "   macro avg       0.88      0.88      0.88       115\n",
            "weighted avg       0.89      0.89      0.89       115\n",
            "\n",
            "Average validation scores: {'accuracy': 0.8911094452773612, 'f1': 0.8906084598964856, 'precision': 0.9002655341077379, 'recall': 0.8911094452773612}\n",
            "Test set scores: {'accuracy': 0.907258064516129, 'f1': 0.9067640328704271, 'precision': 0.9093724326113272, 'recall': 0.907258064516129}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.86      0.98      0.92        45\n",
            "           2       0.94      0.96      0.95        50\n",
            "           3       0.93      0.89      0.91        46\n",
            "           4       0.88      0.91      0.90        47\n",
            "           5       0.87      0.94      0.91        36\n",
            "           6       0.94      1.00      0.97        50\n",
            "           7       0.92      0.81      0.86        42\n",
            "          12       0.77      0.87      0.82        23\n",
            "          13       0.88      0.77      0.82        30\n",
            "          16       0.88      0.86      0.87        42\n",
            "          17       0.96      0.87      0.91        55\n",
            "          24       1.00      0.97      0.98        30\n",
            "\n",
            "    accuracy                           0.91       496\n",
            "   macro avg       0.90      0.90      0.90       496\n",
            "weighted avg       0.91      0.91      0.91       496\n",
            "\n",
            "   subject_id          model  val_accuracy    val_f1  val_precision  \\\n",
            "0           1  Decision Tree      0.891109  0.890608       0.900266   \n",
            "\n",
            "   val_recall  test_accuracy   test_f1  test_precision  test_recall  \n",
            "0    0.891109       0.907258  0.906764        0.909372     0.907258  \n"
          ]
        }
      ],
      "source": [
        "# also evaluate with DecisionTreeClassifier\n",
        "\n",
        "# Initialize the evaluator\n",
        "evaluator = ModelEval(cv=5, n_splits=10)\n",
        "\n",
        "evaluator.add_model(DecisionTreeClassifier(), \"Decision Tree\", param_grid={\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'max_features': [None, 'sqrt', 'log2']\n",
        "})\n",
        "\n",
        "# Add metrics\n",
        "evaluator.add_metric(accuracy_score, \"Accuracy\")\n",
        "evaluator.add_metric(f1_score, \"F1 Score\")\n",
        "evaluator.add_metric(precision_score, \"Precision\")\n",
        "evaluator.add_metric(recall_score, \"Recall\")\n",
        "\n",
        "# Generate features and labels for each subject using PreProcessor and FeatureExtraction\n",
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "# file_path =  '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject101.dat'\n",
        "\n",
        "# preprocessor.initializeDataFrame(file_path)\n",
        "# preprocessor.dataCleaning()\n",
        "# preprocessor.applyPreProcessing()\n",
        "\n",
        "# subject_id = int(file_path[-5])\n",
        "# subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "# feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "# features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0lqloH0-uC1",
        "outputId": "4fc89d02-ada2-4cdb-abe9-0b50bdcdfa83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame still contains some NAN values\n",
            "Evaluating model: Decision Tree for subject 2\n",
            "Fold scores: {'accuracy': 0.9016393442622951, 'f1': 0.9009500128049666, 'precision': 0.9057567205108189, 'recall': 0.9016393442622951}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.70      0.70      0.70        10\n",
            "           3       0.92      1.00      0.96        12\n",
            "           4       0.93      0.81      0.87        16\n",
            "           5       1.00      1.00      1.00         4\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       0.87      1.00      0.93        13\n",
            "          12       0.78      1.00      0.88         7\n",
            "          13       0.86      0.75      0.80         8\n",
            "          16       1.00      1.00      1.00        10\n",
            "          17       0.85      0.85      0.85        13\n",
            "          24       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.90       122\n",
            "   macro avg       0.91      0.90      0.90       122\n",
            "weighted avg       0.91      0.90      0.90       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8442622950819673, 'f1': 0.8420737584338607, 'precision': 0.8439686719580644, 'recall': 0.8442622950819673}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      1.00      0.96        12\n",
            "           2       0.78      0.70      0.74        10\n",
            "           3       0.83      0.83      0.83        12\n",
            "           4       0.76      0.87      0.81        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       0.92      1.00      0.96        11\n",
            "           7       0.92      0.92      0.92        13\n",
            "          12       0.57      0.57      0.57         7\n",
            "          13       0.83      0.62      0.71         8\n",
            "          16       0.89      0.80      0.84        10\n",
            "          17       0.85      0.85      0.85        13\n",
            "          24       0.83      0.83      0.83         6\n",
            "\n",
            "    accuracy                           0.84       122\n",
            "   macro avg       0.84      0.83      0.84       122\n",
            "weighted avg       0.84      0.84      0.84       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9180327868852459, 'f1': 0.9166094063424668, 'precision': 0.9193217643012725, 'recall': 0.9180327868852459}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.80      0.80      0.80        10\n",
            "           3       0.85      0.92      0.88        12\n",
            "           4       0.94      1.00      0.97        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      0.93      0.96        14\n",
            "          12       0.75      0.86      0.80         7\n",
            "          13       0.80      0.57      0.67         7\n",
            "          16       0.91      1.00      0.95        10\n",
            "          17       0.92      0.92      0.92        13\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.92       122\n",
            "   macro avg       0.91      0.91      0.91       122\n",
            "weighted avg       0.92      0.92      0.92       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9262295081967213, 'f1': 0.9300146760760458, 'precision': 0.9419398907103825, 'recall': 0.9262295081967213}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.80      0.80      0.80        10\n",
            "           3       1.00      1.00      1.00        12\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      0.92      0.96        12\n",
            "           7       1.00      1.00      1.00        14\n",
            "          12       0.58      1.00      0.74         7\n",
            "          13       0.83      0.71      0.77         7\n",
            "          16       1.00      1.00      1.00        10\n",
            "          17       1.00      0.92      0.96        13\n",
            "          24       0.80      0.80      0.80         5\n",
            "\n",
            "    accuracy                           0.93       122\n",
            "   macro avg       0.92      0.92      0.91       122\n",
            "weighted avg       0.94      0.93      0.93       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8852459016393442, 'f1': 0.8811785161158353, 'precision': 0.8866375427850838, 'recall': 0.8852459016393442}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.75      0.90      0.82        10\n",
            "           3       0.92      1.00      0.96        12\n",
            "           4       0.87      0.87      0.87        15\n",
            "           5       1.00      0.80      0.89         5\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       0.88      1.00      0.93        14\n",
            "          12       0.60      0.43      0.50         7\n",
            "          13       0.71      0.71      0.71         7\n",
            "          16       1.00      0.70      0.82        10\n",
            "          17       0.86      0.92      0.89        13\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.89       122\n",
            "   macro avg       0.88      0.86      0.87       122\n",
            "weighted avg       0.89      0.89      0.88       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8852459016393442, 'f1': 0.8815515280754987, 'precision': 0.8850432923178825, 'recall': 0.8852459016393442}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      1.00      0.96        12\n",
            "           2       0.82      0.90      0.86        10\n",
            "           3       0.91      0.83      0.87        12\n",
            "           4       0.94      1.00      0.97        15\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       0.92      0.92      0.92        12\n",
            "           7       1.00      0.93      0.96        14\n",
            "          12       0.78      0.88      0.82         8\n",
            "          13       0.75      0.43      0.55         7\n",
            "          16       0.73      0.80      0.76        10\n",
            "          17       0.83      0.83      0.83        12\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.89       122\n",
            "   macro avg       0.88      0.88      0.87       122\n",
            "weighted avg       0.89      0.89      0.88       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8852459016393442, 'f1': 0.8860631948486921, 'precision': 0.8941849964029327, 'recall': 0.8852459016393442}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       0.89      0.80      0.84        10\n",
            "           3       0.79      1.00      0.88        11\n",
            "           4       0.94      1.00      0.97        16\n",
            "           5       0.80      0.80      0.80         5\n",
            "           6       1.00      0.92      0.96        12\n",
            "           7       0.92      0.79      0.85        14\n",
            "          12       0.75      0.75      0.75         8\n",
            "          13       0.67      0.86      0.75         7\n",
            "          16       1.00      1.00      1.00        10\n",
            "          17       0.92      0.92      0.92        12\n",
            "          24       0.80      0.80      0.80         5\n",
            "\n",
            "    accuracy                           0.89       122\n",
            "   macro avg       0.87      0.87      0.87       122\n",
            "weighted avg       0.89      0.89      0.89       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8852459016393442, 'f1': 0.88119697529965, 'precision': 0.8876008621187021, 'recall': 0.8852459016393442}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      1.00      0.96        12\n",
            "           2       0.89      0.80      0.84        10\n",
            "           3       1.00      0.91      0.95        11\n",
            "           4       0.88      0.94      0.91        16\n",
            "           5       1.00      0.60      0.75         5\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       0.88      1.00      0.93        14\n",
            "          12       0.70      0.88      0.78         8\n",
            "          13       0.60      0.43      0.50         7\n",
            "          16       0.90      0.90      0.90        10\n",
            "          17       0.85      0.92      0.88        12\n",
            "          24       1.00      0.80      0.89         5\n",
            "\n",
            "    accuracy                           0.89       122\n",
            "   macro avg       0.88      0.85      0.86       122\n",
            "weighted avg       0.89      0.89      0.88       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9180327868852459, 'f1': 0.9131877736234939, 'precision': 0.9305590584279109, 'recall': 0.9180327868852459}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      1.00      0.96        12\n",
            "           2       1.00      0.50      0.67        10\n",
            "           3       0.85      1.00      0.92        11\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       0.83      1.00      0.91         5\n",
            "           6       0.92      1.00      0.96        12\n",
            "           7       1.00      0.93      0.96        14\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       0.90      1.00      0.95         9\n",
            "          17       0.73      0.92      0.81        12\n",
            "          24       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.92       122\n",
            "   macro avg       0.93      0.91      0.91       122\n",
            "weighted avg       0.93      0.92      0.91       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8677685950413223, 'f1': 0.8647374987676398, 'precision': 0.8728480723619274, 'recall': 0.8677685950413223}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.83      0.83      0.83        12\n",
            "           2       0.70      0.70      0.70        10\n",
            "           3       1.00      0.82      0.90        11\n",
            "           4       0.88      0.94      0.91        16\n",
            "           5       1.00      1.00      1.00         4\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       0.92      0.92      0.92        13\n",
            "          12       0.80      0.50      0.62         8\n",
            "          13       0.70      1.00      0.82         7\n",
            "          16       0.82      1.00      0.90         9\n",
            "          17       0.83      0.77      0.80        13\n",
            "          24       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.87       121\n",
            "   macro avg       0.87      0.87      0.87       121\n",
            "weighted avg       0.87      0.87      0.86       121\n",
            "\n",
            "Average validation scores: {'accuracy': 0.8916948922910175, 'f1': 0.8897563340388152, 'precision': 0.8967860871894977, 'recall': 0.8916948922910175}\n",
            "Test set scores: {'accuracy': 0.9158699808795411, 'f1': 0.9157925928848483, 'precision': 0.9193603082830102, 'recall': 0.9158699808795411}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      1.00      0.96        36\n",
            "           2       0.93      0.90      0.91        48\n",
            "           3       0.93      0.98      0.95        53\n",
            "           4       0.98      0.98      0.98        61\n",
            "           5       0.87      1.00      0.93        13\n",
            "           6       0.98      1.00      0.99        48\n",
            "           7       0.98      0.90      0.94        60\n",
            "          12       0.91      0.76      0.83        38\n",
            "          13       0.73      0.86      0.79        28\n",
            "          16       0.81      0.87      0.84        39\n",
            "          17       0.93      0.83      0.88        66\n",
            "          24       0.86      0.94      0.90        33\n",
            "\n",
            "    accuracy                           0.92       523\n",
            "   macro avg       0.90      0.92      0.91       523\n",
            "weighted avg       0.92      0.92      0.92       523\n",
            "\n",
            "   subject_id          model  val_accuracy    val_f1  val_precision  \\\n",
            "0           1  Decision Tree      0.891109  0.890608       0.900266   \n",
            "1           2  Decision Tree      0.891695  0.889756       0.896786   \n",
            "\n",
            "   val_recall  test_accuracy   test_f1  test_precision  test_recall  \n",
            "0    0.891109       0.907258  0.906764        0.909372     0.907258  \n",
            "1    0.891695       0.915870  0.915793        0.919360     0.915870  \n"
          ]
        }
      ],
      "source": [
        "# Generate features and labels for each subject using PreProcessor and FeatureExtraction\n",
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "file_path =  '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject102.dat'\n",
        "\n",
        "preprocessor.initializeDataFrame(file_path)\n",
        "preprocessor.dataCleaning()\n",
        "preprocessor.applyPreProcessing()\n",
        "\n",
        "subject_id = int(file_path[-5])\n",
        "subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezFeYGHSACx3",
        "outputId": "ed771aaa-4f8c-42bf-d502-210d81f28228"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame still contains some NAN values\n",
            "Evaluating model: Decision Tree for subject 3\n",
            "Fold scores: {'accuracy': 0.9382716049382716, 'f1': 0.9371788221461425, 'precision': 0.9490740740740741, 'recall': 0.9382716049382716}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        14\n",
            "           3       0.75      1.00      0.86         9\n",
            "           4       1.00      1.00      1.00        15\n",
            "          12       1.00      0.75      0.86         4\n",
            "          13       0.88      1.00      0.93         7\n",
            "          16       1.00      0.70      0.82        10\n",
            "          17       0.92      0.92      0.92        13\n",
            "\n",
            "    accuracy                           0.94        81\n",
            "   macro avg       0.94      0.92      0.92        81\n",
            "weighted avg       0.95      0.94      0.94        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.9382716049382716, 'f1': 0.9370117525202292, 'precision': 0.9429226123670567, 'recall': 0.9382716049382716}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.80      0.89        10\n",
            "           2       0.93      1.00      0.97        14\n",
            "           3       0.82      1.00      0.90         9\n",
            "           4       1.00      1.00      1.00        15\n",
            "          12       1.00      1.00      1.00         4\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.88      0.78      0.82         9\n",
            "          17       0.93      1.00      0.96        13\n",
            "\n",
            "    accuracy                           0.94        81\n",
            "   macro avg       0.94      0.93      0.93        81\n",
            "weighted avg       0.94      0.94      0.94        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.9012345679012346, 'f1': 0.9033914874457324, 'precision': 0.9186541339319116, 'recall': 0.9012345679012346}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.90      0.95        10\n",
            "           2       0.81      1.00      0.90        13\n",
            "           3       0.82      0.90      0.86        10\n",
            "           4       1.00      0.93      0.97        15\n",
            "          12       0.67      1.00      0.80         4\n",
            "          13       0.86      0.86      0.86         7\n",
            "          16       1.00      0.78      0.88         9\n",
            "          17       1.00      0.85      0.92        13\n",
            "\n",
            "    accuracy                           0.90        81\n",
            "   macro avg       0.89      0.90      0.89        81\n",
            "weighted avg       0.92      0.90      0.90        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.8148148148148148, 'f1': 0.8215685425133883, 'precision': 0.8351165980795611, 'recall': 0.8148148148148148}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.90      0.90      0.90        10\n",
            "           2       0.92      0.92      0.92        13\n",
            "           3       0.80      0.89      0.84         9\n",
            "           4       0.92      0.73      0.81        15\n",
            "          12       0.33      0.50      0.40         4\n",
            "          13       0.56      0.62      0.59         8\n",
            "          16       0.89      0.89      0.89         9\n",
            "          17       0.92      0.85      0.88        13\n",
            "\n",
            "    accuracy                           0.81        81\n",
            "   macro avg       0.78      0.79      0.78        81\n",
            "weighted avg       0.84      0.81      0.82        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.9506172839506173, 'f1': 0.9506335917971329, 'precision': 0.9562663673774784, 'recall': 0.9506172839506173}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      1.00      0.95        10\n",
            "           2       1.00      0.92      0.96        13\n",
            "           3       0.90      1.00      0.95         9\n",
            "           4       1.00      0.93      0.97        15\n",
            "          12       0.83      1.00      0.91         5\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.90      1.00      0.95         9\n",
            "          17       1.00      0.85      0.92        13\n",
            "\n",
            "    accuracy                           0.95        81\n",
            "   macro avg       0.94      0.96      0.95        81\n",
            "weighted avg       0.96      0.95      0.95        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.8765432098765432, 'f1': 0.8751854729632508, 'precision': 0.8804713804713804, 'recall': 0.8765432098765432}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.75      0.90      0.82        10\n",
            "           2       1.00      0.92      0.96        13\n",
            "           3       0.82      1.00      0.90         9\n",
            "           4       1.00      1.00      1.00        15\n",
            "          12       0.80      0.80      0.80         5\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.89      0.89      0.89         9\n",
            "          17       0.73      0.62      0.67        13\n",
            "\n",
            "    accuracy                           0.88        81\n",
            "   macro avg       0.87      0.87      0.87        81\n",
            "weighted avg       0.88      0.88      0.88        81\n",
            "\n",
            "Fold scores: {'accuracy': 0.9, 'f1': 0.8948395097286227, 'precision': 0.9141165258352759, 'recall': 0.9}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.80      0.89        10\n",
            "           2       1.00      0.92      0.96        13\n",
            "           3       0.73      0.89      0.80         9\n",
            "           4       0.94      1.00      0.97        15\n",
            "          12       1.00      0.40      0.57         5\n",
            "          13       0.78      1.00      0.88         7\n",
            "          16       0.89      0.89      0.89         9\n",
            "          17       0.92      1.00      0.96        12\n",
            "\n",
            "    accuracy                           0.90        80\n",
            "   macro avg       0.91      0.86      0.86        80\n",
            "weighted avg       0.91      0.90      0.89        80\n",
            "\n",
            "Fold scores: {'accuracy': 0.875, 'f1': 0.8741836567285484, 'precision': 0.8767762445887446, 'recall': 0.875}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      1.00      0.95        10\n",
            "           2       1.00      0.92      0.96        13\n",
            "           3       0.88      0.78      0.82         9\n",
            "           4       0.93      0.93      0.93        15\n",
            "          12       0.50      0.50      0.50         4\n",
            "          13       0.83      0.71      0.77         7\n",
            "          16       0.80      0.89      0.84         9\n",
            "          17       0.86      0.92      0.89        13\n",
            "\n",
            "    accuracy                           0.88        80\n",
            "   macro avg       0.84      0.83      0.83        80\n",
            "weighted avg       0.88      0.88      0.87        80\n",
            "\n",
            "Fold scores: {'accuracy': 0.9125, 'f1': 0.9109781429440872, 'precision': 0.9126041666666668, 'recall': 0.9125}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        10\n",
            "           2       0.92      0.92      0.92        13\n",
            "           3       0.88      0.78      0.82         9\n",
            "           4       0.93      0.93      0.93        15\n",
            "          12       0.80      1.00      0.89         4\n",
            "          13       0.83      0.71      0.77         7\n",
            "          16       0.90      1.00      0.95         9\n",
            "          17       0.92      0.92      0.92        13\n",
            "\n",
            "    accuracy                           0.91        80\n",
            "   macro avg       0.90      0.91      0.90        80\n",
            "weighted avg       0.91      0.91      0.91        80\n",
            "\n",
            "Fold scores: {'accuracy': 0.8875, 'f1': 0.8873738776014385, 'precision': 0.8997607376283847, 'recall': 0.8875}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.89      0.89      0.89         9\n",
            "           2       1.00      0.86      0.92        14\n",
            "           3       1.00      0.89      0.94         9\n",
            "           4       0.93      0.87      0.90        15\n",
            "          12       0.67      0.50      0.57         4\n",
            "          13       0.78      1.00      0.88         7\n",
            "          16       1.00      0.89      0.94         9\n",
            "          17       0.76      1.00      0.87        13\n",
            "\n",
            "    accuracy                           0.89        80\n",
            "   macro avg       0.88      0.86      0.86        80\n",
            "weighted avg       0.90      0.89      0.89        80\n",
            "\n",
            "Average validation scores: {'accuracy': 0.8994753086419752, 'f1': 0.8992344856388573, 'precision': 0.9085762841020533, 'recall': 0.8994753086419752}\n",
            "Test set scores: {'accuracy': 0.953757225433526, 'f1': 0.9536107534631489, 'precision': 0.9538198467640538, 'recall': 0.953757225433526}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.98      0.94      0.96        48\n",
            "           2       0.97      1.00      0.98        58\n",
            "           3       0.93      0.96      0.95        45\n",
            "           4       0.98      0.95      0.96        43\n",
            "          12       0.92      0.92      0.92        24\n",
            "          13       0.89      0.86      0.87        28\n",
            "          16       0.93      0.95      0.94        43\n",
            "          17       0.98      0.98      0.98        57\n",
            "\n",
            "    accuracy                           0.95       346\n",
            "   macro avg       0.95      0.94      0.95       346\n",
            "weighted avg       0.95      0.95      0.95       346\n",
            "\n",
            "   subject_id          model  val_accuracy    val_f1  val_precision  \\\n",
            "0           1  Decision Tree      0.891109  0.890608       0.900266   \n",
            "1           2  Decision Tree      0.891695  0.889756       0.896786   \n",
            "2           3  Decision Tree      0.899475  0.899234       0.908576   \n",
            "\n",
            "   val_recall  test_accuracy   test_f1  test_precision  test_recall  \n",
            "0    0.891109       0.907258  0.906764        0.909372     0.907258  \n",
            "1    0.891695       0.915870  0.915793        0.919360     0.915870  \n",
            "2    0.899475       0.953757  0.953611        0.953820     0.953757  \n"
          ]
        }
      ],
      "source": [
        "# Generate features and labels for each subject using PreProcessor and FeatureExtraction\n",
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "file_path =  '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject103.dat'\n",
        "\n",
        "preprocessor.initializeDataFrame(file_path)\n",
        "preprocessor.dataCleaning()\n",
        "preprocessor.applyPreProcessing()\n",
        "\n",
        "subject_id = int(file_path[-5])\n",
        "subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5XYkMy0AXit",
        "outputId": "d84969ae-6e3f-4aaf-e4b0-15261faadbf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame still contains some NAN values\n",
            "Evaluating model: Decision Tree for subject 4\n",
            "Fold scores: {'accuracy': 0.9537037037037037, 'f1': 0.9538062948621172, 'precision': 0.9563385174496285, 'recall': 0.9537037037037037}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      1.00      1.00        12\n",
            "           3       0.91      1.00      0.95        10\n",
            "           4       0.93      1.00      0.96        13\n",
            "           6       0.90      0.82      0.86        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       0.78      0.88      0.82         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       1.00      0.90      0.95        10\n",
            "          17       1.00      0.92      0.96        12\n",
            "\n",
            "    accuracy                           0.95       108\n",
            "   macro avg       0.95      0.95      0.95       108\n",
            "weighted avg       0.96      0.95      0.95       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.897196261682243, 'f1': 0.898302861620084, 'precision': 0.9064712546020957, 'recall': 0.897196261682243}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      0.92      0.96        12\n",
            "           3       0.73      0.80      0.76        10\n",
            "           4       1.00      0.85      0.92        13\n",
            "           6       0.92      1.00      0.96        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       0.73      1.00      0.84         8\n",
            "          13       1.00      0.83      0.91         6\n",
            "          16       0.80      0.80      0.80        10\n",
            "          17       0.82      0.75      0.78        12\n",
            "\n",
            "    accuracy                           0.90       107\n",
            "   macro avg       0.90      0.89      0.89       107\n",
            "weighted avg       0.91      0.90      0.90       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9065420560747663, 'f1': 0.9075711469291314, 'precision': 0.9152202937249666, 'recall': 0.9065420560747663}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       1.00      1.00      1.00        12\n",
            "           3       0.90      0.90      0.90        10\n",
            "           4       0.93      1.00      0.96        13\n",
            "           6       0.71      0.91      0.80        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       1.00      0.71      0.83         7\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.80      0.80      0.80        10\n",
            "          17       0.83      0.83      0.83        12\n",
            "\n",
            "    accuracy                           0.91       107\n",
            "   macro avg       0.92      0.90      0.90       107\n",
            "weighted avg       0.92      0.91      0.91       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9158878504672897, 'f1': 0.9134440983039114, 'precision': 0.9224863921125602, 'recall': 0.9158878504672897}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      1.00      0.96        12\n",
            "           2       0.85      0.92      0.88        12\n",
            "           3       1.00      0.60      0.75        10\n",
            "           4       0.93      1.00      0.96        13\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.75      0.86      0.80         7\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.90      0.90      0.90        10\n",
            "          17       0.85      0.92      0.88        12\n",
            "\n",
            "    accuracy                           0.92       107\n",
            "   macro avg       0.92      0.91      0.91       107\n",
            "weighted avg       0.92      0.92      0.91       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9158878504672897, 'f1': 0.914447604858007, 'precision': 0.9206457094307561, 'recall': 0.9158878504672897}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.91      0.91        11\n",
            "           2       0.80      1.00      0.89        12\n",
            "           3       1.00      0.82      0.90        11\n",
            "           4       1.00      1.00      1.00        14\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.88      1.00      0.93         7\n",
            "          13       0.88      1.00      0.93         7\n",
            "          16       0.88      0.70      0.78        10\n",
            "          17       0.91      0.83      0.87        12\n",
            "\n",
            "    accuracy                           0.92       107\n",
            "   macro avg       0.92      0.92      0.91       107\n",
            "weighted avg       0.92      0.92      0.91       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9158878504672897, 'f1': 0.9146244130627884, 'precision': 0.9172001414992069, 'recall': 0.9158878504672897}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.91      0.95        11\n",
            "           2       0.92      1.00      0.96        12\n",
            "           3       0.92      1.00      0.96        11\n",
            "           4       0.92      0.85      0.88        13\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       0.86      1.00      0.92        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.78      0.70      0.74        10\n",
            "          17       0.83      0.83      0.83        12\n",
            "\n",
            "    accuracy                           0.92       107\n",
            "   macro avg       0.92      0.91      0.92       107\n",
            "weighted avg       0.92      0.92      0.91       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.8598130841121495, 'f1': 0.8598450701254441, 'precision': 0.8725411659991098, 'recall': 0.8598130841121495}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.82      0.90        11\n",
            "           2       0.69      0.92      0.79        12\n",
            "           3       0.91      0.91      0.91        11\n",
            "           4       0.93      1.00      0.96        13\n",
            "           6       0.88      0.70      0.78        10\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       0.83      0.71      0.77         7\n",
            "          16       0.71      0.91      0.80        11\n",
            "          17       0.80      0.67      0.73        12\n",
            "\n",
            "    accuracy                           0.86       107\n",
            "   macro avg       0.87      0.85      0.86       107\n",
            "weighted avg       0.87      0.86      0.86       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9252336448598131, 'f1': 0.9251916867937441, 'precision': 0.9347648716807595, 'recall': 0.9252336448598131}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        11\n",
            "           2       0.92      0.92      0.92        12\n",
            "           3       0.92      1.00      0.96        11\n",
            "           4       0.93      1.00      0.96        13\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.78      0.88      0.82         8\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       1.00      0.82      0.90        11\n",
            "          17       0.79      1.00      0.88        11\n",
            "\n",
            "    accuracy                           0.93       107\n",
            "   macro avg       0.93      0.91      0.92       107\n",
            "weighted avg       0.93      0.93      0.93       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.8598130841121495, 'f1': 0.8569795512037018, 'precision': 0.8621931287819138, 'recall': 0.8598130841121495}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      1.00      0.96        12\n",
            "           2       0.91      0.83      0.87        12\n",
            "           3       0.83      0.91      0.87        11\n",
            "           4       0.87      1.00      0.93        13\n",
            "           6       0.86      0.60      0.71        10\n",
            "           7       0.92      0.85      0.88        13\n",
            "          12       0.88      0.88      0.88         8\n",
            "          13       0.88      1.00      0.93         7\n",
            "          16       0.89      0.80      0.84        10\n",
            "          17       0.67      0.73      0.70        11\n",
            "\n",
            "    accuracy                           0.86       107\n",
            "   macro avg       0.86      0.86      0.86       107\n",
            "weighted avg       0.86      0.86      0.86       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9439252336448598, 'f1': 0.9434001546373495, 'precision': 0.9461932148848036, 'recall': 0.9439252336448598}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      1.00      0.96        12\n",
            "           2       0.85      0.92      0.88        12\n",
            "           3       1.00      0.91      0.95        11\n",
            "           4       0.93      1.00      0.96        13\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       0.86      0.75      0.80         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       1.00      0.90      0.95        10\n",
            "          17       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.94       107\n",
            "   macro avg       0.95      0.94      0.94       107\n",
            "weighted avg       0.95      0.94      0.94       107\n",
            "\n",
            "Average validation scores: {'accuracy': 0.9093890619591555, 'f1': 0.9087612882396279, 'precision': 0.9154054690165803, 'recall': 0.9093890619591555}\n",
            "Test set scores: {'accuracy': 0.9065217391304348, 'f1': 0.9067391512308063, 'precision': 0.9085499079845634, 'recall': 0.9065217391304348}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        37\n",
            "           2       0.85      0.96      0.90        49\n",
            "           3       0.98      0.93      0.96        58\n",
            "           4       0.95      0.88      0.91        80\n",
            "           6       0.89      0.95      0.92        44\n",
            "           7       0.96      0.98      0.97        56\n",
            "          12       0.84      0.81      0.83        32\n",
            "          13       0.65      0.68      0.67        25\n",
            "          16       0.90      0.87      0.89        31\n",
            "          17       0.88      0.88      0.88        48\n",
            "\n",
            "    accuracy                           0.91       460\n",
            "   macro avg       0.89      0.89      0.89       460\n",
            "weighted avg       0.91      0.91      0.91       460\n",
            "\n",
            "   subject_id          model  val_accuracy    val_f1  val_precision  \\\n",
            "0           1  Decision Tree      0.891109  0.890608       0.900266   \n",
            "1           2  Decision Tree      0.891695  0.889756       0.896786   \n",
            "2           3  Decision Tree      0.899475  0.899234       0.908576   \n",
            "3           4  Decision Tree      0.909389  0.908761       0.915405   \n",
            "\n",
            "   val_recall  test_accuracy   test_f1  test_precision  test_recall  \n",
            "0    0.891109       0.907258  0.906764        0.909372     0.907258  \n",
            "1    0.891695       0.915870  0.915793        0.919360     0.915870  \n",
            "2    0.899475       0.953757  0.953611        0.953820     0.953757  \n",
            "3    0.909389       0.906522  0.906739        0.908550     0.906522  \n"
          ]
        }
      ],
      "source": [
        "# Generate features and labels for each subject using PreProcessor and FeatureExtraction\n",
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "file_path =  '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject104.dat'\n",
        "\n",
        "preprocessor.initializeDataFrame(file_path)\n",
        "preprocessor.dataCleaning()\n",
        "preprocessor.applyPreProcessing()\n",
        "\n",
        "subject_id = int(file_path[-5])\n",
        "subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wiHbPTQBWTb",
        "outputId": "be6ba4cc-9c4a-4a5b-d7a2-8f01c3720ce3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame still contains some NAN values\n",
            "Evaluating model: Decision Tree for subject 5\n",
            "Fold scores: {'accuracy': 0.889763779527559, 'f1': 0.8900167299468797, 'precision': 0.89603992901237, 'recall': 0.889763779527559}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.92      1.00      0.96        12\n",
            "           3       0.73      0.80      0.76        10\n",
            "           4       0.94      1.00      0.97        15\n",
            "           5       0.92      1.00      0.96        11\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      0.83      0.91        12\n",
            "          12       0.78      1.00      0.88         7\n",
            "          13       0.67      0.67      0.67         6\n",
            "          16       0.92      0.92      0.92        12\n",
            "          17       0.93      0.81      0.87        16\n",
            "          24       0.33      0.33      0.33         3\n",
            "\n",
            "    accuracy                           0.89       127\n",
            "   macro avg       0.84      0.85      0.84       127\n",
            "weighted avg       0.90      0.89      0.89       127\n",
            "\n",
            "Fold scores: {'accuracy': 0.8818897637795275, 'f1': 0.8794495592211797, 'precision': 0.8823030643896784, 'recall': 0.8818897637795275}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.93      1.00      0.96        13\n",
            "           3       0.64      0.70      0.67        10\n",
            "           4       0.88      0.93      0.90        15\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       0.92      1.00      0.96        11\n",
            "          12       0.71      0.71      0.71         7\n",
            "          13       0.75      0.50      0.60         6\n",
            "          16       0.91      0.83      0.87        12\n",
            "          17       0.88      0.88      0.88        16\n",
            "          24       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.88       127\n",
            "   macro avg       0.88      0.84      0.85       127\n",
            "weighted avg       0.88      0.88      0.88       127\n",
            "\n",
            "Fold scores: {'accuracy': 0.8571428571428571, 'f1': 0.8537820031508672, 'precision': 0.8577940014389595, 'recall': 0.8571428571428571}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.86      1.00      0.92        12\n",
            "           2       0.92      0.92      0.92        12\n",
            "           3       0.83      0.56      0.67         9\n",
            "           4       0.94      1.00      0.97        15\n",
            "           5       0.92      1.00      0.96        11\n",
            "           6       0.91      0.83      0.87        12\n",
            "           7       0.91      0.91      0.91        11\n",
            "          12       1.00      0.83      0.91         6\n",
            "          13       0.57      0.67      0.62         6\n",
            "          16       0.64      0.58      0.61        12\n",
            "          17       0.82      0.88      0.85        16\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.86       126\n",
            "   macro avg       0.86      0.85      0.85       126\n",
            "weighted avg       0.86      0.86      0.85       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.9126984126984127, 'f1': 0.9091023684419474, 'precision': 0.9162797098896538, 'recall': 0.9126984126984127}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.86      0.92      0.89        13\n",
            "           2       0.92      1.00      0.96        12\n",
            "           3       0.89      0.80      0.84        10\n",
            "           4       0.94      1.00      0.97        15\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       0.92      1.00      0.96        12\n",
            "           7       1.00      0.91      0.95        11\n",
            "          12       1.00      0.67      0.80         6\n",
            "          13       0.86      1.00      0.92         6\n",
            "          16       0.88      0.64      0.74        11\n",
            "          17       0.88      1.00      0.94        15\n",
            "          24       0.80      1.00      0.89         4\n",
            "\n",
            "    accuracy                           0.91       126\n",
            "   macro avg       0.91      0.90      0.90       126\n",
            "weighted avg       0.92      0.91      0.91       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.9285714285714286, 'f1': 0.9249805846569494, 'precision': 0.9307566331375854, 'recall': 0.9285714285714286}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       0.92      1.00      0.96        12\n",
            "           3       0.89      0.80      0.84        10\n",
            "           4       0.94      0.94      0.94        16\n",
            "           5       0.92      1.00      0.96        11\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       0.67      0.40      0.50         5\n",
            "          16       0.79      1.00      0.88        11\n",
            "          17       1.00      0.80      0.89        15\n",
            "          24       0.75      1.00      0.86         3\n",
            "\n",
            "    accuracy                           0.93       126\n",
            "   macro avg       0.91      0.91      0.90       126\n",
            "weighted avg       0.93      0.93      0.92       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.9365079365079365, 'f1': 0.9376244313867329, 'precision': 0.946283457561653, 'recall': 0.9365079365079365}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       0.91      0.83      0.87        12\n",
            "           3       1.00      1.00      1.00        10\n",
            "           4       1.00      0.94      0.97        16\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       0.71      1.00      0.83         5\n",
            "          16       0.91      0.83      0.87        12\n",
            "          17       0.79      1.00      0.88        15\n",
            "          24       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.94       126\n",
            "   macro avg       0.94      0.95      0.94       126\n",
            "weighted avg       0.95      0.94      0.94       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.8650793650793651, 'f1': 0.8632142831119815, 'precision': 0.8919753086419754, 'recall': 0.8650793650793651}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        12\n",
            "           2       0.92      1.00      0.96        12\n",
            "           3       0.69      0.90      0.78        10\n",
            "           4       0.94      0.94      0.94        16\n",
            "           5       0.83      0.91      0.87        11\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       0.92      0.92      0.92        12\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       0.44      0.80      0.57         5\n",
            "          16       1.00      0.42      0.59        12\n",
            "          17       0.87      0.87      0.87        15\n",
            "          24       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.87       126\n",
            "   macro avg       0.88      0.87      0.86       126\n",
            "weighted avg       0.89      0.87      0.86       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.9047619047619048, 'f1': 0.9062749856538675, 'precision': 0.9134615384615384, 'recall': 0.9047619047619048}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        12\n",
            "           2       0.92      0.92      0.92        12\n",
            "           3       0.69      0.90      0.78        10\n",
            "           4       0.88      0.88      0.88        16\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       0.92      1.00      0.96        12\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       0.80      0.80      0.80         5\n",
            "          16       1.00      0.92      0.96        12\n",
            "          17       0.92      0.80      0.86        15\n",
            "          24       0.75      1.00      0.86         3\n",
            "\n",
            "    accuracy                           0.90       126\n",
            "   macro avg       0.90      0.91      0.90       126\n",
            "weighted avg       0.91      0.90      0.91       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.9365079365079365, 'f1': 0.9361476342842804, 'precision': 0.9400111054522821, 'recall': 0.9365079365079365}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.83      0.87        12\n",
            "           2       0.92      0.92      0.92        12\n",
            "           3       0.82      0.90      0.86        10\n",
            "           4       0.94      1.00      0.97        16\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.88      1.00      0.93         7\n",
            "          13       0.83      1.00      0.91         5\n",
            "          16       1.00      0.92      0.96        12\n",
            "          17       0.93      0.93      0.93        15\n",
            "          24       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.94       126\n",
            "   macro avg       0.94      0.92      0.92       126\n",
            "weighted avg       0.94      0.94      0.94       126\n",
            "\n",
            "Fold scores: {'accuracy': 0.9126984126984127, 'f1': 0.911688667899848, 'precision': 0.9145970353953548, 'recall': 0.9126984126984127}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.71      0.83      0.77        12\n",
            "           3       0.91      1.00      0.95        10\n",
            "           4       0.94      1.00      0.97        16\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       0.92      1.00      0.96        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.83      0.71      0.77         7\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       0.91      0.83      0.87        12\n",
            "          17       0.85      0.73      0.79        15\n",
            "          24       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.91       126\n",
            "   macro avg       0.92      0.92      0.92       126\n",
            "weighted avg       0.91      0.91      0.91       126\n",
            "\n",
            "Average validation scores: {'accuracy': 0.902562179727534, 'f1': 0.9012281247754533, 'precision': 0.9089501783381051, 'recall': 0.902562179727534}\n",
            "Test set scores: {'accuracy': 0.9316081330868762, 'f1': 0.9321026343280352, 'precision': 0.9335394303916649, 'recall': 0.9316081330868762}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.95      1.00      0.97        35\n",
            "           2       0.98      0.95      0.96        58\n",
            "           3       0.91      0.87      0.89        47\n",
            "           4       0.96      0.95      0.96        57\n",
            "           5       0.98      0.96      0.97        53\n",
            "           6       0.98      0.98      0.98        51\n",
            "           7       1.00      0.98      0.99        57\n",
            "          12       0.78      0.84      0.81        25\n",
            "          13       0.79      0.90      0.84        29\n",
            "          16       0.88      0.84      0.86        44\n",
            "          17       0.90      0.92      0.91        66\n",
            "          24       0.94      0.89      0.92        19\n",
            "\n",
            "    accuracy                           0.93       541\n",
            "   macro avg       0.92      0.92      0.92       541\n",
            "weighted avg       0.93      0.93      0.93       541\n",
            "\n",
            "   subject_id          model  val_accuracy    val_f1  val_precision  \\\n",
            "0           1  Decision Tree      0.891109  0.890608       0.900266   \n",
            "1           2  Decision Tree      0.891695  0.889756       0.896786   \n",
            "2           3  Decision Tree      0.899475  0.899234       0.908576   \n",
            "3           4  Decision Tree      0.909389  0.908761       0.915405   \n",
            "4           5  Decision Tree      0.902562  0.901228       0.908950   \n",
            "\n",
            "   val_recall  test_accuracy   test_f1  test_precision  test_recall  \n",
            "0    0.891109       0.907258  0.906764        0.909372     0.907258  \n",
            "1    0.891695       0.915870  0.915793        0.919360     0.915870  \n",
            "2    0.899475       0.953757  0.953611        0.953820     0.953757  \n",
            "3    0.909389       0.906522  0.906739        0.908550     0.906522  \n",
            "4    0.902562       0.931608  0.932103        0.933539     0.931608  \n"
          ]
        }
      ],
      "source": [
        "# Generate features and labels for each subject using PreProcessor and FeatureExtraction\n",
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "file_path =  '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject105.dat'\n",
        "\n",
        "preprocessor.initializeDataFrame(file_path)\n",
        "preprocessor.dataCleaning()\n",
        "preprocessor.applyPreProcessing()\n",
        "\n",
        "subject_id = int(file_path[-5])\n",
        "subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqI7UsbUGE6O",
        "outputId": "0a5b8b4c-a61a-411b-be1a-7f06e834544d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame still contains some NAN values\n",
            "Evaluating model: Decision Tree for subject 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8620689655172413, 'f1': 0.8666619273433864, 'precision': 0.8860716700473292, 'recall': 0.8620689655172413}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.91      0.91        11\n",
            "           2       0.90      0.90      0.90        10\n",
            "           3       0.65      1.00      0.79        11\n",
            "           4       1.00      1.00      1.00        12\n",
            "           5       1.00      0.78      0.88         9\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       1.00      0.85      0.92        13\n",
            "          12       0.56      0.71      0.63         7\n",
            "          13       0.80      0.80      0.80         5\n",
            "          16       0.78      0.70      0.74        10\n",
            "          17       1.00      0.82      0.90        17\n",
            "\n",
            "    accuracy                           0.86       116\n",
            "   macro avg       0.86      0.85      0.85       116\n",
            "weighted avg       0.89      0.86      0.87       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.9224137931034483, 'f1': 0.9234570027673477, 'precision': 0.9314177202108236, 'recall': 0.9224137931034483}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.82      0.90        11\n",
            "           2       0.91      1.00      0.95        10\n",
            "           3       1.00      0.91      0.95        11\n",
            "           4       0.92      1.00      0.96        12\n",
            "           5       0.91      1.00      0.95        10\n",
            "           6       1.00      0.82      0.90        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.71      0.83      0.77         6\n",
            "          13       0.80      0.80      0.80         5\n",
            "          16       0.75      0.90      0.82        10\n",
            "          17       1.00      1.00      1.00        17\n",
            "\n",
            "    accuracy                           0.92       116\n",
            "   macro avg       0.91      0.91      0.91       116\n",
            "weighted avg       0.93      0.92      0.92       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8879310344827587, 'f1': 0.8899746803897359, 'precision': 0.9036969496021219, 'recall': 0.8879310344827587}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      1.00      0.96        12\n",
            "           2       0.80      0.80      0.80        10\n",
            "           3       0.62      0.91      0.74        11\n",
            "           4       0.92      1.00      0.96        12\n",
            "           5       1.00      0.90      0.95        10\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       0.80      0.67      0.73         6\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       0.80      0.80      0.80        10\n",
            "          17       1.00      0.76      0.87        17\n",
            "\n",
            "    accuracy                           0.89       116\n",
            "   macro avg       0.90      0.89      0.89       116\n",
            "weighted avg       0.90      0.89      0.89       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8620689655172413, 'f1': 0.8628534619019215, 'precision': 0.8744868637110016, 'recall': 0.8620689655172413}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        12\n",
            "           2       0.92      1.00      0.96        11\n",
            "           3       0.71      0.91      0.80        11\n",
            "           4       0.83      0.91      0.87        11\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.38      0.50      0.43         6\n",
            "          13       0.67      0.40      0.50         5\n",
            "          16       0.88      0.70      0.78        10\n",
            "          17       1.00      0.82      0.90        17\n",
            "\n",
            "    accuracy                           0.86       116\n",
            "   macro avg       0.84      0.82      0.82       116\n",
            "weighted avg       0.87      0.86      0.86       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8793103448275862, 'f1': 0.8796689157166983, 'precision': 0.8865027214165145, 'recall': 0.8793103448275862}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.85      0.92      0.88        12\n",
            "           2       0.75      0.82      0.78        11\n",
            "           3       0.90      0.82      0.86        11\n",
            "           4       1.00      1.00      1.00        11\n",
            "           5       0.91      1.00      0.95        10\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       0.85      0.92      0.88        12\n",
            "          12       0.83      0.83      0.83         6\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       0.75      0.90      0.82        10\n",
            "          17       0.93      0.76      0.84        17\n",
            "\n",
            "    accuracy                           0.88       116\n",
            "   macro avg       0.89      0.88      0.88       116\n",
            "weighted avg       0.89      0.88      0.88       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.9137931034482759, 'f1': 0.9139523513389212, 'precision': 0.9169115726227794, 'recall': 0.9137931034482759}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.91      0.91      0.91        11\n",
            "           3       0.82      0.82      0.82        11\n",
            "           4       1.00      1.00      1.00        11\n",
            "           5       0.91      1.00      0.95        10\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.83      0.71      0.77         7\n",
            "          13       0.80      0.80      0.80         5\n",
            "          16       0.75      0.90      0.82        10\n",
            "          17       0.94      0.88      0.91        17\n",
            "\n",
            "    accuracy                           0.91       116\n",
            "   macro avg       0.91      0.90      0.90       116\n",
            "weighted avg       0.92      0.91      0.91       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.9051724137931034, 'f1': 0.90369217305223, 'precision': 0.9078855052992986, 'recall': 0.9051724137931034}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       0.71      0.91      0.80        11\n",
            "           4       1.00      0.91      0.95        11\n",
            "           5       1.00      0.90      0.95        10\n",
            "           6       0.91      1.00      0.95        10\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       0.86      0.86      0.86         7\n",
            "          13       0.83      1.00      0.91         5\n",
            "          16       0.80      0.89      0.84         9\n",
            "          17       0.89      0.89      0.89        18\n",
            "          24       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.91       116\n",
            "   macro avg       0.83      0.84      0.83       116\n",
            "weighted avg       0.91      0.91      0.90       116\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8782608695652174, 'f1': 0.8779725567438232, 'precision': 0.8921039034849776, 'recall': 0.8782608695652174}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.86      1.00      0.92        12\n",
            "           2       0.82      0.90      0.86        10\n",
            "           3       0.89      0.73      0.80        11\n",
            "           4       0.92      1.00      0.96        11\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       0.83      1.00      0.91        10\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      0.57      0.73         7\n",
            "          13       0.67      0.80      0.73         5\n",
            "          16       0.86      0.67      0.75         9\n",
            "          17       0.88      0.83      0.86        18\n",
            "          24       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.88       115\n",
            "   macro avg       0.81      0.79      0.79       115\n",
            "weighted avg       0.89      0.88      0.88       115\n",
            "\n",
            "Fold scores: {'accuracy': 0.9043478260869565, 'f1': 0.9015183171704912, 'precision': 0.9075719602035391, 'recall': 0.9043478260869565}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       0.83      1.00      0.91        10\n",
            "           3       0.78      0.64      0.70        11\n",
            "           4       1.00      1.00      1.00        11\n",
            "           5       0.90      0.90      0.90        10\n",
            "           6       0.91      1.00      0.95        10\n",
            "           7       0.86      1.00      0.92        12\n",
            "          12       1.00      0.71      0.83         7\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       0.89      0.89      0.89         9\n",
            "          17       0.89      0.94      0.92        18\n",
            "\n",
            "    accuracy                           0.90       115\n",
            "   macro avg       0.91      0.90      0.90       115\n",
            "weighted avg       0.91      0.90      0.90       115\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.8347826086956521, 'f1': 0.8349810707950373, 'precision': 0.8444833097235843, 'recall': 0.8347826086956521}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       1.00      0.80      0.89        10\n",
            "           3       0.91      0.91      0.91        11\n",
            "           4       0.90      0.82      0.86        11\n",
            "           5       0.89      0.89      0.89         9\n",
            "           6       0.75      0.82      0.78        11\n",
            "           7       0.79      0.92      0.85        12\n",
            "          12       0.56      0.71      0.63         7\n",
            "          13       0.60      0.75      0.67         4\n",
            "          16       0.71      0.50      0.59        10\n",
            "          17       0.89      0.94      0.92        18\n",
            "\n",
            "    accuracy                           0.83       115\n",
            "   macro avg       0.82      0.82      0.81       115\n",
            "weighted avg       0.84      0.83      0.83       115\n",
            "\n",
            "Average validation scores: {'accuracy': 0.8850149925037482, 'f1': 0.8854732457219592, 'precision': 0.895113217632197, 'recall': 0.8850149925037482}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set scores: {'accuracy': 0.9215291750503019, 'f1': 0.9209263048420555, 'precision': 0.9220587132945072, 'recall': 0.9215291750503019}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.95      1.00      0.97        37\n",
            "           2       0.98      1.00      0.99        50\n",
            "           3       0.91      0.82      0.87        51\n",
            "           4       1.00      0.96      0.98        57\n",
            "           5       1.00      0.92      0.96        53\n",
            "           6       0.88      1.00      0.94        30\n",
            "           7       0.95      0.98      0.96        55\n",
            "          12       0.80      0.76      0.78        21\n",
            "          13       0.79      0.79      0.79        24\n",
            "          16       0.80      0.79      0.80        42\n",
            "          17       0.90      0.95      0.92        77\n",
            "\n",
            "    accuracy                           0.92       497\n",
            "   macro avg       0.91      0.91      0.91       497\n",
            "weighted avg       0.92      0.92      0.92       497\n",
            "\n",
            "   subject_id          model  val_accuracy    val_f1  val_precision  \\\n",
            "0           1  Decision Tree      0.891109  0.890608       0.900266   \n",
            "1           2  Decision Tree      0.891695  0.889756       0.896786   \n",
            "2           3  Decision Tree      0.899475  0.899234       0.908576   \n",
            "3           4  Decision Tree      0.909389  0.908761       0.915405   \n",
            "4           5  Decision Tree      0.902562  0.901228       0.908950   \n",
            "5           6  Decision Tree      0.885015  0.885473       0.895113   \n",
            "\n",
            "   val_recall  test_accuracy   test_f1  test_precision  test_recall  \n",
            "0    0.891109       0.907258  0.906764        0.909372     0.907258  \n",
            "1    0.891695       0.915870  0.915793        0.919360     0.915870  \n",
            "2    0.899475       0.953757  0.953611        0.953820     0.953757  \n",
            "3    0.909389       0.906522  0.906739        0.908550     0.906522  \n",
            "4    0.902562       0.931608  0.932103        0.933539     0.931608  \n",
            "5    0.885015       0.921529  0.920926        0.922059     0.921529  \n"
          ]
        }
      ],
      "source": [
        "# Generate features and labels for each subject using PreProcessor and FeatureExtraction\n",
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "file_path =  '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject106.dat'\n",
        "\n",
        "preprocessor.initializeDataFrame(file_path)\n",
        "preprocessor.dataCleaning()\n",
        "preprocessor.applyPreProcessing()\n",
        "\n",
        "subject_id = int(file_path[-5])\n",
        "subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-1h8xwHHUsL",
        "outputId": "d8515d06-d5e0-4096-eac6-2d6378c1d6f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame still contains some NAN values\n",
            "Evaluating model: Decision Tree for subject 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.9074074074074074, 'f1': 0.9054832296791361, 'precision': 0.9093469801803136, 'recall': 0.9074074074074074}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        13\n",
            "           2       0.57      0.80      0.67         5\n",
            "           3       0.85      0.92      0.88        12\n",
            "           4       1.00      1.00      1.00        16\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       0.92      0.85      0.88        13\n",
            "          12       0.90      1.00      0.95         9\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       0.82      0.90      0.86        10\n",
            "          17       1.00      0.85      0.92        13\n",
            "\n",
            "    accuracy                           0.91       108\n",
            "   macro avg       0.82      0.82      0.81       108\n",
            "weighted avg       0.91      0.91      0.91       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9351851851851852, 'f1': 0.938129546764423, 'precision': 0.9462081128747796, 'recall': 0.9351851851851852}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      1.00      1.00         5\n",
            "           3       0.92      0.92      0.92        12\n",
            "           4       1.00      0.94      0.97        16\n",
            "           5       0.50      1.00      0.67         1\n",
            "           6       0.92      1.00      0.96        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.86      0.75      0.80         8\n",
            "          13       0.62      0.83      0.71         6\n",
            "          16       1.00      1.00      1.00        11\n",
            "          17       1.00      0.92      0.96        13\n",
            "\n",
            "    accuracy                           0.94       108\n",
            "   macro avg       0.89      0.93      0.90       108\n",
            "weighted avg       0.95      0.94      0.94       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9166666666666666, 'f1': 0.9158568587279232, 'precision': 0.9206196581196581, 'recall': 0.9166666666666666}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       0.67      0.67      0.67         6\n",
            "           3       0.91      0.91      0.91        11\n",
            "           4       1.00      0.81      0.90        16\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       0.92      1.00      0.96        11\n",
            "           7       0.92      1.00      0.96        12\n",
            "          12       0.75      0.75      0.75         8\n",
            "          13       1.00      0.83      0.91         6\n",
            "          16       1.00      1.00      1.00        11\n",
            "          17       0.87      1.00      0.93        13\n",
            "\n",
            "    accuracy                           0.92       108\n",
            "   macro avg       0.91      0.91      0.91       108\n",
            "weighted avg       0.92      0.92      0.92       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9444444444444444, 'f1': 0.9425178787336598, 'precision': 0.9516028633675693, 'recall': 0.9444444444444444}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      0.67      0.80         6\n",
            "           3       1.00      1.00      1.00        11\n",
            "           4       0.94      1.00      0.97        16\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       0.79      1.00      0.88        11\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.67      0.80         6\n",
            "          16       0.91      0.91      0.91        11\n",
            "          17       0.93      1.00      0.96        13\n",
            "\n",
            "    accuracy                           0.94       108\n",
            "   macro avg       0.96      0.92      0.93       108\n",
            "weighted avg       0.95      0.94      0.94       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9166666666666666, 'f1': 0.9150177488384117, 'precision': 0.9211309523809523, 'recall': 0.9166666666666666}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00         6\n",
            "           3       0.91      0.91      0.91        11\n",
            "           4       0.94      0.94      0.94        16\n",
            "           5       0.50      1.00      0.67         1\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       0.86      1.00      0.92        12\n",
            "          12       0.88      0.88      0.88         8\n",
            "          13       1.00      0.83      0.91         6\n",
            "          16       0.88      0.64      0.74        11\n",
            "          17       0.93      1.00      0.96        13\n",
            "\n",
            "    accuracy                           0.92       108\n",
            "   macro avg       0.89      0.92      0.89       108\n",
            "weighted avg       0.92      0.92      0.92       108\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold scores: {'accuracy': 0.9074074074074074, 'f1': 0.902661071260105, 'precision': 0.9017924976258309, 'recall': 0.9074074074074074}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.85      0.88        13\n",
            "           2       1.00      0.83      0.91         6\n",
            "           3       1.00      1.00      1.00        11\n",
            "           4       0.94      0.94      0.94        16\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.92      1.00      0.96        11\n",
            "           7       0.92      1.00      0.96        12\n",
            "          12       0.80      1.00      0.89         8\n",
            "          13       0.83      0.83      0.83         6\n",
            "          16       0.82      0.82      0.82        11\n",
            "          17       0.92      0.85      0.88        13\n",
            "\n",
            "    accuracy                           0.91       108\n",
            "   macro avg       0.82      0.83      0.82       108\n",
            "weighted avg       0.90      0.91      0.90       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9166666666666666, 'f1': 0.917875086405558, 'precision': 0.9249632569077013, 'recall': 0.9166666666666666}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       1.00      1.00      1.00         6\n",
            "           3       0.82      0.82      0.82        11\n",
            "           4       0.94      0.94      0.94        16\n",
            "           5       1.00      1.00      1.00         2\n",
            "           6       0.92      1.00      0.96        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      0.75      0.86         8\n",
            "          13       0.57      0.80      0.67         5\n",
            "          16       0.89      0.80      0.84        10\n",
            "          17       0.93      1.00      0.97        14\n",
            "\n",
            "    accuracy                           0.92       108\n",
            "   macro avg       0.92      0.91      0.91       108\n",
            "weighted avg       0.92      0.92      0.92       108\n",
            "\n",
            "Fold scores: {'accuracy': 0.9065420560747663, 'f1': 0.9060804419387793, 'precision': 0.9078771695594126, 'recall': 0.9065420560747663}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       0.83      0.83      0.83         6\n",
            "           3       0.86      1.00      0.92        12\n",
            "           4       0.93      0.93      0.93        15\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.82      0.82      0.82        11\n",
            "           7       0.92      0.92      0.92        12\n",
            "          12       0.86      0.75      0.80         8\n",
            "          13       0.80      0.80      0.80         5\n",
            "          16       1.00      0.90      0.95        10\n",
            "          17       1.00      1.00      1.00        14\n",
            "\n",
            "    accuracy                           0.91       107\n",
            "   macro avg       0.82      0.81      0.82       107\n",
            "weighted avg       0.91      0.91      0.91       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.897196261682243, 'f1': 0.8964862759255282, 'precision': 0.9039231796241142, 'recall': 0.897196261682243}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       0.86      1.00      0.92         6\n",
            "           3       0.92      1.00      0.96        12\n",
            "           4       0.83      1.00      0.91        15\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      0.82      0.90        11\n",
            "           7       0.92      0.92      0.92        13\n",
            "          12       0.75      0.75      0.75         8\n",
            "          13       1.00      0.80      0.89         5\n",
            "          16       0.82      0.90      0.86        10\n",
            "          17       0.91      0.77      0.83        13\n",
            "\n",
            "    accuracy                           0.90       107\n",
            "   macro avg       0.91      0.90      0.90       107\n",
            "weighted avg       0.90      0.90      0.90       107\n",
            "\n",
            "Fold scores: {'accuracy': 0.9626168224299065, 'f1': 0.9630422737475336, 'precision': 0.967873831775701, 'recall': 0.9626168224299065}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.81      1.00      0.90        13\n",
            "           2       1.00      1.00      1.00         6\n",
            "           3       1.00      1.00      1.00        12\n",
            "           4       0.93      0.93      0.93        15\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       1.00      0.90      0.95        10\n",
            "          17       1.00      0.85      0.92        13\n",
            "\n",
            "    accuracy                           0.96       107\n",
            "   macro avg       0.98      0.97      0.97       107\n",
            "weighted avg       0.97      0.96      0.96       107\n",
            "\n",
            "Average validation scores: {'accuracy': 0.921079958463136, 'f1': 0.9203150412021058, 'precision': 0.9255338502416034, 'recall': 0.921079958463136}\n",
            "Test set scores: {'accuracy': 0.9047619047619048, 'f1': 0.9035187646074185, 'precision': 0.9072085303700608, 'recall': 0.9047619047619048}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.98      0.94        41\n",
            "           2       0.83      0.87      0.85        23\n",
            "           3       0.87      0.93      0.90        56\n",
            "           4       0.97      0.97      0.97        67\n",
            "           5       0.90      0.75      0.82        12\n",
            "           6       0.91      1.00      0.95        40\n",
            "           7       0.96      0.99      0.97        67\n",
            "          12       0.90      0.80      0.85        35\n",
            "          13       0.75      0.90      0.82        20\n",
            "          16       0.84      0.84      0.84        38\n",
            "          17       0.94      0.76      0.84        63\n",
            "\n",
            "    accuracy                           0.90       462\n",
            "   macro avg       0.89      0.89      0.89       462\n",
            "weighted avg       0.91      0.90      0.90       462\n",
            "\n",
            "   subject_id          model  val_accuracy    val_f1  val_precision  \\\n",
            "0           1  Decision Tree      0.891109  0.890608       0.900266   \n",
            "1           2  Decision Tree      0.891695  0.889756       0.896786   \n",
            "2           3  Decision Tree      0.899475  0.899234       0.908576   \n",
            "3           4  Decision Tree      0.909389  0.908761       0.915405   \n",
            "4           5  Decision Tree      0.902562  0.901228       0.908950   \n",
            "5           6  Decision Tree      0.885015  0.885473       0.895113   \n",
            "6           7  Decision Tree      0.921080  0.920315       0.925534   \n",
            "\n",
            "   val_recall  test_accuracy   test_f1  test_precision  test_recall  \n",
            "0    0.891109       0.907258  0.906764        0.909372     0.907258  \n",
            "1    0.891695       0.915870  0.915793        0.919360     0.915870  \n",
            "2    0.899475       0.953757  0.953611        0.953820     0.953757  \n",
            "3    0.909389       0.906522  0.906739        0.908550     0.906522  \n",
            "4    0.902562       0.931608  0.932103        0.933539     0.931608  \n",
            "5    0.885015       0.921529  0.920926        0.922059     0.921529  \n",
            "6    0.921080       0.904762  0.903519        0.907209     0.904762  \n"
          ]
        }
      ],
      "source": [
        "# Generate features and labels for each subject using PreProcessor and FeatureExtraction\n",
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "file_path =  '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject107.dat'\n",
        "\n",
        "preprocessor.initializeDataFrame(file_path)\n",
        "preprocessor.dataCleaning()\n",
        "preprocessor.applyPreProcessing()\n",
        "\n",
        "subject_id = int(file_path[-5])\n",
        "subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUfBZZ_vHrx4",
        "outputId": "9ba5df46-7b73-4860-aeb3-f410fdfbe4a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model: Decision Tree for subject 8\n",
            "Fold scores: {'accuracy': 0.9098360655737705, 'f1': 0.9098035800454651, 'precision': 0.9177985948477752, 'recall': 0.9098360655737705}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        13\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       0.92      0.92      0.92        12\n",
            "           4       0.83      1.00      0.91        15\n",
            "           5       0.89      0.89      0.89         9\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       0.93      1.00      0.96        13\n",
            "          12       0.80      0.80      0.80         5\n",
            "          13       0.60      0.75      0.67         4\n",
            "          16       1.00      0.73      0.84        11\n",
            "          17       1.00      0.93      0.97        15\n",
            "          24       1.00      0.75      0.86         4\n",
            "\n",
            "    accuracy                           0.91       122\n",
            "   macro avg       0.90      0.88      0.89       122\n",
            "weighted avg       0.92      0.91      0.91       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9426229508196722, 'f1': 0.9409711379998266, 'precision': 0.9439075630252102, 'recall': 0.9426229508196722}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        13\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       1.00      0.82      0.90        11\n",
            "           4       1.00      1.00      1.00        15\n",
            "           5       1.00      1.00      1.00         9\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       0.93      1.00      0.96        13\n",
            "          12       0.75      0.60      0.67         5\n",
            "          13       0.80      1.00      0.89         4\n",
            "          16       0.90      0.82      0.86        11\n",
            "          17       0.88      1.00      0.94        15\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.94       122\n",
            "   macro avg       0.93      0.93      0.93       122\n",
            "weighted avg       0.94      0.94      0.94       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.8934426229508197, 'f1': 0.8927783830560087, 'precision': 0.8981443533697633, 'recall': 0.8934426229508197}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.85      0.88        13\n",
            "           2       0.83      1.00      0.91        10\n",
            "           3       0.90      0.82      0.86        11\n",
            "           4       1.00      0.93      0.97        15\n",
            "           5       0.89      1.00      0.94         8\n",
            "           6       0.91      0.91      0.91        11\n",
            "           7       0.81      0.93      0.87        14\n",
            "          12       1.00      1.00      1.00         5\n",
            "          13       0.75      0.60      0.67         5\n",
            "          16       1.00      0.82      0.90        11\n",
            "          17       0.81      0.87      0.84        15\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.89       122\n",
            "   macro avg       0.90      0.89      0.89       122\n",
            "weighted avg       0.90      0.89      0.89       122\n",
            "\n",
            "Fold scores: {'accuracy': 0.9669421487603306, 'f1': 0.9671607853426036, 'precision': 0.9708382526564344, 'recall': 0.9669421487603306}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      1.00      0.96        13\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       1.00      1.00      1.00        11\n",
            "           4       1.00      1.00      1.00        15\n",
            "           5       0.80      1.00      0.89         8\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.80      0.89         5\n",
            "          13       1.00      1.00      1.00         5\n",
            "          16       1.00      0.91      0.95        11\n",
            "          17       0.93      0.93      0.93        15\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.97       121\n",
            "   macro avg       0.97      0.96      0.96       121\n",
            "weighted avg       0.97      0.97      0.97       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.8677685950413223, 'f1': 0.8609034862235538, 'precision': 0.8717138921684376, 'recall': 0.8677685950413223}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       0.73      1.00      0.85        11\n",
            "           4       0.88      0.93      0.90        15\n",
            "           5       1.00      0.88      0.93         8\n",
            "           6       0.86      1.00      0.92        12\n",
            "           7       0.93      1.00      0.96        13\n",
            "          12       0.50      0.40      0.44         5\n",
            "          13       0.67      0.80      0.73         5\n",
            "          16       0.83      0.45      0.59        11\n",
            "          17       0.93      0.87      0.90        15\n",
            "          24       0.75      0.75      0.75         4\n",
            "\n",
            "    accuracy                           0.87       121\n",
            "   macro avg       0.84      0.83      0.83       121\n",
            "weighted avg       0.87      0.87      0.86       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.9090909090909091, 'f1': 0.9044482936725968, 'precision': 0.9166890447639111, 'recall': 0.9090909090909091}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        12\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       0.86      1.00      0.92        12\n",
            "           4       0.76      0.93      0.84        14\n",
            "           5       0.89      1.00      0.94         8\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.75      0.60      0.67         5\n",
            "          13       1.00      0.40      0.57         5\n",
            "          16       0.92      0.92      0.92        12\n",
            "          17       0.93      1.00      0.97        14\n",
            "          24       1.00      0.75      0.86         4\n",
            "\n",
            "    accuracy                           0.91       121\n",
            "   macro avg       0.92      0.86      0.88       121\n",
            "weighted avg       0.92      0.91      0.90       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.9173553719008265, 'f1': 0.9191860027991161, 'precision': 0.9268206540933814, 'recall': 0.9173553719008265}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       1.00      1.00      1.00        12\n",
            "           4       0.92      0.86      0.89        14\n",
            "           5       0.78      0.88      0.82         8\n",
            "           6       1.00      0.92      0.96        12\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.71      1.00      0.83         5\n",
            "          13       0.60      0.60      0.60         5\n",
            "          16       0.79      0.92      0.85        12\n",
            "          17       1.00      0.93      0.96        14\n",
            "          24       1.00      0.75      0.86         4\n",
            "\n",
            "    accuracy                           0.92       121\n",
            "   macro avg       0.90      0.90      0.89       121\n",
            "weighted avg       0.93      0.92      0.92       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.8760330578512396, 'f1': 0.8811511411178563, 'precision': 0.8910593538692712, 'recall': 0.8760330578512396}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       0.92      1.00      0.96        12\n",
            "           4       0.92      0.86      0.89        14\n",
            "           5       1.00      1.00      1.00         8\n",
            "           6       1.00      0.92      0.96        12\n",
            "           7       0.85      0.85      0.85        13\n",
            "          12       0.57      0.80      0.67         5\n",
            "          13       0.43      0.60      0.50         5\n",
            "          16       0.82      0.75      0.78        12\n",
            "          17       0.86      0.86      0.86        14\n",
            "          24       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.88       121\n",
            "   macro avg       0.86      0.87      0.86       121\n",
            "weighted avg       0.89      0.88      0.88       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.9256198347107438, 'f1': 0.9225038453308617, 'precision': 0.9297520661157025, 'recall': 0.9256198347107438}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       0.92      0.92      0.92        12\n",
            "           4       0.93      1.00      0.97        14\n",
            "           5       1.00      0.88      0.93         8\n",
            "           6       0.80      1.00      0.89        12\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       0.83      1.00      0.91         5\n",
            "          13       0.83      1.00      0.91         5\n",
            "          16       0.88      0.58      0.70        12\n",
            "          17       1.00      0.93      0.96        14\n",
            "          24       0.75      0.75      0.75         4\n",
            "\n",
            "    accuracy                           0.93       121\n",
            "   macro avg       0.91      0.92      0.91       121\n",
            "weighted avg       0.93      0.93      0.92       121\n",
            "\n",
            "Fold scores: {'accuracy': 0.8842975206611571, 'f1': 0.8822338598195472, 'precision': 0.9030396691173116, 'recall': 0.8842975206611571}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        13\n",
            "           2       0.82      0.90      0.86        10\n",
            "           3       1.00      0.83      0.91        12\n",
            "           4       0.74      1.00      0.85        14\n",
            "           5       1.00      0.62      0.77         8\n",
            "           6       1.00      1.00      1.00        12\n",
            "           7       1.00      0.77      0.87        13\n",
            "          12       0.80      0.80      0.80         5\n",
            "          13       0.60      0.75      0.67         4\n",
            "          16       0.85      1.00      0.92        11\n",
            "          17       0.94      1.00      0.97        15\n",
            "          24       1.00      0.50      0.67         4\n",
            "\n",
            "    accuracy                           0.88       121\n",
            "   macro avg       0.89      0.84      0.85       121\n",
            "weighted avg       0.90      0.88      0.88       121\n",
            "\n",
            "Average validation scores: {'accuracy': 0.9093009077360792, 'f1': 0.9081140515407435, 'precision': 0.9169763444027199, 'recall': 0.9093009077360792}\n",
            "Test set scores: {'accuracy': 0.9097888675623801, 'f1': 0.9106820330674934, 'precision': 0.9169034626167292, 'recall': 0.9097888675623801}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.86      1.00      0.92        36\n",
            "           2       1.00      0.92      0.96        51\n",
            "           3       0.75      0.92      0.82        51\n",
            "           4       0.97      0.95      0.96        65\n",
            "           5       0.96      0.85      0.90        27\n",
            "           6       1.00      0.92      0.96        52\n",
            "           7       0.94      0.98      0.96        61\n",
            "          12       0.83      0.80      0.82        25\n",
            "          13       0.74      0.88      0.80        16\n",
            "          16       0.93      0.87      0.90        47\n",
            "          17       0.92      0.81      0.86        73\n",
            "          24       0.94      1.00      0.97        17\n",
            "\n",
            "    accuracy                           0.91       521\n",
            "   macro avg       0.90      0.91      0.90       521\n",
            "weighted avg       0.92      0.91      0.91       521\n",
            "\n",
            "   subject_id          model  val_accuracy    val_f1  val_precision  \\\n",
            "0           1  Decision Tree      0.891109  0.890608       0.900266   \n",
            "1           2  Decision Tree      0.891695  0.889756       0.896786   \n",
            "2           3  Decision Tree      0.899475  0.899234       0.908576   \n",
            "3           4  Decision Tree      0.909389  0.908761       0.915405   \n",
            "4           5  Decision Tree      0.902562  0.901228       0.908950   \n",
            "5           6  Decision Tree      0.885015  0.885473       0.895113   \n",
            "6           7  Decision Tree      0.921080  0.920315       0.925534   \n",
            "7           8  Decision Tree      0.909301  0.908114       0.916976   \n",
            "\n",
            "   val_recall  test_accuracy   test_f1  test_precision  test_recall  \n",
            "0    0.891109       0.907258  0.906764        0.909372     0.907258  \n",
            "1    0.891695       0.915870  0.915793        0.919360     0.915870  \n",
            "2    0.899475       0.953757  0.953611        0.953820     0.953757  \n",
            "3    0.909389       0.906522  0.906739        0.908550     0.906522  \n",
            "4    0.902562       0.931608  0.932103        0.933539     0.931608  \n",
            "5    0.885015       0.921529  0.920926        0.922059     0.921529  \n",
            "6    0.921080       0.904762  0.903519        0.907209     0.904762  \n",
            "7    0.909301       0.909789  0.910682        0.916903     0.909789  \n"
          ]
        }
      ],
      "source": [
        "# Generate features and labels for each subject using PreProcessor and FeatureExtraction\n",
        "preprocessor = PreProcessor()\n",
        "subject_data = {}\n",
        "\n",
        "file_path =  '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject108.dat'\n",
        "\n",
        "preprocessor.initializeDataFrame(file_path)\n",
        "preprocessor.dataCleaning()\n",
        "preprocessor.applyPreProcessing()\n",
        "\n",
        "subject_id = int(file_path[-5])\n",
        "subject_df = preprocessor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size=150, overlap=0, fs=100)\n",
        "\n",
        "subject_data[subject_id] = (features, labels)\n",
        "\n",
        "# Evaluate models for all subjects\n",
        "evaluator.evaluate_all_subjects(subject_data)\n",
        "\n",
        "# Report results\n",
        "results_df = evaluator.report_results()\n",
        "\n",
        "# Save results_df with subject id\n",
        "results_df.to_csv(f\"{subject_id}_results.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
