{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Noor-Z1/PAMAP2-DataAnalysis-ML/blob/main/PreProcesssing%26FeatureExtraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo77tDJTMZ4f"
      },
      "source": [
        "# **CNG 514 - Term Project**\n",
        "\n",
        "### Notebook # 2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "In this notebook we experiment with three different feature extraction techniques and compare each of their results for two different models (Random Forest and KNN), for two of the subjects\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxicRzUdJKXJ",
        "outputId": "bca9a0b4-aa67-4768-e006-d7cb0930ee9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mounting drive for loading the dataset files\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRU8hhdcK6X7"
      },
      "outputs": [],
      "source": [
        "# import the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "import matplotlib as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaXPknqon2Rt"
      },
      "source": [
        "# PreProcessor class\n",
        "\n",
        "In this class you can see the basic pre-processing applied to the data of any subject before any feature extraction. Any dropped columns are due to dataset author's comments or domain knowledge. For example all orientation columns are dropped since they are not that necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmjF0c9YhnNN"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "from scipy.signal import ellip, filtfilt, welch\n",
        "import numpy as np\n",
        "from scipy.stats import skew, kurtosis, entropy\n",
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "\n",
        "class PreProcessor:\n",
        "    def __init__(self):\n",
        "        self.dataFrame = pd.DataFrame()\n",
        "\n",
        "    def initializeDataFrame(self, filepath):\n",
        "\n",
        "        colNames = [\"timestamp\", \"activityID\", \"heartrate\"]\n",
        "\n",
        "        IMUhand = ['handTemperature',\n",
        "                   'handAcc16_1', 'handAcc16_2', 'handAcc16_3',\n",
        "                   'handAcc6_1', 'handAcc6_2', 'handAcc6_3',\n",
        "                   'handGyro1', 'handGyro2', 'handGyro3',\n",
        "                   'handMagne1', 'handMagne2', 'handMagne3',\n",
        "                   'handOrientation1', 'handOrientation2', 'handOrientation3', 'handOrientation4']\n",
        "\n",
        "        IMUchest = ['chestTemperature',\n",
        "                    'chestAcc16_1', 'chestAcc16_2', 'chestAcc16_3',\n",
        "                    'chestAcc6_1', 'chestAcc6_2', 'chestAcc6_3',\n",
        "                    'chestGyro1', 'chestGyro2', 'chestGyro3',\n",
        "                    'chestMagne1', 'chestMagne2', 'chestMagne3',\n",
        "                    'chestOrientation1', 'chestOrientation2', 'chestOrientation3', 'chestOrientation4']\n",
        "\n",
        "        IMUankle = ['ankleTemperature',\n",
        "                    'ankleAcc16_1', 'ankleAcc16_2', 'ankleAcc16_3',\n",
        "                    'ankleAcc6_1', 'ankleAcc6_2', 'ankleAcc6_3',\n",
        "                    'ankleGyro1', 'ankleGyro2', 'ankleGyro3',\n",
        "                    'ankleMagne1', 'ankleMagne2', 'ankleMagne3',\n",
        "                    'ankleOrientation1', 'ankleOrientation2', 'ankleOrientation3', 'ankleOrientation4']\n",
        "\n",
        "        columns = colNames + IMUhand + IMUchest + IMUankle  # All columns in one list\n",
        "\n",
        "        procData = pd.read_table(filepath, header=None, sep='\\s+')\n",
        "        procData.columns = columns\n",
        "        procData['subject_id'] = int(filepath[-5])\n",
        "        self.dataFrame = self.dataFrame._append(procData, ignore_index=True)\n",
        "        self.dataFrame.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    def dataCleaning(self):\n",
        "        self.dataFrame = self.dataFrame.drop(\n",
        "            ['handOrientation1', 'handOrientation2', 'handOrientation3', 'handOrientation4',\n",
        "             'chestOrientation1', 'chestOrientation2', 'chestOrientation3', 'chestOrientation4',\n",
        "             'ankleOrientation1', 'ankleOrientation2', 'ankleOrientation3', 'ankleOrientation4',\n",
        "             'handAcc6_1', 'handAcc6_2', 'handAcc6_3', 'chestAcc6_1', 'chestAcc6_2',\n",
        "             'chestAcc6_3', 'ankleAcc6_1', 'ankleAcc6_2', 'ankleAcc6_3'], axis=1)\n",
        "\n",
        "        self.dataFrame = self.dataFrame.drop(self.dataFrame[self.dataFrame.activityID == 0].index)\n",
        "        self.dataFrame = self.dataFrame.apply(pd.to_numeric, errors='ignore')\n",
        "        self.dataFrame = self.dataFrame.interpolate()\n",
        "\n",
        "    def applyPreProcessing(self):\n",
        "        self.dataFrame.reset_index(drop=True, inplace=True)\n",
        "        self.dataFrame.loc[:3, \"heartrate\"] = 100\n",
        "\n",
        "        checkForNan = self.dataFrame.isnull().values.any()\n",
        "        if checkForNan:\n",
        "            print(\"DataFrame still contains some NAN values\")\n",
        "\n",
        "    def getSubjectDf(self, subject_id):\n",
        "        return self.dataFrame[self.dataFrame['subject_id'] == subject_id]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uXdx6nLhagx"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0-19WH_hcRA"
      },
      "source": [
        "# **Feature Extraction 1**\n",
        "\n",
        "This is our own way of doing feature extraction where we:\n",
        "> perform windowing with 0 overlap and 150 as the window size, extract time and frequency domain feature from the raw gyroscope and acc columns per window and concatenate all features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNrKts7GPtLb",
        "outputId": "7386aad2-a4ff-43de-a991-8d90db2d8c05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1653, 127)\n",
            "(1653,)\n"
          ]
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "from scipy.signal import ellip, filtfilt, welch\n",
        "import numpy as np\n",
        "from scipy.stats import skew, kurtosis, entropy\n",
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "\n",
        "class FeatureExtraction1:\n",
        "    def __init__(self, subjectDf, subjectID):\n",
        "        self.dataFrame = subjectDf\n",
        "        self.subjectID = subjectID\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_time_domain_features(data, isheartrate= False):\n",
        "\n",
        "\n",
        "        mean = np.mean(data)\n",
        "        std_dev = np.std(data)\n",
        "\n",
        "        if not isheartrate:\n",
        "          skewness = skew(data, nan_policy='omit')\n",
        "          kurt = kurtosis(data, nan_policy='omit')\n",
        "          return mean, std_dev, skewness, kurt\n",
        "\n",
        "        else:\n",
        "          return mean, std_dev\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_frequency_domain_features(data, fs):\n",
        "        f, Pxx = welch(data, fs=fs, nperseg=len(data))\n",
        "        entropy_power = entropy(Pxx)\n",
        "        peak_power_freq = f[np.argmax(Pxx)]\n",
        "        return entropy_power, peak_power_freq\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_signal_magnitude_area(data):\n",
        "        return np.sum(np.abs(data))\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_pairwise_correlations(data):\n",
        "        correlations = pairwise_distances(data, metric='correlation')\n",
        "        return correlations\n",
        "\n",
        "    def sliding_window_feature_extraction(self, window_size=150, overlap=0, fs=1/0.01):\n",
        "        angular_velocity_columns = ['handGyro1', 'handGyro2', 'handGyro3',\n",
        "                                    'chestGyro1', 'chestGyro2', 'chestGyro3',\n",
        "                                    'ankleGyro1', 'ankleGyro2', 'ankleGyro3']\n",
        "        acceleration_columns = ['handAcc16_1', 'handAcc16_2', 'handAcc16_3',\n",
        "                                'chestAcc16_1', 'chestAcc16_2', 'chestAcc16_3',\n",
        "                                'ankleAcc16_1', 'ankleAcc16_2', 'ankleAcc16_3']\n",
        "\n",
        "        heart_rate_col = ['heartrate']\n",
        "\n",
        "\n",
        "        combined_columns  = angular_velocity_columns + acceleration_columns\n",
        "\n",
        "        all_features = []\n",
        "\n",
        "        all_labels = []\n",
        "\n",
        "        stride = int(window_size * (1 - overlap))\n",
        "\n",
        "        for start in range(0, len(self.dataFrame) - window_size + 1, stride):\n",
        "            window_data_time = self.dataFrame.loc[start:start + window_size - 1, angular_velocity_columns + acceleration_columns + heart_rate_col]\n",
        "            labels = self.dataFrame.loc[start:start + window_size - 1, 'activityID']\n",
        "\n",
        "            # Ensure the window contains only one activity\n",
        "            if labels.nunique() == 1:\n",
        "                label = labels.iloc[0]\n",
        "                time_domain_features = [self.compute_time_domain_features(window_data_time[column]) for column in combined_columns]\n",
        "                time_domain_features = np.array(time_domain_features).flatten()\n",
        "\n",
        "                freq_domain_features = [self.compute_frequency_domain_features(window_data_time[column], fs) for column in combined_columns]\n",
        "                freq_domain_features = np.array(freq_domain_features).flatten()\n",
        "                sma = self.compute_signal_magnitude_area(window_data_time)\n",
        "\n",
        "                # pairwise_corr = self.compute_pairwise_correlations(window_data_time)\n",
        "                # pairwise_corr = pairwise_corr.flatten()\n",
        "\n",
        "                features = np.concatenate([time_domain_features, freq_domain_features, sma])\n",
        "                all_features.append(features)\n",
        "                all_labels.append(label)\n",
        "\n",
        "        return np.array(all_features), np.array(all_labels)\n",
        "\n",
        "    def applyFeatureExtraction(self, window_size, overlap, fs):\n",
        "        features, labels = self.sliding_window_feature_extraction(window_size=window_size, overlap=overlap, fs=fs)\n",
        "        return features, labels\n",
        "\n",
        "\n",
        "\n",
        "# # Usage example\n",
        "# file_path = '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject101.dat'\n",
        "# processor = PreProcessor()\n",
        "# processor.initializeDataFrame(file_path)\n",
        "# processor.dataCleaning()\n",
        "# processor.applyPreProcessing()\n",
        "\n",
        "# subject_id = 1\n",
        "# subject_df = processor.getSubjectDf(subject_id)\n",
        "\n",
        "\n",
        "# feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "\n",
        "# window_size = 150\n",
        "# overlap = 0\n",
        "\n",
        "# features, labels = feature_extractor.applyFeatureExtraction(window_size, overlap, fs=100)\n",
        "\n",
        "# print(features.shape)\n",
        "# print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNOlxpOEOdUu",
        "outputId": "252ae894-1595-4282-d692-9f06339f66ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold accuracy: 0.9181034482758621\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.85      0.92        27\n",
            "           2       1.00      0.81      0.89        21\n",
            "           3       0.70      1.00      0.83        19\n",
            "           4       1.00      0.86      0.92        21\n",
            "           5       1.00      0.95      0.98        21\n",
            "           6       1.00      0.82      0.90        22\n",
            "           7       0.89      0.94      0.92        18\n",
            "          12       0.83      0.94      0.88        16\n",
            "          13       1.00      0.93      0.96        14\n",
            "          16       0.92      1.00      0.96        22\n",
            "          17       0.83      1.00      0.91        20\n",
            "          24       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           0.92       232\n",
            "   macro avg       0.93      0.92      0.92       232\n",
            "weighted avg       0.93      0.92      0.92       232\n",
            "\n",
            "Fold accuracy: 0.9310344827586207\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        28\n",
            "           2       1.00      0.90      0.95        21\n",
            "           3       0.79      1.00      0.88        19\n",
            "           4       1.00      0.95      0.97        20\n",
            "           5       1.00      0.86      0.92        21\n",
            "           6       1.00      1.00      1.00        21\n",
            "           7       0.95      1.00      0.97        19\n",
            "          12       0.88      0.82      0.85        17\n",
            "          13       0.91      0.77      0.83        13\n",
            "          16       0.91      0.95      0.93        22\n",
            "          17       0.86      0.90      0.88        20\n",
            "          24       0.83      0.91      0.87        11\n",
            "\n",
            "    accuracy                           0.93       232\n",
            "   macro avg       0.93      0.92      0.92       232\n",
            "weighted avg       0.94      0.93      0.93       232\n",
            "\n",
            "Fold accuracy: 0.9307359307359307\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.93      0.96        27\n",
            "           2       0.95      0.95      0.95        21\n",
            "           3       0.95      0.95      0.95        20\n",
            "           4       1.00      0.95      0.97        20\n",
            "           5       1.00      0.95      0.98        21\n",
            "           6       0.95      1.00      0.98        21\n",
            "           7       0.95      0.95      0.95        19\n",
            "          12       0.78      0.88      0.82        16\n",
            "          13       0.86      0.92      0.89        13\n",
            "          16       0.87      0.91      0.89        22\n",
            "          17       0.91      1.00      0.95        20\n",
            "          24       0.88      0.64      0.74        11\n",
            "\n",
            "    accuracy                           0.93       231\n",
            "   macro avg       0.92      0.92      0.92       231\n",
            "weighted avg       0.93      0.93      0.93       231\n",
            "\n",
            "Fold accuracy: 0.9264069264069265\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.85      0.92        27\n",
            "           2       1.00      0.86      0.92        21\n",
            "           3       0.70      0.95      0.81        20\n",
            "           4       1.00      0.95      0.97        20\n",
            "           5       1.00      0.95      0.98        21\n",
            "           6       1.00      1.00      1.00        21\n",
            "           7       1.00      0.89      0.94        18\n",
            "          12       0.78      0.88      0.82        16\n",
            "          13       0.93      1.00      0.96        13\n",
            "          16       0.95      0.95      0.95        22\n",
            "          17       0.91      1.00      0.95        21\n",
            "          24       0.90      0.82      0.86        11\n",
            "\n",
            "    accuracy                           0.93       231\n",
            "   macro avg       0.93      0.92      0.92       231\n",
            "weighted avg       0.94      0.93      0.93       231\n",
            "\n",
            "Fold accuracy: 0.9393939393939394\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.96      0.98        27\n",
            "           2       1.00      1.00      1.00        21\n",
            "           3       0.90      0.95      0.93        20\n",
            "           4       0.90      0.95      0.93        20\n",
            "           5       0.91      1.00      0.95        21\n",
            "           6       1.00      0.95      0.98        21\n",
            "           7       1.00      0.89      0.94        18\n",
            "          12       0.87      0.81      0.84        16\n",
            "          13       0.91      0.71      0.80        14\n",
            "          16       0.92      1.00      0.96        22\n",
            "          17       0.91      1.00      0.95        20\n",
            "          24       0.91      0.91      0.91        11\n",
            "\n",
            "    accuracy                           0.94       231\n",
            "   macro avg       0.94      0.93      0.93       231\n",
            "weighted avg       0.94      0.94      0.94       231\n",
            "\n",
            "Average accuracy: 0.9291349455142559\n",
            "Test set accuracy: 0.9455645161290323\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.96      0.98      0.97        45\n",
            "           2       0.98      0.94      0.96        50\n",
            "           3       0.88      0.98      0.93        46\n",
            "           4       1.00      0.94      0.97        47\n",
            "           5       0.94      0.94      0.94        36\n",
            "           6       0.98      0.98      0.98        50\n",
            "           7       1.00      0.95      0.98        42\n",
            "          12       0.84      0.91      0.87        23\n",
            "          13       1.00      0.77      0.87        30\n",
            "          16       0.87      0.93      0.90        42\n",
            "          17       0.93      0.98      0.96        55\n",
            "          24       0.97      0.97      0.97        30\n",
            "\n",
            "    accuracy                           0.95       496\n",
            "   macro avg       0.95      0.94      0.94       496\n",
            "weighted avg       0.95      0.95      0.95       496\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# now based on these features, train, test and cross validate a model\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from scipy.stats import skew, kurtosis\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "def nested_cross_validation(features, labels, test_size=0.3, n_splits=5):\n",
        "    # Split data into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=test_size, random_state=42)\n",
        "\n",
        "    outer_cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    }\n",
        "\n",
        "    model = RandomForestClassifier()\n",
        "    clf = GridSearchCV(estimator=model, param_grid=param_grid, cv=n_splits, scoring='f1_weighted')\n",
        "\n",
        "    outer_scores = []\n",
        "\n",
        "    for train_index, val_index in outer_cv.split(X_train, y_train):\n",
        "        X_train_inner, X_val = X_train[train_index], X_train[val_index]\n",
        "        y_train_inner, y_val = y_train[train_index], y_train[val_index]\n",
        "\n",
        "        imputer = SimpleImputer(strategy='mean')\n",
        "        X_train_inner = imputer.fit_transform(X_train_inner)\n",
        "        X_val = imputer.transform(X_val)\n",
        "\n",
        "        scaler = StandardScaler().fit(X_train_inner)\n",
        "        X_train_inner = scaler.transform(X_train_inner)\n",
        "        X_val = scaler.transform(X_val)\n",
        "\n",
        "        clf.fit(X_train_inner, y_train_inner)\n",
        "        best_model = clf.best_estimator_\n",
        "\n",
        "        y_pred = best_model.predict(X_val)\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        outer_scores.append(accuracy)\n",
        "\n",
        "        print(f\"Fold accuracy: {accuracy}\")\n",
        "        print(classification_report(y_val, y_pred, zero_division=0))\n",
        "\n",
        "    print(\"Average accuracy:\", np.mean(outer_scores))\n",
        "\n",
        "    # Final evaluation on the test set\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    X_train = imputer.fit_transform(X_train)\n",
        "    X_test = imputer.transform(X_test)\n",
        "\n",
        "    scaler = StandardScaler().fit(X_train)\n",
        "    X_train = scaler.transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "    best_model = clf.best_estimator_\n",
        "\n",
        "    y_pred_test = best_model.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "    print(\"Test set accuracy:\", test_accuracy)\n",
        "    print(classification_report(y_test, y_pred_test, zero_division=0))\n",
        "\n",
        "\n",
        "nested_cross_validation(features, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwOFnUI5OiHj",
        "outputId": "70fb589e-cb4c-49b8-b258-e5b564a0066b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold accuracy: 0.9310344827586207\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.86      0.92        14\n",
            "           2       0.91      1.00      0.95        10\n",
            "           3       0.73      0.89      0.80         9\n",
            "           4       1.00      0.82      0.90        11\n",
            "           5       0.91      0.91      0.91        11\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       0.90      1.00      0.95         9\n",
            "          12       0.88      0.88      0.88         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       1.00      1.00      1.00        11\n",
            "          17       1.00      1.00      1.00        10\n",
            "          24       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.93       116\n",
            "   macro avg       0.93      0.94      0.93       116\n",
            "weighted avg       0.94      0.93      0.93       116\n",
            "\n",
            "Fold accuracy: 0.8620689655172413\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      0.93      0.93        14\n",
            "           2       1.00      0.64      0.78        11\n",
            "           3       0.69      1.00      0.82         9\n",
            "           4       0.90      0.90      0.90        10\n",
            "           5       0.91      0.91      0.91        11\n",
            "           6       0.89      0.73      0.80        11\n",
            "           7       1.00      0.78      0.88         9\n",
            "          12       0.89      1.00      0.94         8\n",
            "          13       0.75      0.86      0.80         7\n",
            "          16       0.90      0.82      0.86        11\n",
            "          17       0.77      1.00      0.87        10\n",
            "          24       0.80      0.80      0.80         5\n",
            "\n",
            "    accuracy                           0.86       116\n",
            "   macro avg       0.87      0.86      0.86       116\n",
            "weighted avg       0.88      0.86      0.86       116\n",
            "\n",
            "Fold accuracy: 0.9310344827586207\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      0.73      0.84        11\n",
            "           3       0.83      1.00      0.91        10\n",
            "           4       0.91      1.00      0.95        10\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      0.89      0.94         9\n",
            "          12       0.78      0.88      0.82         8\n",
            "          13       0.86      0.86      0.86         7\n",
            "          16       1.00      1.00      1.00        11\n",
            "          17       0.82      0.90      0.86        10\n",
            "          24       1.00      0.80      0.89         5\n",
            "\n",
            "    accuracy                           0.93       116\n",
            "   macro avg       0.93      0.92      0.92       116\n",
            "weighted avg       0.94      0.93      0.93       116\n",
            "\n",
            "Fold accuracy: 0.896551724137931\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        13\n",
            "           2       1.00      0.82      0.90        11\n",
            "           3       0.71      1.00      0.83        10\n",
            "           4       0.90      0.90      0.90        10\n",
            "           5       0.91      0.91      0.91        11\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      0.89      0.94         9\n",
            "          12       0.86      0.75      0.80         8\n",
            "          13       0.86      0.86      0.86         7\n",
            "          16       0.91      0.91      0.91        11\n",
            "          17       0.82      0.90      0.86        10\n",
            "          24       1.00      0.80      0.89         5\n",
            "\n",
            "    accuracy                           0.90       116\n",
            "   macro avg       0.91      0.89      0.89       116\n",
            "weighted avg       0.91      0.90      0.90       116\n",
            "\n",
            "Fold accuracy: 0.8620689655172413\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.85      0.88        13\n",
            "           2       1.00      0.73      0.84        11\n",
            "           3       0.67      0.80      0.73        10\n",
            "           4       0.90      0.90      0.90        10\n",
            "           5       0.89      0.80      0.84        10\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       0.90      1.00      0.95         9\n",
            "          12       0.86      0.75      0.80         8\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.82      0.82      0.82        11\n",
            "          17       0.77      1.00      0.87        10\n",
            "          24       0.71      0.83      0.77         6\n",
            "\n",
            "    accuracy                           0.86       116\n",
            "   macro avg       0.87      0.86      0.86       116\n",
            "weighted avg       0.87      0.86      0.86       116\n",
            "\n",
            "Fold accuracy: 0.9482758620689655\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        11\n",
            "           3       1.00      0.90      0.95        10\n",
            "           4       1.00      1.00      1.00        10\n",
            "           5       1.00      1.00      1.00        10\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00         9\n",
            "          12       0.73      1.00      0.84         8\n",
            "          13       0.67      0.86      0.75         7\n",
            "          16       1.00      1.00      1.00        11\n",
            "          17       1.00      1.00      1.00        10\n",
            "          24       1.00      0.50      0.67         6\n",
            "\n",
            "    accuracy                           0.95       116\n",
            "   macro avg       0.95      0.93      0.93       116\n",
            "weighted avg       0.96      0.95      0.95       116\n",
            "\n",
            "Fold accuracy: 0.9310344827586207\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.86      0.92        14\n",
            "           2       1.00      0.70      0.82        10\n",
            "           3       0.83      1.00      0.91        10\n",
            "           4       0.91      1.00      0.95        10\n",
            "           5       0.90      0.90      0.90        10\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       0.90      0.90      0.90        10\n",
            "          12       0.90      1.00      0.95         9\n",
            "          13       0.75      1.00      0.86         6\n",
            "          16       1.00      0.91      0.95        11\n",
            "          17       1.00      1.00      1.00        10\n",
            "          24       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.93       116\n",
            "   macro avg       0.93      0.94      0.93       116\n",
            "weighted avg       0.94      0.93      0.93       116\n",
            "\n",
            "Fold accuracy: 0.8695652173913043\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.86      0.92        14\n",
            "           2       1.00      0.80      0.89        10\n",
            "           3       0.64      0.90      0.75        10\n",
            "           4       1.00      0.90      0.95        10\n",
            "           5       0.83      1.00      0.91        10\n",
            "           6       0.91      1.00      0.95        10\n",
            "           7       1.00      0.90      0.95        10\n",
            "          12       0.75      0.75      0.75         8\n",
            "          13       0.75      1.00      0.86         6\n",
            "          16       0.91      0.91      0.91        11\n",
            "          17       0.80      0.80      0.80        10\n",
            "          24       1.00      0.50      0.67         6\n",
            "\n",
            "    accuracy                           0.87       115\n",
            "   macro avg       0.88      0.86      0.86       115\n",
            "weighted avg       0.89      0.87      0.87       115\n",
            "\n",
            "Fold accuracy: 0.9565217391304348\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       1.00      0.80      0.89        10\n",
            "           3       0.91      1.00      0.95        10\n",
            "           4       1.00      0.90      0.95        10\n",
            "           5       0.91      1.00      0.95        10\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      1.00      1.00         9\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       1.00      1.00      1.00         6\n",
            "          16       1.00      1.00      1.00        11\n",
            "          17       0.85      1.00      0.92        11\n",
            "          24       0.83      0.83      0.83         6\n",
            "\n",
            "    accuracy                           0.96       115\n",
            "   macro avg       0.96      0.95      0.95       115\n",
            "weighted avg       0.96      0.96      0.96       115\n",
            "\n",
            "Fold accuracy: 0.8956521739130435\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.86      0.92        14\n",
            "           2       0.80      0.80      0.80        10\n",
            "           3       0.77      1.00      0.87        10\n",
            "           4       0.91      1.00      0.95        10\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       0.89      0.80      0.84        10\n",
            "           7       1.00      1.00      1.00         9\n",
            "          12       0.83      0.62      0.71         8\n",
            "          13       0.83      0.71      0.77         7\n",
            "          16       1.00      0.91      0.95        11\n",
            "          17       0.77      1.00      0.87        10\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.90       115\n",
            "   macro avg       0.90      0.89      0.89       115\n",
            "weighted avg       0.90      0.90      0.89       115\n",
            "\n",
            "Average accuracy: 0.9083808095952024\n",
            "Test set accuracy: 0.8729838709677419\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.98      0.96      0.97        45\n",
            "           2       0.86      0.74      0.80        50\n",
            "           3       0.72      0.85      0.78        46\n",
            "           4       0.93      0.91      0.92        47\n",
            "           5       0.92      0.94      0.93        36\n",
            "           6       0.98      0.92      0.95        50\n",
            "           7       0.95      0.83      0.89        42\n",
            "          12       0.72      0.91      0.81        23\n",
            "          13       0.96      0.73      0.83        30\n",
            "          16       0.97      0.86      0.91        42\n",
            "          17       0.72      0.87      0.79        55\n",
            "          24       0.91      0.97      0.94        30\n",
            "\n",
            "    accuracy                           0.87       496\n",
            "   macro avg       0.88      0.87      0.88       496\n",
            "weighted avg       0.88      0.87      0.87       496\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "def nested_cross_validation(features, labels, test_size=0.3, n_splits=10):\n",
        "\n",
        "    # Split data into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=test_size, random_state=42)\n",
        "\n",
        "    outer_cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    param_grid={\n",
        "    'n_neighbors': [3, 5, 7, 9, 11, 12],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski'] }\n",
        "\n",
        "    model = KNeighborsClassifier()\n",
        "    clf = GridSearchCV(estimator=model, param_grid=param_grid, cv=n_splits, scoring='f1_weighted')\n",
        "\n",
        "    outer_scores = []\n",
        "\n",
        "    for train_index, val_index in outer_cv.split(X_train, y_train):\n",
        "        X_train_inner, X_val = X_train[train_index], X_train[val_index]\n",
        "        y_train_inner, y_val = y_train[train_index], y_train[val_index]\n",
        "\n",
        "        scaler = RobustScaler().fit(X_train_inner)\n",
        "        X_train_inner = scaler.transform(X_train_inner)\n",
        "        X_val = scaler.transform(X_val)\n",
        "\n",
        "        clf.fit(X_train_inner, y_train_inner)\n",
        "        best_model = clf.best_estimator_\n",
        "\n",
        "        y_pred = best_model.predict(X_val)\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        outer_scores.append(accuracy)\n",
        "\n",
        "        print(f\"Fold accuracy: {accuracy}\")\n",
        "        print(classification_report(y_val, y_pred))\n",
        "\n",
        "    print(\"Average accuracy:\", np.mean(outer_scores))\n",
        "\n",
        "    # Final evaluation on the test set\n",
        "\n",
        "    scaler = RobustScaler().fit(X_train)\n",
        "    X_train = scaler.transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "    best_model = clf.best_estimator_\n",
        "\n",
        "\n",
        "    y_pred_test = best_model.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "    print(\"Test set accuracy:\", test_accuracy)\n",
        "    print(classification_report(y_test, y_pred_test, zero_division=0))\n",
        "\n",
        "\n",
        "nested_cross_validation(features, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xAFar2vR8uJ"
      },
      "source": [
        "## Evaluating the first Feature Extraction on another subject (subject 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5lXySQLQq0q",
        "outputId": "eefc4ca4-6116-48bd-d721-9a1ccb9abc87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame still contains some NAN values\n",
            "(1531, 127)\n",
            "(1531,)\n",
            "Fold accuracy: 0.9166666666666666\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       0.86      1.00      0.92        12\n",
            "           3       0.73      0.80      0.76        10\n",
            "           4       0.93      1.00      0.96        13\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       0.88      0.88      0.88         8\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       1.00      0.80      0.89        10\n",
            "          17       0.85      0.92      0.88        12\n",
            "\n",
            "    accuracy                           0.92       108\n",
            "   macro avg       0.92      0.91      0.91       108\n",
            "weighted avg       0.92      0.92      0.92       108\n",
            "\n",
            "Fold accuracy: 0.9345794392523364\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.90      0.75      0.82        12\n",
            "           3       0.75      0.90      0.82        10\n",
            "           4       0.93      1.00      0.96        13\n",
            "           6       1.00      1.00      1.00        11\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.83      0.91         6\n",
            "          16       1.00      0.80      0.89        10\n",
            "          17       0.86      1.00      0.92        12\n",
            "\n",
            "    accuracy                           0.93       107\n",
            "   macro avg       0.94      0.93      0.93       107\n",
            "weighted avg       0.94      0.93      0.93       107\n",
            "\n",
            "Fold accuracy: 0.9158878504672897\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.75      0.86        12\n",
            "           2       1.00      0.92      0.96        12\n",
            "           3       0.67      1.00      0.80        10\n",
            "           4       0.92      0.92      0.92        13\n",
            "           6       1.00      0.91      0.95        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.91      1.00      0.95        10\n",
            "          17       0.85      0.92      0.88        12\n",
            "\n",
            "    accuracy                           0.92       107\n",
            "   macro avg       0.93      0.92      0.92       107\n",
            "weighted avg       0.93      0.92      0.92       107\n",
            "\n",
            "Fold accuracy: 0.8878504672897196\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       1.00      0.75      0.86        12\n",
            "           3       0.71      1.00      0.83        10\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       0.83      0.91      0.87        11\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       1.00      0.50      0.67        10\n",
            "          17       0.65      0.92      0.76        12\n",
            "\n",
            "    accuracy                           0.89       107\n",
            "   macro avg       0.92      0.89      0.89       107\n",
            "weighted avg       0.92      0.89      0.89       107\n",
            "\n",
            "Fold accuracy: 0.9065420560747663\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.91      0.91        11\n",
            "           2       0.91      0.83      0.87        12\n",
            "           3       0.73      0.73      0.73        11\n",
            "           4       0.93      0.93      0.93        14\n",
            "           6       0.92      1.00      0.96        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.88      0.70      0.78        10\n",
            "          17       0.86      1.00      0.92        12\n",
            "\n",
            "    accuracy                           0.91       107\n",
            "   macro avg       0.91      0.91      0.91       107\n",
            "weighted avg       0.91      0.91      0.90       107\n",
            "\n",
            "Fold accuracy: 0.9158878504672897\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.82      0.90        11\n",
            "           2       0.91      0.83      0.87        12\n",
            "           3       0.79      1.00      0.88        11\n",
            "           4       0.87      1.00      0.93        13\n",
            "           6       0.92      1.00      0.96        11\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       1.00      0.80      0.89        10\n",
            "          17       0.85      0.92      0.88        12\n",
            "\n",
            "    accuracy                           0.92       107\n",
            "   macro avg       0.93      0.91      0.91       107\n",
            "weighted avg       0.93      0.92      0.91       107\n",
            "\n",
            "Fold accuracy: 0.8598130841121495\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.64      0.78        11\n",
            "           2       0.83      0.83      0.83        12\n",
            "           3       0.50      0.82      0.62        11\n",
            "           4       0.93      1.00      0.96        13\n",
            "           6       0.90      0.90      0.90        10\n",
            "           7       1.00      0.83      0.91        12\n",
            "          12       0.89      1.00      0.94         8\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       1.00      0.91      0.95        11\n",
            "          17       0.92      0.92      0.92        12\n",
            "\n",
            "    accuracy                           0.86       107\n",
            "   macro avg       0.90      0.86      0.86       107\n",
            "weighted avg       0.89      0.86      0.87       107\n",
            "\n",
            "Fold accuracy: 0.897196261682243\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        11\n",
            "           2       1.00      0.92      0.96        12\n",
            "           3       0.71      0.91      0.80        11\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       0.90      0.90      0.90        10\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.62      0.77         8\n",
            "          13       0.83      0.71      0.77         7\n",
            "          16       1.00      0.73      0.84        11\n",
            "          17       0.69      1.00      0.81        11\n",
            "\n",
            "    accuracy                           0.90       107\n",
            "   macro avg       0.91      0.88      0.89       107\n",
            "weighted avg       0.92      0.90      0.90       107\n",
            "\n",
            "Fold accuracy: 0.8878504672897196\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.77      0.83      0.80        12\n",
            "           3       0.62      0.91      0.74        11\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       1.00      0.60      0.75        10\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       1.00      0.80      0.89        10\n",
            "          17       0.77      0.91      0.83        11\n",
            "\n",
            "    accuracy                           0.89       107\n",
            "   macro avg       0.92      0.88      0.89       107\n",
            "weighted avg       0.91      0.89      0.89       107\n",
            "\n",
            "Fold accuracy: 0.9158878504672897\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.92      0.92      0.92        12\n",
            "           3       0.71      0.91      0.80        11\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       1.00      0.80      0.89        10\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       1.00      0.75      0.86         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.90      0.90      0.90        10\n",
            "          17       0.77      0.91      0.83        11\n",
            "\n",
            "    accuracy                           0.92       107\n",
            "   macro avg       0.93      0.91      0.92       107\n",
            "weighted avg       0.93      0.92      0.92       107\n",
            "\n",
            "Average accuracy: 0.9038161993769469\n",
            "Test set accuracy: 0.9152173913043479\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        37\n",
            "           2       0.91      0.98      0.94        49\n",
            "           3       0.76      0.93      0.84        58\n",
            "           4       0.96      0.96      0.96        80\n",
            "           6       0.94      1.00      0.97        44\n",
            "           7       1.00      0.96      0.98        56\n",
            "          12       0.81      0.81      0.81        32\n",
            "          13       1.00      0.64      0.78        25\n",
            "          16       1.00      0.74      0.85        31\n",
            "          17       0.89      0.88      0.88        48\n",
            "\n",
            "    accuracy                           0.92       460\n",
            "   macro avg       0.93      0.89      0.90       460\n",
            "weighted avg       0.92      0.92      0.91       460\n",
            "\n",
            "Fold accuracy: 0.9534883720930233\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.96      0.98        23\n",
            "           2       0.96      0.96      0.96        24\n",
            "           3       0.84      1.00      0.91        21\n",
            "           4       0.96      0.96      0.96        26\n",
            "           6       1.00      0.95      0.98        22\n",
            "           7       1.00      1.00      1.00        25\n",
            "          12       0.94      0.94      0.94        16\n",
            "          13       1.00      0.93      0.96        14\n",
            "          16       0.95      0.90      0.92        20\n",
            "          17       0.92      0.92      0.92        24\n",
            "\n",
            "    accuracy                           0.95       215\n",
            "   macro avg       0.96      0.95      0.95       215\n",
            "weighted avg       0.96      0.95      0.95       215\n",
            "\n",
            "Fold accuracy: 0.9485981308411215\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.91      0.95        23\n",
            "           2       0.92      0.92      0.92        24\n",
            "           3       0.83      0.90      0.86        21\n",
            "           4       1.00      1.00      1.00        26\n",
            "           6       1.00      0.90      0.95        21\n",
            "           7       1.00      0.96      0.98        25\n",
            "          12       0.94      1.00      0.97        16\n",
            "          13       1.00      0.92      0.96        13\n",
            "          16       0.91      0.95      0.93        21\n",
            "          17       0.92      1.00      0.96        24\n",
            "\n",
            "    accuracy                           0.95       214\n",
            "   macro avg       0.95      0.95      0.95       214\n",
            "weighted avg       0.95      0.95      0.95       214\n",
            "\n",
            "Fold accuracy: 0.9672897196261683\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.91      0.95        23\n",
            "           2       1.00      0.96      0.98        24\n",
            "           3       0.87      0.95      0.91        21\n",
            "           4       1.00      0.96      0.98        26\n",
            "           6       1.00      1.00      1.00        21\n",
            "           7       0.96      1.00      0.98        26\n",
            "          12       1.00      1.00      1.00        15\n",
            "          13       1.00      1.00      1.00        14\n",
            "          16       0.95      0.90      0.93        21\n",
            "          17       0.92      1.00      0.96        23\n",
            "\n",
            "    accuracy                           0.97       214\n",
            "   macro avg       0.97      0.97      0.97       214\n",
            "weighted avg       0.97      0.97      0.97       214\n",
            "\n",
            "Fold accuracy: 0.9205607476635514\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        24\n",
            "           2       0.95      0.88      0.91        24\n",
            "           3       0.69      0.95      0.80        21\n",
            "           4       0.96      1.00      0.98        26\n",
            "           6       1.00      1.00      1.00        21\n",
            "           7       1.00      1.00      1.00        26\n",
            "          12       1.00      0.80      0.89        15\n",
            "          13       1.00      0.71      0.83        14\n",
            "          16       0.86      0.90      0.88        20\n",
            "          17       0.88      1.00      0.94        23\n",
            "\n",
            "    accuracy                           0.92       214\n",
            "   macro avg       0.93      0.91      0.91       214\n",
            "weighted avg       0.93      0.92      0.92       214\n",
            "\n",
            "Fold accuracy: 0.9345794392523364\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        23\n",
            "           2       1.00      0.96      0.98        24\n",
            "           3       0.81      1.00      0.90        22\n",
            "           4       1.00      1.00      1.00        27\n",
            "           6       1.00      0.81      0.89        21\n",
            "           7       1.00      0.96      0.98        25\n",
            "          12       1.00      0.80      0.89        15\n",
            "          13       0.88      1.00      0.93        14\n",
            "          16       0.94      0.85      0.89        20\n",
            "          17       0.78      0.91      0.84        23\n",
            "\n",
            "    accuracy                           0.93       214\n",
            "   macro avg       0.94      0.93      0.93       214\n",
            "weighted avg       0.94      0.93      0.94       214\n",
            "\n",
            "Average accuracy: 0.9449032818952402\n",
            "Test set accuracy: 0.95\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        37\n",
            "           2       1.00      0.98      0.99        49\n",
            "           3       0.84      1.00      0.91        58\n",
            "           4       1.00      0.96      0.98        80\n",
            "           6       1.00      0.98      0.99        44\n",
            "           7       1.00      0.98      0.99        56\n",
            "          12       0.85      0.91      0.88        32\n",
            "          13       0.90      0.76      0.83        25\n",
            "          16       0.90      0.87      0.89        31\n",
            "          17       0.96      0.92      0.94        48\n",
            "\n",
            "    accuracy                           0.95       460\n",
            "   macro avg       0.95      0.94      0.94       460\n",
            "weighted avg       0.95      0.95      0.95       460\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from scipy.stats import skew, kurtosis\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "def nested_cross_validationRF(features, labels, test_size=0.3, n_splits=5):\n",
        "    # Split data into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=test_size, random_state=42)\n",
        "\n",
        "    outer_cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    }\n",
        "\n",
        "    model = RandomForestClassifier()\n",
        "    clf = GridSearchCV(estimator=model, param_grid=param_grid, cv=n_splits, scoring='f1_weighted')\n",
        "\n",
        "    outer_scores = []\n",
        "\n",
        "    for train_index, val_index in outer_cv.split(X_train, y_train):\n",
        "        X_train_inner, X_val = X_train[train_index], X_train[val_index]\n",
        "        y_train_inner, y_val = y_train[train_index], y_train[val_index]\n",
        "\n",
        "        imputer = SimpleImputer(strategy='mean')\n",
        "        X_train_inner = imputer.fit_transform(X_train_inner)\n",
        "        X_val = imputer.transform(X_val)\n",
        "\n",
        "        scaler = StandardScaler().fit(X_train_inner)\n",
        "        X_train_inner = scaler.transform(X_train_inner)\n",
        "        X_val = scaler.transform(X_val)\n",
        "\n",
        "        clf.fit(X_train_inner, y_train_inner)\n",
        "        best_model = clf.best_estimator_\n",
        "\n",
        "        y_pred = best_model.predict(X_val)\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        outer_scores.append(accuracy)\n",
        "\n",
        "        print(f\"Fold accuracy: {accuracy}\")\n",
        "        print(classification_report(y_val, y_pred, zero_division=0))\n",
        "\n",
        "    print(\"Average accuracy:\", np.mean(outer_scores))\n",
        "\n",
        "    # Final evaluation on the test set\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    X_train = imputer.fit_transform(X_train)\n",
        "    X_test = imputer.transform(X_test)\n",
        "\n",
        "    scaler = StandardScaler().fit(X_train)\n",
        "    X_train = scaler.transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "    best_model = clf.best_estimator_\n",
        "\n",
        "    y_pred_test = best_model.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "    print(\"Test set accuracy:\", test_accuracy)\n",
        "    print(classification_report(y_test, y_pred_test, zero_division=0))\n",
        "\n",
        "\n",
        "def nested_cross_validationKNN(features, labels, test_size=0.3, n_splits=10):\n",
        "\n",
        "    # Split data into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=test_size, random_state=42)\n",
        "\n",
        "    outer_cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    param_grid={\n",
        "    'n_neighbors': [3, 5, 7, 9, 11, 12],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski'] }\n",
        "\n",
        "    model = KNeighborsClassifier()\n",
        "    clf = GridSearchCV(estimator=model, param_grid=param_grid, cv=n_splits, scoring='f1_weighted')\n",
        "\n",
        "    outer_scores = []\n",
        "\n",
        "    for train_index, val_index in outer_cv.split(X_train, y_train):\n",
        "        X_train_inner, X_val = X_train[train_index], X_train[val_index]\n",
        "        y_train_inner, y_val = y_train[train_index], y_train[val_index]\n",
        "\n",
        "        scaler = RobustScaler().fit(X_train_inner)\n",
        "        X_train_inner = scaler.transform(X_train_inner)\n",
        "        X_val = scaler.transform(X_val)\n",
        "\n",
        "        clf.fit(X_train_inner, y_train_inner)\n",
        "        best_model = clf.best_estimator_\n",
        "\n",
        "        y_pred = best_model.predict(X_val)\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        outer_scores.append(accuracy)\n",
        "\n",
        "        print(f\"Fold accuracy: {accuracy}\")\n",
        "        print(classification_report(y_val, y_pred))\n",
        "\n",
        "    print(\"Average accuracy:\", np.mean(outer_scores))\n",
        "\n",
        "    # Final evaluation on the test set\n",
        "\n",
        "    scaler = RobustScaler().fit(X_train)\n",
        "    X_train = scaler.transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "    best_model = clf.best_estimator_\n",
        "\n",
        "\n",
        "    y_pred_test = best_model.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "    print(\"Test set accuracy:\", test_accuracy)\n",
        "    print(classification_report(y_test, y_pred_test, zero_division=0))\n",
        "\n",
        "\n",
        "file_path = '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject104.dat'\n",
        "processor = PreProcessor()\n",
        "processor.initializeDataFrame(file_path)\n",
        "processor.dataCleaning()\n",
        "processor.applyPreProcessing()\n",
        "\n",
        "subject_id = 4\n",
        "subject_df = processor.getSubjectDf(subject_id)\n",
        "\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "\n",
        "window_size = 150\n",
        "overlap = 0\n",
        "\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size, overlap, fs=100)\n",
        "\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "\n",
        "nested_cross_validationKNN(features, labels)\n",
        "nested_cross_validationRF(features,labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7Prnj2d7epV"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from scipy.stats import skew, kurtosis\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "def nested_cross_validationRF(features, labels, test_size=0.3, n_splits=5):\n",
        "    # Split data into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=test_size, random_state=42)\n",
        "\n",
        "    outer_cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    }\n",
        "\n",
        "    model = RandomForestClassifier()\n",
        "    clf = GridSearchCV(estimator=model, param_grid=param_grid, cv=n_splits, scoring='f1_weighted')\n",
        "\n",
        "    outer_scores = []\n",
        "\n",
        "    for train_index, val_index in outer_cv.split(X_train, y_train):\n",
        "        X_train_inner, X_val = X_train[train_index], X_train[val_index]\n",
        "        y_train_inner, y_val = y_train[train_index], y_train[val_index]\n",
        "\n",
        "        imputer = SimpleImputer(strategy='mean')\n",
        "        X_train_inner = imputer.fit_transform(X_train_inner)\n",
        "        X_val = imputer.transform(X_val)\n",
        "\n",
        "        scaler = StandardScaler().fit(X_train_inner)\n",
        "        X_train_inner = scaler.transform(X_train_inner)\n",
        "        X_val = scaler.transform(X_val)\n",
        "\n",
        "        clf.fit(X_train_inner, y_train_inner)\n",
        "        best_model = clf.best_estimator_\n",
        "\n",
        "        y_pred = best_model.predict(X_val)\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        outer_scores.append(accuracy)\n",
        "\n",
        "        print(f\"Fold accuracy: {accuracy}\")\n",
        "        print(classification_report(y_val, y_pred, zero_division=0))\n",
        "\n",
        "    print(\"Average accuracy:\", np.mean(outer_scores))\n",
        "\n",
        "    # Final evaluation on the test set\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    X_train = imputer.fit_transform(X_train)\n",
        "    X_test = imputer.transform(X_test)\n",
        "\n",
        "    scaler = StandardScaler().fit(X_train)\n",
        "    X_train = scaler.transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "    best_model = clf.best_estimator_\n",
        "\n",
        "    y_pred_test = best_model.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "    print(\"Test set accuracy:\", test_accuracy)\n",
        "    print(classification_report(y_test, y_pred_test, zero_division=0))\n",
        "\n",
        "\n",
        "def nested_cross_validationKNN(features, labels, test_size=0.3, n_splits=10):\n",
        "\n",
        "    # Split data into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=test_size, random_state=42)\n",
        "\n",
        "    outer_cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    param_grid={\n",
        "    'n_neighbors': [3, 5, 7, 9, 11, 12],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski'] }\n",
        "\n",
        "    model = KNeighborsClassifier()\n",
        "    clf = GridSearchCV(estimator=model, param_grid=param_grid, cv=n_splits, scoring='f1_weighted')\n",
        "\n",
        "    outer_scores = []\n",
        "\n",
        "    for train_index, val_index in outer_cv.split(X_train, y_train):\n",
        "        X_train_inner, X_val = X_train[train_index], X_train[val_index]\n",
        "        y_train_inner, y_val = y_train[train_index], y_train[val_index]\n",
        "\n",
        "        scaler = RobustScaler().fit(X_train_inner)\n",
        "        X_train_inner = scaler.transform(X_train_inner)\n",
        "        X_val = scaler.transform(X_val)\n",
        "\n",
        "        clf.fit(X_train_inner, y_train_inner)\n",
        "        best_model = clf.best_estimator_\n",
        "\n",
        "        y_pred = best_model.predict(X_val)\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        outer_scores.append(accuracy)\n",
        "\n",
        "        print(f\"Fold accuracy: {accuracy}\")\n",
        "        print(classification_report(y_val, y_pred))\n",
        "\n",
        "    print(\"Average accuracy:\", np.mean(outer_scores))\n",
        "\n",
        "    # Final evaluation on the test set\n",
        "\n",
        "    scaler = RobustScaler().fit(X_train)\n",
        "    X_train = scaler.transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "    best_model = clf.best_estimator_\n",
        "\n",
        "\n",
        "    y_pred_test = best_model.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "    print(\"Test set accuracy:\", test_accuracy)\n",
        "    print(classification_report(y_test, y_pred_test, zero_division=0))\n",
        "\n",
        "\n",
        "file_path = '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject106.dat'\n",
        "processor = PreProcessor()\n",
        "processor.initializeDataFrame(file_path)\n",
        "processor.dataCleaning()\n",
        "processor.applyPreProcessing()\n",
        "\n",
        "subject_id = 6\n",
        "subject_df = processor.getSubjectDf(subject_id)\n",
        "\n",
        "\n",
        "feature_extractor = FeatureExtraction1(subject_df, subject_id)\n",
        "\n",
        "window_size = 150\n",
        "overlap = 0\n",
        "\n",
        "features, labels = feature_extractor.applyFeatureExtraction(window_size, overlap, fs=100)\n",
        "\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "\n",
        "nested_cross_validationKNN(features, labels)\n",
        "print(\"\\n Now evluating Subject 6 on RF\")\n",
        "nested_cross_validationRF(features,labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6ql6nfwSDhE"
      },
      "source": [
        "# **Feature Extraction 2**\n",
        "\n",
        "We have also included the heartrate information and every window we extract the mean heartrate and its std deviation.\n",
        "\n",
        "Further, in this we separate all accelerometer data to body and gravity components and include both components and apply feature extraction on them. We also change window size to 300 and overlap to 0.5, same as one of the reference papers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "id": "BKVmMZ9oo4wZ",
        "outputId": "8d839d2d-9c68-49cc-91a7-c3627b71f8f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "activityID\n",
            "1     27187\n",
            "6     23575\n",
            "17    23573\n",
            "2     23480\n",
            "16    22941\n",
            "4     22253\n",
            "3     21717\n",
            "5     21265\n",
            "7     20265\n",
            "12    15890\n",
            "13    14899\n",
            "24    12912\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "features_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-6c50a780-4279-4d73-b34b-1824498728fa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>handGyro1_mean</th>\n",
              "      <th>handGyro1_std</th>\n",
              "      <th>handGyro1_skew</th>\n",
              "      <th>handGyro1_kurt</th>\n",
              "      <th>handGyro2_mean</th>\n",
              "      <th>handGyro2_std</th>\n",
              "      <th>handGyro2_skew</th>\n",
              "      <th>handGyro2_kurt</th>\n",
              "      <th>handGyro3_mean</th>\n",
              "      <th>handGyro3_std</th>\n",
              "      <th>...</th>\n",
              "      <th>body_handAcc16_1_sma</th>\n",
              "      <th>body_handAcc16_2_sma</th>\n",
              "      <th>body_handAcc16_3_sma</th>\n",
              "      <th>body_chestAcc16_1_sma</th>\n",
              "      <th>body_chestAcc16_2_sma</th>\n",
              "      <th>body_chestAcc16_3_sma</th>\n",
              "      <th>body_ankleAcc16_1_sma</th>\n",
              "      <th>body_ankleAcc16_2_sma</th>\n",
              "      <th>body_ankleAcc16_3_sma</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.137226</td>\n",
              "      <td>0.527463</td>\n",
              "      <td>0.015774</td>\n",
              "      <td>0.100983</td>\n",
              "      <td>0.350521</td>\n",
              "      <td>0.464791</td>\n",
              "      <td>0.310585</td>\n",
              "      <td>-1.051760</td>\n",
              "      <td>0.061615</td>\n",
              "      <td>0.301724</td>\n",
              "      <td>...</td>\n",
              "      <td>210.619957</td>\n",
              "      <td>262.908913</td>\n",
              "      <td>241.664229</td>\n",
              "      <td>74.184756</td>\n",
              "      <td>32.721972</td>\n",
              "      <td>44.976022</td>\n",
              "      <td>21.336608</td>\n",
              "      <td>52.368111</td>\n",
              "      <td>27.090982</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.036560</td>\n",
              "      <td>0.824434</td>\n",
              "      <td>0.080164</td>\n",
              "      <td>0.224009</td>\n",
              "      <td>0.198049</td>\n",
              "      <td>0.361774</td>\n",
              "      <td>0.103602</td>\n",
              "      <td>-0.928197</td>\n",
              "      <td>0.111461</td>\n",
              "      <td>0.423236</td>\n",
              "      <td>...</td>\n",
              "      <td>195.620804</td>\n",
              "      <td>356.556044</td>\n",
              "      <td>355.552099</td>\n",
              "      <td>63.122289</td>\n",
              "      <td>33.805038</td>\n",
              "      <td>52.297379</td>\n",
              "      <td>20.483788</td>\n",
              "      <td>30.655766</td>\n",
              "      <td>22.201224</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.128513</td>\n",
              "      <td>0.913687</td>\n",
              "      <td>0.570222</td>\n",
              "      <td>0.352048</td>\n",
              "      <td>0.086507</td>\n",
              "      <td>0.295838</td>\n",
              "      <td>-0.078255</td>\n",
              "      <td>-0.068920</td>\n",
              "      <td>0.002302</td>\n",
              "      <td>0.410864</td>\n",
              "      <td>...</td>\n",
              "      <td>225.167825</td>\n",
              "      <td>358.287608</td>\n",
              "      <td>350.745403</td>\n",
              "      <td>50.018347</td>\n",
              "      <td>29.469813</td>\n",
              "      <td>40.986112</td>\n",
              "      <td>20.432232</td>\n",
              "      <td>29.401250</td>\n",
              "      <td>20.448833</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.079574</td>\n",
              "      <td>0.605663</td>\n",
              "      <td>0.732990</td>\n",
              "      <td>2.954588</td>\n",
              "      <td>-0.077228</td>\n",
              "      <td>0.433403</td>\n",
              "      <td>-2.852270</td>\n",
              "      <td>10.781492</td>\n",
              "      <td>-0.087603</td>\n",
              "      <td>0.244531</td>\n",
              "      <td>...</td>\n",
              "      <td>157.873195</td>\n",
              "      <td>250.200390</td>\n",
              "      <td>183.683916</td>\n",
              "      <td>56.243605</td>\n",
              "      <td>30.779978</td>\n",
              "      <td>50.668413</td>\n",
              "      <td>21.818145</td>\n",
              "      <td>21.905372</td>\n",
              "      <td>19.762246</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.247295</td>\n",
              "      <td>0.524092</td>\n",
              "      <td>0.922840</td>\n",
              "      <td>5.402961</td>\n",
              "      <td>-0.659975</td>\n",
              "      <td>0.690729</td>\n",
              "      <td>-0.948733</td>\n",
              "      <td>0.277324</td>\n",
              "      <td>0.051882</td>\n",
              "      <td>0.269721</td>\n",
              "      <td>...</td>\n",
              "      <td>270.410285</td>\n",
              "      <td>185.765805</td>\n",
              "      <td>394.944860</td>\n",
              "      <td>201.979049</td>\n",
              "      <td>106.711644</td>\n",
              "      <td>194.831842</td>\n",
              "      <td>29.755081</td>\n",
              "      <td>94.431961</td>\n",
              "      <td>118.782399</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1634</th>\n",
              "      <td>0.748777</td>\n",
              "      <td>2.057120</td>\n",
              "      <td>0.526309</td>\n",
              "      <td>-0.419738</td>\n",
              "      <td>0.338619</td>\n",
              "      <td>1.812967</td>\n",
              "      <td>0.099541</td>\n",
              "      <td>-0.973624</td>\n",
              "      <td>-0.130424</td>\n",
              "      <td>2.523959</td>\n",
              "      <td>...</td>\n",
              "      <td>2859.453314</td>\n",
              "      <td>1236.549837</td>\n",
              "      <td>1422.965678</td>\n",
              "      <td>369.933178</td>\n",
              "      <td>4585.979909</td>\n",
              "      <td>1351.515500</td>\n",
              "      <td>2549.008752</td>\n",
              "      <td>3132.212002</td>\n",
              "      <td>1241.533197</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1635</th>\n",
              "      <td>0.268074</td>\n",
              "      <td>1.899629</td>\n",
              "      <td>0.497572</td>\n",
              "      <td>0.219167</td>\n",
              "      <td>1.053477</td>\n",
              "      <td>1.887499</td>\n",
              "      <td>0.027861</td>\n",
              "      <td>-0.335820</td>\n",
              "      <td>0.161941</td>\n",
              "      <td>2.129133</td>\n",
              "      <td>...</td>\n",
              "      <td>1538.320008</td>\n",
              "      <td>1011.772043</td>\n",
              "      <td>1102.774870</td>\n",
              "      <td>368.554569</td>\n",
              "      <td>2987.846173</td>\n",
              "      <td>974.767462</td>\n",
              "      <td>1912.966380</td>\n",
              "      <td>2338.698121</td>\n",
              "      <td>1080.917490</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1636</th>\n",
              "      <td>-0.269102</td>\n",
              "      <td>1.441967</td>\n",
              "      <td>-0.252770</td>\n",
              "      <td>-0.154110</td>\n",
              "      <td>0.902049</td>\n",
              "      <td>1.589032</td>\n",
              "      <td>0.989387</td>\n",
              "      <td>0.310906</td>\n",
              "      <td>0.689659</td>\n",
              "      <td>1.305696</td>\n",
              "      <td>...</td>\n",
              "      <td>771.825967</td>\n",
              "      <td>715.288114</td>\n",
              "      <td>648.810005</td>\n",
              "      <td>248.041180</td>\n",
              "      <td>1111.657012</td>\n",
              "      <td>478.109804</td>\n",
              "      <td>778.886489</td>\n",
              "      <td>1000.314711</td>\n",
              "      <td>501.791245</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1637</th>\n",
              "      <td>-0.292349</td>\n",
              "      <td>1.160550</td>\n",
              "      <td>-0.117071</td>\n",
              "      <td>-0.300492</td>\n",
              "      <td>-0.126981</td>\n",
              "      <td>0.832508</td>\n",
              "      <td>-0.200080</td>\n",
              "      <td>-0.852752</td>\n",
              "      <td>0.107850</td>\n",
              "      <td>1.029377</td>\n",
              "      <td>...</td>\n",
              "      <td>296.071671</td>\n",
              "      <td>577.943817</td>\n",
              "      <td>337.169359</td>\n",
              "      <td>176.166228</td>\n",
              "      <td>110.614638</td>\n",
              "      <td>145.109934</td>\n",
              "      <td>39.662501</td>\n",
              "      <td>60.545780</td>\n",
              "      <td>37.678900</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1638</th>\n",
              "      <td>-0.173987</td>\n",
              "      <td>0.874614</td>\n",
              "      <td>0.020416</td>\n",
              "      <td>0.259340</td>\n",
              "      <td>0.053283</td>\n",
              "      <td>0.743735</td>\n",
              "      <td>-0.698772</td>\n",
              "      <td>0.171428</td>\n",
              "      <td>-0.177132</td>\n",
              "      <td>0.860816</td>\n",
              "      <td>...</td>\n",
              "      <td>168.408242</td>\n",
              "      <td>348.994982</td>\n",
              "      <td>219.253017</td>\n",
              "      <td>65.297718</td>\n",
              "      <td>53.840630</td>\n",
              "      <td>55.074019</td>\n",
              "      <td>28.391996</td>\n",
              "      <td>56.559521</td>\n",
              "      <td>30.907860</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1639 rows  165 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c50a780-4279-4d73-b34b-1824498728fa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6c50a780-4279-4d73-b34b-1824498728fa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6c50a780-4279-4d73-b34b-1824498728fa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ad22c06b-7f79-48a4-9954-7540f5721e6c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ad22c06b-7f79-48a4-9954-7540f5721e6c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ad22c06b-7f79-48a4-9954-7540f5721e6c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      handGyro1_mean  handGyro1_std  handGyro1_skew  handGyro1_kurt  \\\n",
              "0           0.137226       0.527463        0.015774        0.100983   \n",
              "1          -0.036560       0.824434        0.080164        0.224009   \n",
              "2          -0.128513       0.913687        0.570222        0.352048   \n",
              "3           0.079574       0.605663        0.732990        2.954588   \n",
              "4           0.247295       0.524092        0.922840        5.402961   \n",
              "...              ...            ...             ...             ...   \n",
              "1634        0.748777       2.057120        0.526309       -0.419738   \n",
              "1635        0.268074       1.899629        0.497572        0.219167   \n",
              "1636       -0.269102       1.441967       -0.252770       -0.154110   \n",
              "1637       -0.292349       1.160550       -0.117071       -0.300492   \n",
              "1638       -0.173987       0.874614        0.020416        0.259340   \n",
              "\n",
              "      handGyro2_mean  handGyro2_std  handGyro2_skew  handGyro2_kurt  \\\n",
              "0           0.350521       0.464791        0.310585       -1.051760   \n",
              "1           0.198049       0.361774        0.103602       -0.928197   \n",
              "2           0.086507       0.295838       -0.078255       -0.068920   \n",
              "3          -0.077228       0.433403       -2.852270       10.781492   \n",
              "4          -0.659975       0.690729       -0.948733        0.277324   \n",
              "...              ...            ...             ...             ...   \n",
              "1634        0.338619       1.812967        0.099541       -0.973624   \n",
              "1635        1.053477       1.887499        0.027861       -0.335820   \n",
              "1636        0.902049       1.589032        0.989387        0.310906   \n",
              "1637       -0.126981       0.832508       -0.200080       -0.852752   \n",
              "1638        0.053283       0.743735       -0.698772        0.171428   \n",
              "\n",
              "      handGyro3_mean  handGyro3_std  ...  body_handAcc16_1_sma  \\\n",
              "0           0.061615       0.301724  ...            210.619957   \n",
              "1           0.111461       0.423236  ...            195.620804   \n",
              "2           0.002302       0.410864  ...            225.167825   \n",
              "3          -0.087603       0.244531  ...            157.873195   \n",
              "4           0.051882       0.269721  ...            270.410285   \n",
              "...              ...            ...  ...                   ...   \n",
              "1634       -0.130424       2.523959  ...           2859.453314   \n",
              "1635        0.161941       2.129133  ...           1538.320008   \n",
              "1636        0.689659       1.305696  ...            771.825967   \n",
              "1637        0.107850       1.029377  ...            296.071671   \n",
              "1638       -0.177132       0.860816  ...            168.408242   \n",
              "\n",
              "      body_handAcc16_2_sma  body_handAcc16_3_sma  body_chestAcc16_1_sma  \\\n",
              "0               262.908913            241.664229              74.184756   \n",
              "1               356.556044            355.552099              63.122289   \n",
              "2               358.287608            350.745403              50.018347   \n",
              "3               250.200390            183.683916              56.243605   \n",
              "4               185.765805            394.944860             201.979049   \n",
              "...                    ...                   ...                    ...   \n",
              "1634           1236.549837           1422.965678             369.933178   \n",
              "1635           1011.772043           1102.774870             368.554569   \n",
              "1636            715.288114            648.810005             248.041180   \n",
              "1637            577.943817            337.169359             176.166228   \n",
              "1638            348.994982            219.253017              65.297718   \n",
              "\n",
              "      body_chestAcc16_2_sma  body_chestAcc16_3_sma  body_ankleAcc16_1_sma  \\\n",
              "0                 32.721972              44.976022              21.336608   \n",
              "1                 33.805038              52.297379              20.483788   \n",
              "2                 29.469813              40.986112              20.432232   \n",
              "3                 30.779978              50.668413              21.818145   \n",
              "4                106.711644             194.831842              29.755081   \n",
              "...                     ...                    ...                    ...   \n",
              "1634            4585.979909            1351.515500            2549.008752   \n",
              "1635            2987.846173             974.767462            1912.966380   \n",
              "1636            1111.657012             478.109804             778.886489   \n",
              "1637             110.614638             145.109934              39.662501   \n",
              "1638              53.840630              55.074019              28.391996   \n",
              "\n",
              "      body_ankleAcc16_2_sma  body_ankleAcc16_3_sma  label  \n",
              "0                 52.368111              27.090982      1  \n",
              "1                 30.655766              22.201224      1  \n",
              "2                 29.401250              20.448833      1  \n",
              "3                 21.905372              19.762246      1  \n",
              "4                 94.431961             118.782399      1  \n",
              "...                     ...                    ...    ...  \n",
              "1634            3132.212002            1241.533197     24  \n",
              "1635            2338.698121            1080.917490     24  \n",
              "1636            1000.314711             501.791245     24  \n",
              "1637              60.545780              37.678900     24  \n",
              "1638              56.559521              30.907860     24  \n",
              "\n",
              "[1639 rows x 165 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from scipy.signal import ellip, filtfilt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import skew, kurtosis, entropy\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from scipy.signal import welch\n",
        "\n",
        "\n",
        "class FeatureExtraction2:\n",
        "    def __init__(self, subjectDf, subjectID):\n",
        "        self.dataFrame = subjectDf\n",
        "        self.subjectID = subjectID\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_time_domain_features(data, isheartrate= False):\n",
        "\n",
        "        mean = np.mean(data)\n",
        "        std_dev = np.std(data)\n",
        "\n",
        "        if not isheartrate:\n",
        "          skewness = skew(data, nan_policy='omit')\n",
        "          kurt = kurtosis(data, nan_policy='omit')\n",
        "          return mean, std_dev, skewness, kurt\n",
        "\n",
        "        else:\n",
        "          return mean, std_dev\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_frequency_domain_features(data, fs):\n",
        "        f, Pxx = welch(data, fs=fs, nperseg=len(data))\n",
        "        entropy_power = entropy(Pxx)\n",
        "        peak_power_freq = f[np.argmax(Pxx)]\n",
        "        return entropy_power, peak_power_freq\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_signal_magnitude_area(data):\n",
        "        return np.sum(np.abs(data))\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_pairwise_correlations(data):\n",
        "        correlations = pairwise_distances(data.T, metric='correlation')\n",
        "        return correlations\n",
        "\n",
        "    def apply_iir_filter(self, data, fs, cutoff=0.3, order=4):\n",
        "        b, a = ellip(order, 0.01, 100, cutoff / (0.5 * fs), btype='low')\n",
        "        filtered_data = filtfilt(b, a, data, axis=0)\n",
        "        body_component = data - filtered_data\n",
        "        return body_component, filtered_data\n",
        "\n",
        "    def generate_feature_names(self, angular_velocity_columns, acceleration_columns):\n",
        "        feature_names = []\n",
        "\n",
        "        time_domain = []\n",
        "        freq_domain = []\n",
        "        sma  = []\n",
        "\n",
        "        # Generate feature names for angular velocity columns\n",
        "        for col in angular_velocity_columns:\n",
        "            time_domain.extend([f'{col}_mean', f'{col}_std', f'{col}_skew', f'{col}_kurt'])\n",
        "            freq_domain.extend([f'{col}_entropy_power', f'{col}_peak_power_freq'])\n",
        "            sma.append(f'{col}_sma')\n",
        "\n",
        "        # manually generating feature names for heart rate column also\n",
        "\n",
        "        col = 'heartrate'\n",
        "        time_domain.extend([f'{col}_mean', f'{col}_std'])\n",
        "\n",
        "        # Generate feature names for body and gravity components of acceleration columns\n",
        "        for col in acceleration_columns:\n",
        "            body_prefix = f'body_{col}'\n",
        "            gravity_prefix = f'gravity_{col}'\n",
        "            time_domain.extend([f'{body_prefix}_mean', f'{body_prefix}_std', f'{body_prefix}_skew', f'{body_prefix}_kurt'])\n",
        "            time_domain.extend([f'{gravity_prefix}_mean', f'{gravity_prefix}_std', f'{gravity_prefix}_skew', f'{gravity_prefix}_kurt'])\n",
        "            freq_domain.extend([f'{body_prefix}_entropy_power', f'{body_prefix}_peak_power_freq'])\n",
        "            sma.append(f'{body_prefix}_sma')\n",
        "\n",
        "        feature_names = time_domain + freq_domain + sma\n",
        "\n",
        "        return feature_names\n",
        "\n",
        "    def sliding_window_feature_extraction(self, window_size=300, overlap=0.5, fs=100):\n",
        "        angular_velocity_columns = ['handGyro1', 'handGyro2', 'handGyro3',\n",
        "                                    'chestGyro1', 'chestGyro2', 'chestGyro3',\n",
        "                                    'ankleGyro1', 'ankleGyro2', 'ankleGyro3']\n",
        "        acceleration_columns = ['handAcc16_1', 'handAcc16_2', 'handAcc16_3',\n",
        "                                'chestAcc16_1', 'chestAcc16_2', 'chestAcc16_3',\n",
        "                                'ankleAcc16_1', 'ankleAcc16_2', 'ankleAcc16_3']\n",
        "\n",
        "        heart_rate_column = ['heartrate']\n",
        "\n",
        "        all_features = []\n",
        "        all_labels = []\n",
        "\n",
        "        stride = int(window_size * (1 - overlap))\n",
        "        feature_names = self.generate_feature_names(angular_velocity_columns, acceleration_columns)\n",
        "\n",
        "        for start in range(0, len(self.dataFrame) - window_size + 1, stride):\n",
        "            window_data = self.dataFrame.loc[start:start + window_size - 1, angular_velocity_columns + acceleration_columns + heart_rate_column]\n",
        "            labels = self.dataFrame.loc[start:start + window_size - 1, 'activityID']\n",
        "\n",
        "            # Ensure the window contains only one activity\n",
        "            if labels.nunique() == 1:\n",
        "                label = labels.iloc[0]\n",
        "\n",
        "                # Apply IIR filter to separate body and gravity components\n",
        "                body_acc = []\n",
        "                gravity_acc = []\n",
        "\n",
        "                for col in acceleration_columns:\n",
        "                    body, gravity = self.apply_iir_filter(window_data[col].values, fs)\n",
        "                    body_acc.append(body)\n",
        "                    gravity_acc.append(gravity)\n",
        "\n",
        "                body_acc = np.array(body_acc).T\n",
        "                gravity_acc = np.array(gravity_acc).T\n",
        "\n",
        "                # Extract features from gyroscope, body acceleration, and gravity acceleration signals\n",
        "                time_domain_features = []\n",
        "                freq_domain_features = []\n",
        "                sma_values = []\n",
        "                pairwise_corr_values = []\n",
        "\n",
        "                for col in angular_velocity_columns:\n",
        "                    time_domain_features.extend(self.compute_time_domain_features(window_data[col]))\n",
        "                    freq_domain_features.extend(self.compute_frequency_domain_features(window_data[col], fs))\n",
        "                    sma_values.append(self.compute_signal_magnitude_area(window_data[col]))\n",
        "\n",
        "                time_domain_features.extend(self.compute_time_domain_features(window_data[heart_rate_column[0]], isheartrate= True))\n",
        "\n",
        "                for idx in range(body_acc.shape[1]):\n",
        "                    body = body_acc[:, idx]\n",
        "                    gravity = gravity_acc[:, idx]\n",
        "\n",
        "                    time_domain_features.extend(self.compute_time_domain_features(body))\n",
        "\n",
        "                    time_domain_features.extend(self.compute_time_domain_features(gravity))\n",
        "\n",
        "                    freq_domain_features.extend(self.compute_frequency_domain_features(body, fs))\n",
        "\n",
        "                    sma_values.append(self.compute_signal_magnitude_area(body))\n",
        "\n",
        "\n",
        "                features = np.concatenate([time_domain_features, freq_domain_features, sma_values])\n",
        "                all_features.append(features)\n",
        "                all_labels.append(label)\n",
        "\n",
        "        return np.array(all_features), np.array(all_labels), feature_names\n",
        "\n",
        "    def applyFeatureExtraction(self, window_size, overlap, fs):\n",
        "        features, labels, feature_names = self.sliding_window_feature_extraction(window_size=window_size, overlap=overlap, fs=fs)\n",
        "        return features, labels, feature_names\n",
        "\n",
        "    def features_to_dataframe(self, features, labels, feature_names):\n",
        "        features_df = pd.DataFrame(features, columns=feature_names)\n",
        "        labels_df = pd.DataFrame(labels, columns=['label'])\n",
        "        combined_df = pd.concat([features_df, labels_df], axis=1)\n",
        "        return combined_df\n",
        "\n",
        "\n",
        "# Usage example\n",
        "file_path = '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject101.dat'\n",
        "processor = PreProcessor()\n",
        "processor.initializeDataFrame(file_path)\n",
        "processor.dataCleaning()\n",
        "processor.applyPreProcessing()\n",
        "\n",
        "\n",
        "print(processor.dataFrame['activityID'].value_counts())\n",
        "\n",
        "subject_id = 1\n",
        "subject_df = processor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction2(subject_df, subject_id)\n",
        "features, labels, feature_names = feature_extractor.applyFeatureExtraction(300, 0.5, 100)\n",
        "features_df = feature_extractor.features_to_dataframe(features, labels, feature_names)\n",
        "\n",
        "\n",
        "features_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRZXpiBXXEo2",
        "outputId": "6273713f-01b5-4513-ea2c-e110cbf240d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold accuracy: 0.8521739130434782\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.85      0.88        13\n",
            "           2       1.00      0.70      0.82        10\n",
            "           3       0.57      0.80      0.67        10\n",
            "           4       1.00      0.80      0.89        10\n",
            "           5       0.92      1.00      0.96        11\n",
            "           6       1.00      0.80      0.89        10\n",
            "           7       0.80      0.89      0.84         9\n",
            "          12       0.86      0.75      0.80         8\n",
            "          13       0.88      0.88      0.88         8\n",
            "          16       0.90      0.90      0.90        10\n",
            "          17       0.69      0.90      0.78        10\n",
            "          24       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.85       115\n",
            "   macro avg       0.88      0.86      0.86       115\n",
            "weighted avg       0.88      0.85      0.86       115\n",
            "\n",
            "Fold accuracy: 0.8695652173913043\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.77      0.83        13\n",
            "           2       0.73      0.80      0.76        10\n",
            "           3       0.80      0.80      0.80        10\n",
            "           4       1.00      0.90      0.95        10\n",
            "           5       1.00      0.82      0.90        11\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      0.89      0.94         9\n",
            "          12       0.64      0.88      0.74         8\n",
            "          13       1.00      0.75      0.86         8\n",
            "          16       0.92      1.00      0.96        11\n",
            "          17       0.69      1.00      0.82         9\n",
            "          24       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.87       115\n",
            "   macro avg       0.89      0.87      0.87       115\n",
            "weighted avg       0.89      0.87      0.87       115\n",
            "\n",
            "Fold accuracy: 0.8956521739130435\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.86      0.92      0.89        13\n",
            "           2       1.00      0.70      0.82        10\n",
            "           3       0.62      1.00      0.77        10\n",
            "           4       0.90      0.90      0.90        10\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       0.92      1.00      0.96        11\n",
            "           7       0.71      0.62      0.67         8\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.88      0.93         8\n",
            "          16       1.00      0.91      0.95        11\n",
            "          17       1.00      1.00      1.00         9\n",
            "          24       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.90       115\n",
            "   macro avg       0.92      0.89      0.90       115\n",
            "weighted avg       0.91      0.90      0.90       115\n",
            "\n",
            "Fold accuracy: 0.8521739130434782\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.80      0.86      0.83        14\n",
            "           2       0.83      0.50      0.62        10\n",
            "           3       0.75      0.90      0.82        10\n",
            "           4       0.89      0.80      0.84        10\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       0.86      0.75      0.80         8\n",
            "          12       0.80      1.00      0.89         8\n",
            "          13       0.89      1.00      0.94         8\n",
            "          16       0.90      0.82      0.86        11\n",
            "          17       0.73      0.89      0.80         9\n",
            "          24       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.85       115\n",
            "   macro avg       0.86      0.86      0.85       115\n",
            "weighted avg       0.86      0.85      0.85       115\n",
            "\n",
            "Fold accuracy: 0.8956521739130435\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.87      0.93      0.90        14\n",
            "           2       0.83      0.50      0.62        10\n",
            "           3       0.64      0.90      0.75        10\n",
            "           4       0.91      1.00      0.95        10\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       1.00      0.88      0.93         8\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       0.86      0.75      0.80         8\n",
            "          16       1.00      1.00      1.00        11\n",
            "          17       0.90      1.00      0.95         9\n",
            "          24       0.83      0.83      0.83         6\n",
            "\n",
            "    accuracy                           0.90       115\n",
            "   macro avg       0.90      0.89      0.89       115\n",
            "weighted avg       0.90      0.90      0.89       115\n",
            "\n",
            "Fold accuracy: 0.9391304347826087\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.71      0.83        14\n",
            "           2       1.00      1.00      1.00        11\n",
            "           3       0.71      1.00      0.83        10\n",
            "           4       1.00      0.91      0.95        11\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       1.00      0.88      0.93         8\n",
            "          12       0.88      1.00      0.93         7\n",
            "          13       0.88      1.00      0.93         7\n",
            "          16       1.00      1.00      1.00        11\n",
            "          17       0.90      1.00      0.95         9\n",
            "          24       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.94       115\n",
            "   macro avg       0.95      0.95      0.94       115\n",
            "weighted avg       0.95      0.94      0.94       115\n",
            "\n",
            "Fold accuracy: 0.9217391304347826\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.86      0.86      0.86        14\n",
            "           2       0.89      0.73      0.80        11\n",
            "           3       0.82      0.90      0.86        10\n",
            "           4       1.00      1.00      1.00        11\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      1.00      1.00         8\n",
            "          12       0.86      0.86      0.86         7\n",
            "          13       0.86      0.86      0.86         7\n",
            "          16       1.00      1.00      1.00        11\n",
            "          17       0.82      1.00      0.90         9\n",
            "          24       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.92       115\n",
            "   macro avg       0.92      0.92      0.92       115\n",
            "weighted avg       0.92      0.92      0.92       115\n",
            "\n",
            "Fold accuracy: 0.9210526315789473\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.93      0.96        14\n",
            "           2       0.70      0.64      0.67        11\n",
            "           3       0.75      0.90      0.82        10\n",
            "           4       0.92      1.00      0.96        11\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       1.00      1.00      1.00         8\n",
            "          12       0.88      1.00      0.93         7\n",
            "          13       0.88      1.00      0.93         7\n",
            "          16       1.00      0.80      0.89        10\n",
            "          17       1.00      1.00      1.00        10\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.92       114\n",
            "   macro avg       0.93      0.93      0.93       114\n",
            "weighted avg       0.93      0.92      0.92       114\n",
            "\n",
            "Fold accuracy: 0.8508771929824561\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.86      0.92      0.89        13\n",
            "           2       0.80      0.36      0.50        11\n",
            "           3       0.64      1.00      0.78         9\n",
            "           4       1.00      0.91      0.95        11\n",
            "           5       1.00      0.82      0.90        11\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       0.90      1.00      0.95         9\n",
            "          12       0.83      0.71      0.77         7\n",
            "          13       0.78      0.88      0.82         8\n",
            "          16       0.89      0.80      0.84        10\n",
            "          17       0.71      1.00      0.83        10\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.85       114\n",
            "   macro avg       0.87      0.86      0.85       114\n",
            "weighted avg       0.87      0.85      0.84       114\n",
            "\n",
            "Fold accuracy: 0.868421052631579\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.85      0.88        13\n",
            "           2       0.71      0.50      0.59        10\n",
            "           3       0.62      0.89      0.73         9\n",
            "           4       0.92      1.00      0.96        11\n",
            "           5       0.92      1.00      0.96        11\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      0.89      0.94         9\n",
            "          12       0.70      0.88      0.78         8\n",
            "          13       0.86      0.75      0.80         8\n",
            "          16       1.00      1.00      1.00        10\n",
            "          17       1.00      0.80      0.89        10\n",
            "          24       0.80      0.80      0.80         5\n",
            "\n",
            "    accuracy                           0.87       114\n",
            "   macro avg       0.87      0.86      0.86       114\n",
            "weighted avg       0.88      0.87      0.87       114\n",
            "\n",
            "Average accuracy: 0.8866437833714722\n",
            "Test set accuracy: 0.9329268292682927\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.98      0.89      0.93        45\n",
            "           2       0.93      0.74      0.82        50\n",
            "           3       0.83      0.96      0.89        45\n",
            "           4       1.00      0.98      0.99        42\n",
            "           5       1.00      0.97      0.98        30\n",
            "           6       1.00      0.98      0.99        54\n",
            "           7       0.96      0.98      0.97        49\n",
            "          12       0.86      0.92      0.89        26\n",
            "          13       0.90      1.00      0.95        18\n",
            "          16       1.00      0.96      0.98        45\n",
            "          17       0.83      0.95      0.89        61\n",
            "          24       1.00      0.93      0.96        27\n",
            "\n",
            "    accuracy                           0.93       492\n",
            "   macro avg       0.94      0.94      0.94       492\n",
            "weighted avg       0.94      0.93      0.93       492\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nested_cross_validationKNN(features, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muIvpe78XIlp",
        "outputId": "64aeea98-d433-4b3b-880a-49d24f605f1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold accuracy: 0.908695652173913\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.78      0.88        27\n",
            "           2       1.00      1.00      1.00        21\n",
            "           3       0.83      1.00      0.91        20\n",
            "           4       1.00      0.90      0.95        21\n",
            "           5       1.00      0.91      0.95        22\n",
            "           6       1.00      0.90      0.95        20\n",
            "           7       1.00      0.88      0.94        17\n",
            "          12       0.86      0.80      0.83        15\n",
            "          13       0.92      0.80      0.86        15\n",
            "          16       0.84      1.00      0.91        21\n",
            "          17       0.66      1.00      0.79        19\n",
            "          24       1.00      0.92      0.96        12\n",
            "\n",
            "    accuracy                           0.91       230\n",
            "   macro avg       0.93      0.91      0.91       230\n",
            "weighted avg       0.93      0.91      0.91       230\n",
            "\n",
            "Fold accuracy: 0.908695652173913\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.90      0.96      0.93        27\n",
            "           2       1.00      0.86      0.92        21\n",
            "           3       0.75      0.90      0.82        20\n",
            "           4       0.94      0.81      0.87        21\n",
            "           5       1.00      0.91      0.95        22\n",
            "           6       1.00      1.00      1.00        20\n",
            "           7       1.00      0.82      0.90        17\n",
            "          12       0.88      0.93      0.90        15\n",
            "          13       0.78      0.93      0.85        15\n",
            "          16       0.91      0.91      0.91        22\n",
            "          17       0.86      1.00      0.92        18\n",
            "          24       1.00      0.83      0.91        12\n",
            "\n",
            "    accuracy                           0.91       230\n",
            "   macro avg       0.92      0.91      0.91       230\n",
            "weighted avg       0.92      0.91      0.91       230\n",
            "\n",
            "Fold accuracy: 0.9606986899563319\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.96      0.98        27\n",
            "           2       1.00      1.00      1.00        21\n",
            "           3       0.87      1.00      0.93        20\n",
            "           4       1.00      0.95      0.98        21\n",
            "           5       1.00      1.00      1.00        22\n",
            "           6       0.95      1.00      0.98        21\n",
            "           7       1.00      0.75      0.86        16\n",
            "          12       1.00      1.00      1.00        15\n",
            "          13       0.81      0.87      0.84        15\n",
            "          16       0.95      1.00      0.98        21\n",
            "          17       0.95      1.00      0.97        19\n",
            "          24       1.00      0.91      0.95        11\n",
            "\n",
            "    accuracy                           0.96       229\n",
            "   macro avg       0.96      0.95      0.96       229\n",
            "weighted avg       0.96      0.96      0.96       229\n",
            "\n",
            "Fold accuracy: 0.9694323144104804\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        27\n",
            "           2       1.00      0.95      0.98        21\n",
            "           3       0.90      1.00      0.95        19\n",
            "           4       1.00      1.00      1.00        21\n",
            "           5       1.00      1.00      1.00        22\n",
            "           6       1.00      0.95      0.97        20\n",
            "           7       0.89      1.00      0.94        17\n",
            "          12       0.93      0.93      0.93        15\n",
            "          13       0.93      0.88      0.90        16\n",
            "          16       1.00      0.95      0.98        21\n",
            "          17       0.95      1.00      0.97        19\n",
            "          24       1.00      0.91      0.95        11\n",
            "\n",
            "    accuracy                           0.97       229\n",
            "   macro avg       0.97      0.96      0.97       229\n",
            "weighted avg       0.97      0.97      0.97       229\n",
            "\n",
            "Fold accuracy: 0.9126637554585153\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.89      0.94        27\n",
            "           2       0.94      0.85      0.89        20\n",
            "           3       0.73      1.00      0.84        19\n",
            "           4       0.91      1.00      0.95        21\n",
            "           5       1.00      0.91      0.95        22\n",
            "           6       1.00      0.90      0.95        20\n",
            "           7       0.94      0.94      0.94        17\n",
            "          12       0.92      0.69      0.79        16\n",
            "          13       0.93      0.88      0.90        16\n",
            "          16       0.84      1.00      0.91        21\n",
            "          17       0.86      0.95      0.90        19\n",
            "          24       1.00      0.91      0.95        11\n",
            "\n",
            "    accuracy                           0.91       229\n",
            "   macro avg       0.92      0.91      0.91       229\n",
            "weighted avg       0.92      0.91      0.91       229\n",
            "\n",
            "Average accuracy: 0.9320372128346307\n",
            "Test set accuracy: 0.9552845528455285\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.98      1.00      0.99        45\n",
            "           2       1.00      0.90      0.95        50\n",
            "           3       0.96      0.96      0.96        45\n",
            "           4       1.00      0.98      0.99        42\n",
            "           5       1.00      0.90      0.95        30\n",
            "           6       0.98      0.98      0.98        54\n",
            "           7       1.00      0.98      0.99        49\n",
            "          12       0.92      0.88      0.90        26\n",
            "          13       0.90      1.00      0.95        18\n",
            "          16       0.91      0.96      0.93        45\n",
            "          17       0.86      0.97      0.91        61\n",
            "          24       1.00      0.93      0.96        27\n",
            "\n",
            "    accuracy                           0.96       492\n",
            "   macro avg       0.96      0.95      0.95       492\n",
            "weighted avg       0.96      0.96      0.96       492\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nested_cross_validationRF(features, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgMI6A3NeTaa"
      },
      "source": [
        "## Evaluating the second Feature Extraction on another subject (4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Jzb39RO6zkr",
        "outputId": "c07caadc-0eba-4633-9d61-74160ffd325e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame still contains some NAN values\n"
          ]
        }
      ],
      "source": [
        "# Usage example\n",
        "file_path = '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject104.dat'\n",
        "processor = PreProcessor()\n",
        "processor.initializeDataFrame(file_path)\n",
        "processor.dataCleaning()\n",
        "processor.applyPreProcessing()\n",
        "\n",
        "subject_id = 4\n",
        "subject_df = processor.getSubjectDf(subject_id)\n",
        "\n",
        "\n",
        "feature_extractor = FeatureExtraction2(subject_df, subject_id)\n",
        "features, labels, feature_names = feature_extractor.applyFeatureExtraction(300, 0.5, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erdptFVleR-Y",
        "outputId": "44360ade-f769-451f-a62f-4ee637aa4e08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold accuracy: 0.9439252336448598\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.91      0.95        11\n",
            "           2       0.80      1.00      0.89        12\n",
            "           3       0.90      0.82      0.86        11\n",
            "           4       1.00      1.00      1.00        14\n",
            "           6       0.91      1.00      0.95        10\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.89      0.89      0.89         9\n",
            "          17       1.00      0.92      0.96        12\n",
            "\n",
            "    accuracy                           0.94       107\n",
            "   macro avg       0.95      0.94      0.94       107\n",
            "weighted avg       0.95      0.94      0.94       107\n",
            "\n",
            "Fold accuracy: 0.9158878504672897\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.82      0.90        11\n",
            "           2       0.92      0.92      0.92        12\n",
            "           3       0.85      1.00      0.92        11\n",
            "           4       0.87      0.93      0.90        14\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       0.92      0.92      0.92        13\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       0.78      0.78      0.78         9\n",
            "          17       0.92      1.00      0.96        12\n",
            "\n",
            "    accuracy                           0.92       107\n",
            "   macro avg       0.93      0.91      0.91       107\n",
            "weighted avg       0.92      0.92      0.91       107\n",
            "\n",
            "Fold accuracy: 0.8785046728971962\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.92      0.96        12\n",
            "           2       1.00      0.75      0.86        12\n",
            "           3       0.64      0.82      0.72        11\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       0.90      0.90      0.90        10\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       0.89      1.00      0.94         8\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.86      0.60      0.71        10\n",
            "          17       0.71      1.00      0.83        12\n",
            "\n",
            "    accuracy                           0.88       107\n",
            "   macro avg       0.90      0.88      0.88       107\n",
            "weighted avg       0.90      0.88      0.88       107\n",
            "\n",
            "Fold accuracy: 0.9339622641509434\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.92      0.92      0.92        12\n",
            "           3       0.71      1.00      0.83        10\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       1.00      0.80      0.89        10\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.89      0.80      0.84        10\n",
            "          17       0.92      0.92      0.92        12\n",
            "\n",
            "    accuracy                           0.93       106\n",
            "   macro avg       0.94      0.93      0.94       106\n",
            "weighted avg       0.94      0.93      0.94       106\n",
            "\n",
            "Fold accuracy: 0.9150943396226415\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        12\n",
            "           2       0.91      0.83      0.87        12\n",
            "           3       0.64      0.90      0.75        10\n",
            "           4       0.93      1.00      0.96        13\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       1.00      0.80      0.89        10\n",
            "          17       0.85      0.92      0.88        12\n",
            "\n",
            "    accuracy                           0.92       106\n",
            "   macro avg       0.93      0.91      0.92       106\n",
            "weighted avg       0.93      0.92      0.92       106\n",
            "\n",
            "Fold accuracy: 0.8867924528301887\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.91        12\n",
            "           2       0.82      0.75      0.78        12\n",
            "           3       0.67      0.91      0.77        11\n",
            "           4       1.00      1.00      1.00        14\n",
            "           6       1.00      0.80      0.89        10\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.88      0.88      0.88         8\n",
            "          13       1.00      0.83      0.91         6\n",
            "          16       0.90      0.90      0.90        10\n",
            "          17       0.77      0.91      0.83        11\n",
            "\n",
            "    accuracy                           0.89       106\n",
            "   macro avg       0.90      0.88      0.89       106\n",
            "weighted avg       0.90      0.89      0.89       106\n",
            "\n",
            "Fold accuracy: 0.839622641509434\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.82      0.90        11\n",
            "           2       0.67      0.83      0.74        12\n",
            "           3       0.54      0.64      0.58        11\n",
            "           4       1.00      1.00      1.00        14\n",
            "           6       0.90      0.90      0.90        10\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.75      0.86         8\n",
            "          13       0.75      0.50      0.60         6\n",
            "          16       0.88      0.70      0.78        10\n",
            "          17       0.79      1.00      0.88        11\n",
            "\n",
            "    accuracy                           0.84       106\n",
            "   macro avg       0.85      0.81      0.82       106\n",
            "weighted avg       0.86      0.84      0.84       106\n",
            "\n",
            "Fold accuracy: 0.9339622641509434\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        11\n",
            "           2       1.00      0.82      0.90        11\n",
            "           3       0.82      0.82      0.82        11\n",
            "           4       0.93      1.00      0.97        14\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.83      0.91         6\n",
            "          16       0.83      1.00      0.91        10\n",
            "          17       0.86      1.00      0.92        12\n",
            "\n",
            "    accuracy                           0.93       106\n",
            "   macro avg       0.94      0.93      0.93       106\n",
            "weighted avg       0.94      0.93      0.93       106\n",
            "\n",
            "Fold accuracy: 0.9245283018867925\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.91      0.95        11\n",
            "           2       0.71      0.91      0.80        11\n",
            "           3       0.73      0.73      0.73        11\n",
            "           4       0.93      1.00      0.97        14\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      0.85      0.92        13\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       1.00      1.00      1.00        10\n",
            "          17       1.00      0.92      0.96        12\n",
            "\n",
            "    accuracy                           0.92       106\n",
            "   macro avg       0.94      0.93      0.93       106\n",
            "weighted avg       0.93      0.92      0.93       106\n",
            "\n",
            "Fold accuracy: 0.8773584905660378\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.82      0.90        11\n",
            "           2       0.79      1.00      0.88        11\n",
            "           3       0.90      0.82      0.86        11\n",
            "           4       1.00      1.00      1.00        14\n",
            "           6       0.90      0.90      0.90        10\n",
            "           7       0.93      1.00      0.96        13\n",
            "          12       0.75      0.86      0.80         7\n",
            "          13       0.83      0.71      0.77         7\n",
            "          16       0.86      0.60      0.71        10\n",
            "          17       0.79      0.92      0.85        12\n",
            "\n",
            "    accuracy                           0.88       106\n",
            "   macro avg       0.87      0.86      0.86       106\n",
            "weighted avg       0.88      0.88      0.87       106\n",
            "\n",
            "Average accuracy: 0.9049638511726329\n",
            "Test set accuracy: 0.918859649122807\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.97      0.99        38\n",
            "           2       0.91      0.80      0.85        51\n",
            "           3       0.71      0.91      0.80        55\n",
            "           4       0.99      0.96      0.97        73\n",
            "           6       1.00      0.96      0.98        49\n",
            "           7       1.00      0.98      0.99        56\n",
            "          12       1.00      0.83      0.91        29\n",
            "          13       0.96      0.92      0.94        25\n",
            "          16       1.00      0.82      0.90        34\n",
            "          17       0.80      0.96      0.87        46\n",
            "\n",
            "    accuracy                           0.92       456\n",
            "   macro avg       0.94      0.91      0.92       456\n",
            "weighted avg       0.93      0.92      0.92       456\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nested_cross_validationKNN(features, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Bz1iLwDeW7y",
        "outputId": "fd199512-9714-4c5a-a6b1-d646ef601e8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold accuracy: 0.9483568075117371\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.87      0.93        23\n",
            "           2       1.00      0.96      0.98        24\n",
            "           3       0.85      1.00      0.92        22\n",
            "           4       1.00      0.96      0.98        28\n",
            "           6       1.00      1.00      1.00        20\n",
            "           7       1.00      0.96      0.98        25\n",
            "          12       1.00      0.94      0.97        16\n",
            "          13       1.00      0.85      0.92        13\n",
            "          16       0.75      0.95      0.84        19\n",
            "          17       0.96      0.96      0.96        23\n",
            "\n",
            "    accuracy                           0.95       213\n",
            "   macro avg       0.96      0.94      0.95       213\n",
            "weighted avg       0.96      0.95      0.95       213\n",
            "\n",
            "Fold accuracy: 0.9389671361502347\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        22\n",
            "           2       0.88      0.92      0.90        24\n",
            "           3       0.83      0.86      0.84        22\n",
            "           4       1.00      1.00      1.00        28\n",
            "           6       1.00      0.90      0.95        20\n",
            "           7       1.00      0.88      0.94        26\n",
            "          12       0.94      1.00      0.97        16\n",
            "          13       1.00      0.92      0.96        13\n",
            "          16       1.00      0.89      0.94        19\n",
            "          17       0.82      1.00      0.90        23\n",
            "\n",
            "    accuracy                           0.94       213\n",
            "   macro avg       0.95      0.94      0.94       213\n",
            "weighted avg       0.94      0.94      0.94       213\n",
            "\n",
            "Fold accuracy: 0.9624413145539906\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.91      0.95        23\n",
            "           2       1.00      0.96      0.98        23\n",
            "           3       0.81      0.95      0.88        22\n",
            "           4       1.00      1.00      1.00        27\n",
            "           6       1.00      0.95      0.97        20\n",
            "           7       1.00      1.00      1.00        25\n",
            "          12       1.00      0.94      0.97        16\n",
            "          13       1.00      1.00      1.00        13\n",
            "          16       0.91      1.00      0.95        20\n",
            "          17       0.96      0.92      0.94        24\n",
            "\n",
            "    accuracy                           0.96       213\n",
            "   macro avg       0.97      0.96      0.96       213\n",
            "weighted avg       0.97      0.96      0.96       213\n",
            "\n",
            "Fold accuracy: 0.9481132075471698\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.96      0.98        23\n",
            "           2       1.00      0.91      0.95        23\n",
            "           3       0.75      1.00      0.86        21\n",
            "           4       1.00      0.96      0.98        27\n",
            "           6       1.00      1.00      1.00        20\n",
            "           7       1.00      1.00      1.00        25\n",
            "          12       1.00      0.87      0.93        15\n",
            "          13       0.91      0.71      0.80        14\n",
            "          16       0.90      0.95      0.93        20\n",
            "          17       0.96      1.00      0.98        24\n",
            "\n",
            "    accuracy                           0.95       212\n",
            "   macro avg       0.95      0.94      0.94       212\n",
            "weighted avg       0.96      0.95      0.95       212\n",
            "\n",
            "Fold accuracy: 0.9481132075471698\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.96      0.98        23\n",
            "           2       1.00      0.91      0.95        23\n",
            "           3       0.81      1.00      0.89        21\n",
            "           4       1.00      1.00      1.00        27\n",
            "           6       1.00      0.95      0.97        20\n",
            "           7       1.00      0.96      0.98        25\n",
            "          12       1.00      0.93      0.97        15\n",
            "          13       0.93      0.93      0.93        14\n",
            "          16       0.90      0.90      0.90        20\n",
            "          17       0.88      0.92      0.90        24\n",
            "\n",
            "    accuracy                           0.95       212\n",
            "   macro avg       0.95      0.95      0.95       212\n",
            "weighted avg       0.95      0.95      0.95       212\n",
            "\n",
            "Average accuracy: 0.9491983346620604\n",
            "Test set accuracy: 0.9627192982456141\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        38\n",
            "           2       1.00      0.96      0.98        51\n",
            "           3       0.86      1.00      0.92        55\n",
            "           4       1.00      0.96      0.98        73\n",
            "           6       1.00      0.98      0.99        49\n",
            "           7       1.00      0.98      0.99        56\n",
            "          12       1.00      0.86      0.93        29\n",
            "          13       1.00      0.92      0.96        25\n",
            "          16       0.85      0.97      0.90        34\n",
            "          17       0.96      0.93      0.95        46\n",
            "\n",
            "    accuracy                           0.96       456\n",
            "   macro avg       0.97      0.96      0.96       456\n",
            "weighted avg       0.97      0.96      0.96       456\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nested_cross_validationRF(features, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfl7eLpbfkr1"
      },
      "source": [
        "# **Feature Extraction 3**\n",
        "\n",
        "Everything is same as Feature Extraction 2 but we do not include the gravity component or perform any feature extraction on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LR4PmkKfk9R",
        "outputId": "3a9e51b1-3abe-4f9f-a112-ad51fa498e2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "activityID\n",
            "1     27187\n",
            "6     23575\n",
            "17    23573\n",
            "2     23480\n",
            "16    22941\n",
            "4     22253\n",
            "3     21717\n",
            "5     21265\n",
            "7     20265\n",
            "12    15890\n",
            "13    14899\n",
            "24    12912\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from scipy.signal import ellip, filtfilt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import skew, kurtosis, entropy\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from scipy.signal import welch\n",
        "\n",
        "\n",
        "class FeatureExtraction3:\n",
        "    def __init__(self, subjectDf, subjectID):\n",
        "        self.dataFrame = subjectDf\n",
        "        self.subjectID = subjectID\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_time_domain_features(data, isheartrate= False):\n",
        "\n",
        "\n",
        "        mean = np.mean(data)\n",
        "        std_dev = np.std(data)\n",
        "\n",
        "        if not isheartrate:\n",
        "          skewness = skew(data, nan_policy='omit')\n",
        "          kurt = kurtosis(data, nan_policy='omit')\n",
        "          return mean, std_dev, skewness, kurt\n",
        "\n",
        "        else:\n",
        "          return mean, std_dev\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_frequency_domain_features(data, fs):\n",
        "        f, Pxx = welch(data, fs=fs, nperseg=len(data))\n",
        "        entropy_power = entropy(Pxx)\n",
        "        peak_power_freq = f[np.argmax(Pxx)]\n",
        "        return entropy_power, peak_power_freq\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_signal_magnitude_area(data):\n",
        "        return np.sum(np.abs(data))\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_pairwise_correlations(data):\n",
        "        correlations = pairwise_distances(data.T, metric='correlation')\n",
        "        return correlations\n",
        "\n",
        "    def apply_iir_filter(self, data, fs, cutoff=0.3, order=4):\n",
        "        b, a = ellip(order, 0.01, 100, cutoff / (0.5 * fs), btype='low')\n",
        "        filtered_data = filtfilt(b, a, data, axis=0)\n",
        "        body_component = data - filtered_data\n",
        "        return body_component\n",
        "\n",
        "    def generate_feature_names(self, angular_velocity_columns, acceleration_columns):\n",
        "        feature_names = []\n",
        "\n",
        "        time_domain = []\n",
        "        freq_domain = []\n",
        "        sma  = []\n",
        "\n",
        "        # Generate feature names for angular velocity columns\n",
        "        for col in angular_velocity_columns:\n",
        "            time_domain.extend([f'{col}_mean', f'{col}_std', f'{col}_skew', f'{col}_kurt'])\n",
        "            freq_domain.extend([f'{col}_entropy_power', f'{col}_peak_power_freq'])\n",
        "            sma.append(f'{col}_sma')\n",
        "\n",
        "        # manually generating feature names for heart rate column also\n",
        "\n",
        "        col = 'heartrate'\n",
        "        time_domain.extend([f'{col}_mean', f'{col}_std'])\n",
        "\n",
        "        # Generate feature names for body and gravity components of acceleration columns\n",
        "        for col in acceleration_columns:\n",
        "            body_prefix = f'body_{col}'\n",
        "            time_domain.extend([f'{body_prefix}_mean', f'{body_prefix}_std', f'{body_prefix}_skew', f'{body_prefix}_kurt'])\n",
        "            freq_domain.extend([f'{body_prefix}_entropy_power', f'{body_prefix}_peak_power_freq'])\n",
        "            sma.append(f'{body_prefix}_sma')\n",
        "\n",
        "        feature_names = time_domain + freq_domain + sma\n",
        "\n",
        "        return feature_names\n",
        "\n",
        "    def sliding_window_feature_extraction(self, window_size=300, overlap=0.5, fs=100):\n",
        "        angular_velocity_columns = ['handGyro1', 'handGyro2', 'handGyro3',\n",
        "                                    'chestGyro1', 'chestGyro2', 'chestGyro3',\n",
        "                                    'ankleGyro1', 'ankleGyro2', 'ankleGyro3']\n",
        "        acceleration_columns = ['handAcc16_1', 'handAcc16_2', 'handAcc16_3',\n",
        "                                'chestAcc16_1', 'chestAcc16_2', 'chestAcc16_3',\n",
        "                                'ankleAcc16_1', 'ankleAcc16_2', 'ankleAcc16_3']\n",
        "\n",
        "        heart_rate_column = ['heartrate']\n",
        "\n",
        "        all_features = []\n",
        "        all_labels = []\n",
        "\n",
        "        stride = int(window_size * (1 - overlap))\n",
        "        feature_names = self.generate_feature_names(angular_velocity_columns, acceleration_columns)\n",
        "\n",
        "        for start in range(0, len(self.dataFrame) - window_size + 1, stride):\n",
        "            window_data = self.dataFrame.loc[start:start + window_size - 1, angular_velocity_columns + acceleration_columns + heart_rate_column]\n",
        "            labels = self.dataFrame.loc[start:start + window_size - 1, 'activityID']\n",
        "\n",
        "            # Ensure the window contains only one activity\n",
        "            if labels.nunique() == 1:\n",
        "                label = labels.iloc[0]\n",
        "\n",
        "                # Apply IIR filter to separate body and gravity components\n",
        "                body_acc = []\n",
        "\n",
        "                for col in acceleration_columns:\n",
        "                    body = self.apply_iir_filter(window_data[col].values, fs)\n",
        "                    body_acc.append(body)\n",
        "\n",
        "                body_acc = np.array(body_acc).T\n",
        "\n",
        "\n",
        "                # Extract features from gyroscope, body acceleration, and gravity acceleration signals\n",
        "                time_domain_features = []\n",
        "                freq_domain_features = []\n",
        "                sma_values = []\n",
        "                pairwise_corr_values = []\n",
        "\n",
        "                for col in angular_velocity_columns:\n",
        "                    time_domain_features.extend(self.compute_time_domain_features(window_data[col]))\n",
        "                    freq_domain_features.extend(self.compute_frequency_domain_features(window_data[col], fs))\n",
        "                    sma_values.append(self.compute_signal_magnitude_area(window_data[col]))\n",
        "\n",
        "                time_domain_features.extend(self.compute_time_domain_features(window_data[heart_rate_column[0]], isheartrate= True))\n",
        "\n",
        "                for idx in range(body_acc.shape[1]):\n",
        "                    body = body_acc[:, idx]\n",
        "                    time_domain_features.extend(self.compute_time_domain_features(body))\n",
        "                    freq_domain_features.extend(self.compute_frequency_domain_features(body, fs))\n",
        "                    sma_values.append(self.compute_signal_magnitude_area(body))\n",
        "\n",
        "\n",
        "                features = np.concatenate([time_domain_features, freq_domain_features, sma_values])\n",
        "                all_features.append(features)\n",
        "                all_labels.append(label)\n",
        "\n",
        "        return np.array(all_features), np.array(all_labels), feature_names\n",
        "\n",
        "    def applyFeatureExtraction(self, window_size, overlap, fs):\n",
        "        features, labels, feature_names = self.sliding_window_feature_extraction(window_size=window_size, overlap=overlap, fs=fs)\n",
        "        return features, labels, feature_names\n",
        "\n",
        "    def features_to_dataframe(self, features, labels, feature_names):\n",
        "        features_df = pd.DataFrame(features, columns=feature_names)\n",
        "        labels_df = pd.DataFrame(labels, columns=['label'])\n",
        "        combined_df = pd.concat([features_df, labels_df], axis=1)\n",
        "        return combined_df\n",
        "\n",
        "\n",
        "# Usage example\n",
        "file_path = '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject101.dat'\n",
        "processor = PreProcessor()\n",
        "processor.initializeDataFrame(file_path)\n",
        "processor.dataCleaning()\n",
        "processor.applyPreProcessing()\n",
        "\n",
        "\n",
        "print(processor.dataFrame['activityID'].value_counts())\n",
        "\n",
        "subject_id = 1\n",
        "subject_df = processor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction3(subject_df, subject_id)\n",
        "features, labels, feature_names = feature_extractor.applyFeatureExtraction(300, 0.5, 100)\n",
        "features_df = feature_extractor.features_to_dataframe(features, labels, feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFIHlVmVg_sp",
        "outputId": "b4853e54-9fe5-42ca-8b3e-f01d6bff91f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold accuracy: 0.8260869565217391\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.77      0.87        13\n",
            "           2       1.00      0.60      0.75        10\n",
            "           3       0.50      0.70      0.58        10\n",
            "           4       1.00      0.80      0.89        10\n",
            "           5       0.92      1.00      0.96        11\n",
            "           6       1.00      0.80      0.89        10\n",
            "           7       1.00      0.89      0.94         9\n",
            "          12       0.75      0.75      0.75         8\n",
            "          13       0.78      0.88      0.82         8\n",
            "          16       0.90      0.90      0.90        10\n",
            "          17       0.56      0.90      0.69        10\n",
            "          24       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.83       115\n",
            "   macro avg       0.87      0.83      0.84       115\n",
            "weighted avg       0.87      0.83      0.83       115\n",
            "\n",
            "Fold accuracy: 0.8521739130434782\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.83      0.77      0.80        13\n",
            "           2       0.78      0.70      0.74        10\n",
            "           3       0.80      0.80      0.80        10\n",
            "           4       1.00      0.90      0.95        10\n",
            "           5       1.00      0.82      0.90        11\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       1.00      0.89      0.94         9\n",
            "          12       0.64      0.88      0.74         8\n",
            "          13       1.00      0.75      0.86         8\n",
            "          16       0.73      1.00      0.85        11\n",
            "          17       0.75      1.00      0.86         9\n",
            "          24       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.85       115\n",
            "   macro avg       0.88      0.85      0.86       115\n",
            "weighted avg       0.87      0.85      0.85       115\n",
            "\n",
            "Fold accuracy: 0.8695652173913043\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.85      0.92        13\n",
            "           2       1.00      0.60      0.75        10\n",
            "           3       0.50      0.90      0.64        10\n",
            "           4       0.90      0.90      0.90        10\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       0.85      1.00      0.92        11\n",
            "           7       0.83      0.62      0.71         8\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.88      0.93         8\n",
            "          16       1.00      0.91      0.95        11\n",
            "          17       0.82      1.00      0.90         9\n",
            "          24       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.87       115\n",
            "   macro avg       0.91      0.87      0.87       115\n",
            "weighted avg       0.91      0.87      0.87       115\n",
            "\n",
            "Fold accuracy: 0.8695652173913043\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.79      0.88        14\n",
            "           2       0.75      0.60      0.67        10\n",
            "           3       0.69      0.90      0.78        10\n",
            "           4       0.89      0.80      0.84        10\n",
            "           5       1.00      0.91      0.95        11\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       0.88      0.88      0.88         8\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       0.80      1.00      0.89         8\n",
            "          16       0.90      0.82      0.86        11\n",
            "          17       0.69      1.00      0.82         9\n",
            "          24       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.87       115\n",
            "   macro avg       0.88      0.88      0.87       115\n",
            "weighted avg       0.89      0.87      0.87       115\n",
            "\n",
            "Fold accuracy: 0.8608695652173913\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.72      0.93      0.81        14\n",
            "           2       0.67      0.40      0.50        10\n",
            "           3       0.47      0.70      0.56        10\n",
            "           4       1.00      1.00      1.00        10\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       1.00      0.75      0.86         8\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       0.88      0.88      0.88         8\n",
            "          16       1.00      1.00      1.00        11\n",
            "          17       1.00      0.89      0.94         9\n",
            "          24       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.86       115\n",
            "   macro avg       0.89      0.86      0.87       115\n",
            "weighted avg       0.88      0.86      0.86       115\n",
            "\n",
            "Fold accuracy: 0.8869565217391304\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.57      0.73        14\n",
            "           2       0.83      0.91      0.87        11\n",
            "           3       0.60      0.90      0.72        10\n",
            "           4       0.91      0.91      0.91        11\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       1.00      0.75      0.86         8\n",
            "          12       1.00      0.86      0.92         7\n",
            "          13       0.88      1.00      0.93         7\n",
            "          16       1.00      1.00      1.00        11\n",
            "          17       0.75      1.00      0.86         9\n",
            "          24       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.89       115\n",
            "   macro avg       0.91      0.90      0.90       115\n",
            "weighted avg       0.91      0.89      0.89       115\n",
            "\n",
            "Fold accuracy: 0.8869565217391304\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.71      0.80        14\n",
            "           2       0.70      0.64      0.67        11\n",
            "           3       0.75      0.90      0.82        10\n",
            "           4       1.00      1.00      1.00        11\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      1.00      1.00         8\n",
            "          12       0.86      0.86      0.86         7\n",
            "          13       0.71      0.71      0.71         7\n",
            "          16       0.92      1.00      0.96        11\n",
            "          17       0.82      1.00      0.90         9\n",
            "          24       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.89       115\n",
            "   macro avg       0.89      0.89      0.89       115\n",
            "weighted avg       0.89      0.89      0.89       115\n",
            "\n",
            "Fold accuracy: 0.9122807017543859\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.86      0.92        14\n",
            "           2       0.78      0.64      0.70        11\n",
            "           3       0.69      0.90      0.78        10\n",
            "           4       0.92      1.00      0.96        11\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       1.00      1.00      1.00         8\n",
            "          12       0.88      1.00      0.93         7\n",
            "          13       0.78      1.00      0.88         7\n",
            "          16       1.00      0.80      0.89        10\n",
            "          17       1.00      1.00      1.00        10\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.91       114\n",
            "   macro avg       0.92      0.92      0.92       114\n",
            "weighted avg       0.92      0.91      0.91       114\n",
            "\n",
            "Fold accuracy: 0.8508771929824561\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.77      0.83        13\n",
            "           2       0.80      0.36      0.50        11\n",
            "           3       0.64      1.00      0.78         9\n",
            "           4       0.91      0.91      0.91        11\n",
            "           5       1.00      0.82      0.90        11\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       0.90      1.00      0.95         9\n",
            "          12       0.62      0.71      0.67         7\n",
            "          13       0.88      0.88      0.88         8\n",
            "          16       0.91      1.00      0.95        10\n",
            "          17       0.77      1.00      0.87        10\n",
            "          24       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.85       114\n",
            "   macro avg       0.86      0.86      0.85       114\n",
            "weighted avg       0.87      0.85      0.84       114\n",
            "\n",
            "Fold accuracy: 0.8596491228070176\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.85      0.85      0.85        13\n",
            "           2       0.67      0.40      0.50        10\n",
            "           3       0.53      0.89      0.67         9\n",
            "           4       1.00      1.00      1.00        11\n",
            "           5       1.00      1.00      1.00        11\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      0.89      0.94         9\n",
            "          12       0.70      0.88      0.78         8\n",
            "          13       1.00      0.75      0.86         8\n",
            "          16       1.00      1.00      1.00        10\n",
            "          17       0.89      0.80      0.84        10\n",
            "          24       0.80      0.80      0.80         5\n",
            "\n",
            "    accuracy                           0.86       114\n",
            "   macro avg       0.87      0.85      0.85       114\n",
            "weighted avg       0.88      0.86      0.86       114\n",
            "\n",
            "Average accuracy: 0.8674980930587338\n",
            "Test set accuracy: 0.8780487804878049\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.88      0.67      0.76        45\n",
            "           2       0.84      0.62      0.71        50\n",
            "           3       0.71      0.80      0.75        45\n",
            "           4       1.00      0.98      0.99        42\n",
            "           5       0.94      0.97      0.95        30\n",
            "           6       1.00      0.98      0.99        54\n",
            "           7       0.94      0.98      0.96        49\n",
            "          12       0.85      0.88      0.87        26\n",
            "          13       0.86      1.00      0.92        18\n",
            "          16       0.98      0.89      0.93        45\n",
            "          17       0.72      0.95      0.82        61\n",
            "          24       1.00      0.93      0.96        27\n",
            "\n",
            "    accuracy                           0.88       492\n",
            "   macro avg       0.89      0.89      0.88       492\n",
            "weighted avg       0.89      0.88      0.88       492\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nested_cross_validationKNN(features, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HrnMi0fgJ-I",
        "outputId": "b0822a7d-bc89-4e3e-90de-9f179ed2f9f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold accuracy: 0.8956521739130435\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.74      0.85        27\n",
            "           2       0.91      1.00      0.95        21\n",
            "           3       0.79      0.95      0.86        20\n",
            "           4       1.00      0.90      0.95        21\n",
            "           5       1.00      0.91      0.95        22\n",
            "           6       1.00      0.85      0.92        20\n",
            "           7       1.00      0.88      0.94        17\n",
            "          12       0.92      0.80      0.86        15\n",
            "          13       0.92      0.80      0.86        15\n",
            "          16       0.75      1.00      0.86        21\n",
            "          17       0.70      1.00      0.83        19\n",
            "          24       1.00      0.92      0.96        12\n",
            "\n",
            "    accuracy                           0.90       230\n",
            "   macro avg       0.92      0.90      0.90       230\n",
            "weighted avg       0.92      0.90      0.90       230\n",
            "\n",
            "Fold accuracy: 0.908695652173913\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.90      0.96      0.93        27\n",
            "           2       0.95      0.86      0.90        21\n",
            "           3       0.78      0.90      0.84        20\n",
            "           4       0.94      0.81      0.87        21\n",
            "           5       1.00      0.91      0.95        22\n",
            "           6       0.91      1.00      0.95        20\n",
            "           7       0.88      0.82      0.85        17\n",
            "          12       0.82      0.93      0.87        15\n",
            "          13       1.00      0.93      0.97        15\n",
            "          16       0.95      0.91      0.93        22\n",
            "          17       0.86      1.00      0.92        18\n",
            "          24       1.00      0.83      0.91        12\n",
            "\n",
            "    accuracy                           0.91       230\n",
            "   macro avg       0.92      0.91      0.91       230\n",
            "weighted avg       0.91      0.91      0.91       230\n",
            "\n",
            "Fold accuracy: 0.925764192139738\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.95      0.78      0.86        27\n",
            "           2       0.83      0.95      0.89        21\n",
            "           3       0.78      0.90      0.84        20\n",
            "           4       0.95      0.95      0.95        21\n",
            "           5       1.00      1.00      1.00        22\n",
            "           6       0.95      0.95      0.95        21\n",
            "           7       1.00      0.81      0.90        16\n",
            "          12       1.00      1.00      1.00        15\n",
            "          13       0.87      0.87      0.87        15\n",
            "          16       0.95      1.00      0.98        21\n",
            "          17       0.90      1.00      0.95        19\n",
            "          24       1.00      0.91      0.95        11\n",
            "\n",
            "    accuracy                           0.93       229\n",
            "   macro avg       0.93      0.93      0.93       229\n",
            "weighted avg       0.93      0.93      0.93       229\n",
            "\n",
            "Fold accuracy: 0.9475982532751092\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.96      0.89      0.92        27\n",
            "           2       0.95      0.86      0.90        21\n",
            "           3       0.76      1.00      0.86        19\n",
            "           4       1.00      0.95      0.98        21\n",
            "           5       1.00      1.00      1.00        22\n",
            "           6       0.95      0.95      0.95        20\n",
            "           7       1.00      1.00      1.00        17\n",
            "          12       0.93      0.93      0.93        15\n",
            "          13       0.94      0.94      0.94        16\n",
            "          16       1.00      0.95      0.98        21\n",
            "          17       0.95      1.00      0.97        19\n",
            "          24       1.00      0.91      0.95        11\n",
            "\n",
            "    accuracy                           0.95       229\n",
            "   macro avg       0.95      0.95      0.95       229\n",
            "weighted avg       0.95      0.95      0.95       229\n",
            "\n",
            "Fold accuracy: 0.8995633187772926\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.89      0.94        27\n",
            "           2       0.94      0.85      0.89        20\n",
            "           3       0.67      0.95      0.78        19\n",
            "           4       1.00      0.95      0.98        21\n",
            "           5       1.00      0.91      0.95        22\n",
            "           6       0.95      0.90      0.92        20\n",
            "           7       0.94      0.94      0.94        17\n",
            "          12       1.00      0.69      0.81        16\n",
            "          13       0.76      0.81      0.79        16\n",
            "          16       0.84      1.00      0.91        21\n",
            "          17       0.86      0.95      0.90        19\n",
            "          24       1.00      0.91      0.95        11\n",
            "\n",
            "    accuracy                           0.90       229\n",
            "   macro avg       0.91      0.90      0.90       229\n",
            "weighted avg       0.92      0.90      0.90       229\n",
            "\n",
            "Average accuracy: 0.9154547180558191\n",
            "Test set accuracy: 0.9451219512195121\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.98      0.95        45\n",
            "           2       0.98      0.86      0.91        50\n",
            "           3       0.98      0.89      0.93        45\n",
            "           4       1.00      0.95      0.98        42\n",
            "           5       1.00      0.90      0.95        30\n",
            "           6       0.98      0.98      0.98        54\n",
            "           7       1.00      0.96      0.98        49\n",
            "          12       0.89      0.92      0.91        26\n",
            "          13       1.00      1.00      1.00        18\n",
            "          16       0.93      0.96      0.95        45\n",
            "          17       0.81      1.00      0.90        61\n",
            "          24       1.00      0.93      0.96        27\n",
            "\n",
            "    accuracy                           0.95       492\n",
            "   macro avg       0.96      0.94      0.95       492\n",
            "weighted avg       0.95      0.95      0.95       492\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nested_cross_validationRF(features, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBXpyClwjl7G"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTXQvJjqjrmj",
        "outputId": "84e7c4d6-8982-43be-f814-71aac498096d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame still contains some NAN values\n",
            "activityID\n",
            "4     31932\n",
            "7     27533\n",
            "2     25492\n",
            "17    24995\n",
            "3     24706\n",
            "1     23047\n",
            "6     22699\n",
            "16    20037\n",
            "12    16694\n",
            "13    14285\n",
            "5         1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "file_path = '/content/drive/MyDrive/PAMAP2_Dataset/Protocol/subject104.dat'\n",
        "processor = PreProcessor()\n",
        "processor.initializeDataFrame(file_path)\n",
        "processor.dataCleaning()\n",
        "processor.applyPreProcessing()\n",
        "\n",
        "\n",
        "print(processor.dataFrame['activityID'].value_counts())\n",
        "\n",
        "subject_id = 4\n",
        "subject_df = processor.getSubjectDf(subject_id)\n",
        "\n",
        "feature_extractor = FeatureExtraction3(subject_df, subject_id)\n",
        "features, labels, feature_names = feature_extractor.applyFeatureExtraction(300, 0.5, 100)\n",
        "features_df = feature_extractor.features_to_dataframe(features, labels, feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thAk29vujxk1",
        "outputId": "4f33eb06-aadb-4158-92f5-fe23608cd734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold accuracy: 0.9158878504672897\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.82      0.82      0.82        11\n",
            "           2       0.71      0.83      0.77        12\n",
            "           3       0.90      0.82      0.86        11\n",
            "           4       1.00      1.00      1.00        14\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.88      0.93         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       0.89      0.89      0.89         9\n",
            "          17       0.92      0.92      0.92        12\n",
            "\n",
            "    accuracy                           0.92       107\n",
            "   macro avg       0.92      0.92      0.92       107\n",
            "weighted avg       0.92      0.92      0.92       107\n",
            "\n",
            "Fold accuracy: 0.8411214953271028\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.67      0.73      0.70        11\n",
            "           2       0.86      0.50      0.63        12\n",
            "           3       0.71      0.91      0.80        11\n",
            "           4       0.81      0.93      0.87        14\n",
            "           6       0.91      1.00      0.95        10\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       0.89      1.00      0.94         8\n",
            "          13       1.00      0.71      0.83         7\n",
            "          16       0.78      0.78      0.78         9\n",
            "          17       0.92      0.92      0.92        12\n",
            "\n",
            "    accuracy                           0.84       107\n",
            "   macro avg       0.85      0.84      0.84       107\n",
            "weighted avg       0.85      0.84      0.84       107\n",
            "\n",
            "Fold accuracy: 0.822429906542056\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.82      0.75      0.78        12\n",
            "           2       0.78      0.58      0.67        12\n",
            "           3       0.67      0.55      0.60        11\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       0.90      0.90      0.90        10\n",
            "           7       0.85      0.92      0.88        12\n",
            "          12       0.89      1.00      0.94         8\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.88      0.70      0.78        10\n",
            "          17       0.63      1.00      0.77        12\n",
            "\n",
            "    accuracy                           0.82       107\n",
            "   macro avg       0.84      0.83      0.82       107\n",
            "weighted avg       0.83      0.82      0.82       107\n",
            "\n",
            "Fold accuracy: 0.8490566037735849\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.83      0.83      0.83        12\n",
            "           2       0.57      0.67      0.62        12\n",
            "           3       0.75      0.90      0.82        10\n",
            "           4       0.93      1.00      0.96        13\n",
            "           6       0.88      0.70      0.78        10\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.86      0.92         7\n",
            "          16       0.88      0.70      0.78        10\n",
            "          17       0.85      0.92      0.88        12\n",
            "\n",
            "    accuracy                           0.85       106\n",
            "   macro avg       0.87      0.85      0.85       106\n",
            "weighted avg       0.86      0.85      0.85       106\n",
            "\n",
            "Fold accuracy: 0.8584905660377359\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.79      0.92      0.85        12\n",
            "           2       0.80      0.67      0.73        12\n",
            "           3       0.56      0.90      0.69        10\n",
            "           4       1.00      1.00      1.00        13\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       1.00      0.92      0.96        12\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       1.00      0.70      0.82        10\n",
            "          17       0.73      0.67      0.70        12\n",
            "\n",
            "    accuracy                           0.86       106\n",
            "   macro avg       0.89      0.87      0.87       106\n",
            "weighted avg       0.88      0.86      0.86       106\n",
            "\n",
            "Fold accuracy: 0.8584905660377359\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.83      0.87        12\n",
            "           2       0.75      0.75      0.75        12\n",
            "           3       0.73      0.73      0.73        11\n",
            "           4       1.00      1.00      1.00        14\n",
            "           6       1.00      0.90      0.95        10\n",
            "           7       1.00      1.00      1.00        12\n",
            "          12       0.88      0.88      0.88         8\n",
            "          13       1.00      0.83      0.91         6\n",
            "          16       0.80      0.80      0.80        10\n",
            "          17       0.64      0.82      0.72        11\n",
            "\n",
            "    accuracy                           0.86       106\n",
            "   macro avg       0.87      0.85      0.86       106\n",
            "weighted avg       0.87      0.86      0.86       106\n",
            "\n",
            "Fold accuracy: 0.8113207547169812\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.80      0.73      0.76        11\n",
            "           2       0.62      0.83      0.71        12\n",
            "           3       0.56      0.45      0.50        11\n",
            "           4       1.00      1.00      1.00        14\n",
            "           6       0.90      0.90      0.90        10\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      0.75      0.86         8\n",
            "          13       0.80      0.67      0.73         6\n",
            "          16       0.75      0.60      0.67        10\n",
            "          17       0.73      1.00      0.85        11\n",
            "\n",
            "    accuracy                           0.81       106\n",
            "   macro avg       0.82      0.79      0.80       106\n",
            "weighted avg       0.82      0.81      0.81       106\n",
            "\n",
            "Fold accuracy: 0.8679245283018868\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.82      0.82      0.82        11\n",
            "           2       0.80      0.73      0.76        11\n",
            "           3       0.73      0.73      0.73        11\n",
            "           4       0.93      1.00      0.97        14\n",
            "           6       1.00      0.80      0.89        10\n",
            "           7       1.00      0.92      0.96        13\n",
            "          12       1.00      1.00      1.00         8\n",
            "          13       1.00      0.83      0.91         6\n",
            "          16       0.89      0.80      0.84        10\n",
            "          17       0.71      1.00      0.83        12\n",
            "\n",
            "    accuracy                           0.87       106\n",
            "   macro avg       0.89      0.86      0.87       106\n",
            "weighted avg       0.88      0.87      0.87       106\n",
            "\n",
            "Fold accuracy: 0.8867924528301887\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.77      0.91      0.83        11\n",
            "           2       0.58      0.64      0.61        11\n",
            "           3       0.67      0.55      0.60        11\n",
            "           4       1.00      1.00      1.00        14\n",
            "           6       1.00      1.00      1.00        10\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       1.00      1.00      1.00         7\n",
            "          13       1.00      1.00      1.00         7\n",
            "          16       1.00      0.90      0.95        10\n",
            "          17       0.92      0.92      0.92        12\n",
            "\n",
            "    accuracy                           0.89       106\n",
            "   macro avg       0.89      0.89      0.89       106\n",
            "weighted avg       0.89      0.89      0.89       106\n",
            "\n",
            "Fold accuracy: 0.8490566037735849\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.90      0.82      0.86        11\n",
            "           2       0.79      1.00      0.88        11\n",
            "           3       0.75      0.82      0.78        11\n",
            "           4       1.00      1.00      1.00        14\n",
            "           6       0.80      0.80      0.80        10\n",
            "           7       1.00      1.00      1.00        13\n",
            "          12       0.75      0.86      0.80         7\n",
            "          13       0.83      0.71      0.77         7\n",
            "          16       0.71      0.50      0.59        10\n",
            "          17       0.83      0.83      0.83        12\n",
            "\n",
            "    accuracy                           0.85       106\n",
            "   macro avg       0.84      0.83      0.83       106\n",
            "weighted avg       0.85      0.85      0.85       106\n",
            "\n",
            "Average accuracy: 0.8560571327808146\n",
            "Test set accuracy: 0.8640350877192983\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.79      0.85        38\n",
            "           2       0.67      0.73      0.70        51\n",
            "           3       0.72      0.75      0.73        55\n",
            "           4       0.96      0.96      0.96        73\n",
            "           6       1.00      0.94      0.97        49\n",
            "           7       0.96      0.98      0.97        56\n",
            "          12       0.92      0.83      0.87        29\n",
            "          13       0.88      0.92      0.90        25\n",
            "          16       0.93      0.82      0.87        34\n",
            "          17       0.75      0.87      0.81        46\n",
            "\n",
            "    accuracy                           0.86       456\n",
            "   macro avg       0.87      0.86      0.86       456\n",
            "weighted avg       0.87      0.86      0.87       456\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nested_cross_validationKNN(features, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLdmDkLZjoFr",
        "outputId": "46c60c0a-b05a-424b-fb08-fb3912dda09f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold accuracy: 0.9342723004694836\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.90        23\n",
            "           2       0.96      0.92      0.94        24\n",
            "           3       0.88      1.00      0.94        22\n",
            "           4       1.00      0.96      0.98        28\n",
            "           6       0.87      1.00      0.93        20\n",
            "           7       1.00      0.96      0.98        25\n",
            "          12       1.00      0.94      0.97        16\n",
            "          13       1.00      0.85      0.92        13\n",
            "          16       0.81      0.89      0.85        19\n",
            "          17       0.88      0.96      0.92        23\n",
            "\n",
            "    accuracy                           0.93       213\n",
            "   macro avg       0.94      0.93      0.93       213\n",
            "weighted avg       0.94      0.93      0.93       213\n",
            "\n",
            "Fold accuracy: 0.8826291079812206\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.95      0.91      0.93        22\n",
            "           2       0.95      0.88      0.91        24\n",
            "           3       0.68      0.86      0.76        22\n",
            "           4       1.00      1.00      1.00        28\n",
            "           6       1.00      0.90      0.95        20\n",
            "           7       1.00      0.88      0.94        26\n",
            "          12       0.94      0.94      0.94        16\n",
            "          13       1.00      0.85      0.92        13\n",
            "          16       0.67      0.84      0.74        19\n",
            "          17       0.77      0.74      0.76        23\n",
            "\n",
            "    accuracy                           0.88       213\n",
            "   macro avg       0.90      0.88      0.88       213\n",
            "weighted avg       0.90      0.88      0.89       213\n",
            "\n",
            "Fold accuracy: 0.9295774647887324\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.87      0.93        23\n",
            "           2       0.91      0.91      0.91        23\n",
            "           3       0.78      0.82      0.80        22\n",
            "           4       1.00      1.00      1.00        27\n",
            "           6       1.00      0.90      0.95        20\n",
            "           7       1.00      1.00      1.00        25\n",
            "          12       1.00      0.94      0.97        16\n",
            "          13       1.00      1.00      1.00        13\n",
            "          16       0.90      0.95      0.93        20\n",
            "          17       0.79      0.92      0.85        24\n",
            "\n",
            "    accuracy                           0.93       213\n",
            "   macro avg       0.94      0.93      0.93       213\n",
            "weighted avg       0.94      0.93      0.93       213\n",
            "\n",
            "Fold accuracy: 0.9056603773584906\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.83      0.90        23\n",
            "           2       0.88      0.91      0.89        23\n",
            "           3       0.74      0.81      0.77        21\n",
            "           4       1.00      0.96      0.98        27\n",
            "           6       1.00      1.00      1.00        20\n",
            "           7       1.00      1.00      1.00        25\n",
            "          12       1.00      0.80      0.89        15\n",
            "          13       0.83      0.71      0.77        14\n",
            "          16       0.82      0.90      0.86        20\n",
            "          17       0.83      1.00      0.91        24\n",
            "\n",
            "    accuracy                           0.91       212\n",
            "   macro avg       0.91      0.89      0.90       212\n",
            "weighted avg       0.91      0.91      0.91       212\n",
            "\n",
            "Fold accuracy: 0.9245283018867925\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.87      0.93        23\n",
            "           2       0.88      0.96      0.92        23\n",
            "           3       0.77      0.81      0.79        21\n",
            "           4       1.00      1.00      1.00        27\n",
            "           6       1.00      0.95      0.97        20\n",
            "           7       1.00      0.96      0.98        25\n",
            "          12       0.93      0.93      0.93        15\n",
            "          13       0.92      0.86      0.89        14\n",
            "          16       0.83      0.95      0.88        20\n",
            "          17       0.92      0.92      0.92        24\n",
            "\n",
            "    accuracy                           0.92       212\n",
            "   macro avg       0.93      0.92      0.92       212\n",
            "weighted avg       0.93      0.92      0.93       212\n",
            "\n",
            "Average accuracy: 0.915333510496944\n",
            "Test set accuracy: 0.9320175438596491\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.97      0.99        38\n",
            "           2       1.00      0.92      0.96        51\n",
            "           3       0.83      0.91      0.87        55\n",
            "           4       1.00      0.96      0.98        73\n",
            "           6       0.98      0.94      0.96        49\n",
            "           7       1.00      0.98      0.99        56\n",
            "          12       1.00      0.86      0.93        29\n",
            "          13       1.00      0.88      0.94        25\n",
            "          16       0.78      0.94      0.85        34\n",
            "          17       0.79      0.89      0.84        46\n",
            "\n",
            "    accuracy                           0.93       456\n",
            "   macro avg       0.94      0.93      0.93       456\n",
            "weighted avg       0.94      0.93      0.93       456\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nested_cross_validationRF(features, labels)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPn7cnlyUkfQC1qIhTKmWMm",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
